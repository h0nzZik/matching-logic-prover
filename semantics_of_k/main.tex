\documentclass[UTF8]{article}

%\usepackage{xcolor}
\usepackage[pdftex,dvipsnames]{xcolor}  % Coloured text etc.
\usepackage{xargs}                      % Use more than one optional parameter in a new commands

  % Select what to do with todonotes: 
  % \usepackage[disable]{todonotes} % notes not showed
  %  \usepackage[draft]{todonotes} % notes showed
\usepackage[colorinlistoftodos,prependcaption,textsize=tiny]{todonotes}
\newcommandx{\unsure}[2][1=]{\todo[linecolor=red,backgroundcolor=red!25,bordercolor=red,#1]{#2}}
\newcommandx{\change}[2][1=]{\todo[linecolor=blue,backgroundcolor=blue!25,bordercolor=blue,#1]{#2}}
\newcommandx{\info}[2][1=]{\todo[linecolor=OliveGreen,backgroundcolor=OliveGreen!25,bordercolor=OliveGreen,#1]{#2}}
\newcommandx{\improvement}[2][1=]{\todo[linecolor=Plum,backgroundcolor=Plum!25,bordercolor=Plum,#1]{#2}}
\newcommandx{\thiswillnotshow}[2][1=]{\todo[disable,#1]{#2}}

  % Select what to do with command \comment:  
  % \newcommand{\comment}[1]
      {} %comment not showed
  \newcommand{\comment}[1]
    {\par {\bfseries \color{blue} #1 \par}} %comment showed
    
  \usepackage{amsmath}
  \usepackage{amssymb}
  
  \usepackage{amsthm}
  
  % Declare a global counter for theorem environments:
  \newcounter{thmcounter}
  
  % Define new theorem styles:
  \theoremstyle{plain}
  \newtheorem{theorem}[thmcounter]{Theorem}
  \newtheorem{corollary}[thmcounter]{Corollary}
  \newtheorem{lemma}[thmcounter]{Lemma}
  \newtheorem{proposition}[thmcounter]{Proposition}
  \theoremstyle{definition}
  \newtheorem{definition}[thmcounter]{Definition}
  \newtheorem{example}[thmcounter]{Example}
  \theoremstyle{remark}
  \newtheorem{remark}[thmcounter]{Remark}
  \newtheorem{notation}[thmcounter]{Notation}
  
  
  % Package for changing fonts in the Verbatim environment:
  \usepackage{fancyvrb}
  
  % Package for URLs:
  \usepackage{hyperref}  
  
  % Define serif fonts for ML theories used in math mode:
  \newcommand{\PA}{\mathsf{PA}}
  \newcommand{\SEQ}{\mathsf{SEQ}}
  \newcommand{\HEAP}{\mathsf{HEAP}}
  \newcommand{\IMP}{\mathsf{IMP}}
  \newcommand{\FIX}{\mathsf{FIX}}
  \newcommand{\LAMBDA}{\mathsf{LAMBDA}}
  \newcommand{\CTXT}{\mathsf{CTXT}}
  \newcommand{\DEF}{\mathsf{DEF}}
  \newcommand{\METALEVEL}{\mathsf{META-LEVEL}}
  
  % Define serif fonts for symbols:
  \newcommand{\impite}{\mathsf{ite}}
  \newcommand{\impwhile}{\mathsf{while}}
  \newcommand{\imptt}{\mathsf{tt}}
  \newcommand{\impff}{\mathsf{ff}}
  \newcommand{\impskip}{\mathsf{skip}}
  \newcommand{\impseq}{\mathsf{seq}}
  \newcommand{\impasgn}{\mathsf{asgn}}
  
  \newcommand{\impmapsto}{\mathsf{mapsto}}
  \newcommand{\impmerge}{\mathsf{merge}}
  
  \newcommand{\up}{\mathsf{\#up}}
  \newcommand{\down}{\mathsf{\#down}}
  \newcommand{\isGround}{\mathsf{isGround}}
  \newcommand{\xfalse}{\mathsf{false}}
  \newcommand{\xtrue}{\mathsf{true}}
  
  
  % Define identity context
  \newcommand{\I}{\mathsf{I}}
  
  % Define the colon ":" that is used in "x:s"
  % with less spacing around.
  \newcommand{\cln}{{:}}
 
  
  % Define ceiling and flooring symbols:
  \usepackage{mathtools}
  \DeclarePairedDelimiter{\ceil}{\lceil}{\rceil}

  % Package for underlining and strikethrough texts.
  \usepackage[normalem]{ulem}
  
  % Define text over equality
  \usepackage{mathtools}
  \newcommand{\xeq}[1]
    {\stackrel{\mathclap{\normalfont\tiny\mbox{#1}}}{=}}
    
  % Package for display-mode quotations.
  \usepackage{csquotes}
  
  % Package for double-bracket [[P]] (known as the semantics bracket)
  \usepackage{stmaryrd}
  \newcommand{\Bracket}[1]
    {\llbracket#1\rrbracket}

  % Title and authors
  \title{The Semantics of K}
  \author{Formal Systems Laboratory \\
          University of Illinois}

\begin{document}

\maketitle

\comment{Please feel free to contribute to this report in all ways.
\info{Follow the FSL rules for editing, though; e.g., <80 characters per line,
each sentence on a new line, etc.}
You could add new contents, remove redundant ones, refactor and
organize the texts, and correct typos.}

\section{Matching Logic}

\newcommand{\Var}{\textit{Var}}
\newcommand{\Nat}{\textit{Nat}}

Let us recall the basic grammar of matching logic
from~\cite{rosu-2017-lmcs}.\improvement{Add references.}
~
Let $\Var$ be a countable set of
\emph{variables}.\unsure{Not sure why you prefer to work with only one set of
variables, instead of a set $\Var_s$ for each sort $s$.}
~
Assume a matching logic \emph{signature} $(S, \Sigma)$.
For simplicity, here we assume that the sets of \emph{sorts} $S$
and of \emph{symbols} $\Sigma$ are finite.
We partition $\Sigma$ in sets of symbols
$\Sigma_{s_1 \ldots s_n, s}$ of \emph{arity} $s_1\ldots s_n,s$, where
$s_1,\ldots, s_n, s \in S$.
Then \emph{patterns} of sort $s \in S$ are generated by the following grammar:
\begin{align*}
\varphi_s \Coloneqq\  &x \cln s \quad \text{where $x \in \Var$} \\
\mid\  &\varphi_s \wedge \varphi_s \\
\mid\  &\neg \varphi_s \\
\mid\  &\exists x \cln s' . \varphi_s \quad \text{where $x \in N$ and $s' \in S$} \\
\mid\  &\sigma(\varphi_{s_1},\dots,\varphi_{s_n}) \quad \text{where $\sigma \in \Sigma$ has $n$ arguments, and \dots}
\end{align*}
The grammar above only defines the syntax of (well-formed) patterns of sort
$s$.
It says nothing about their semantics.
For example, patterns $x\cln s \wedge y \cln s$ and
$y\cln s \wedge x \cln s$ are distinct elements in the language
of the grammar, in spite of them being semantically/provably equal
in matching logic.

For notational convenience, we take the liberty to use mix-fix syntax for
operators in $\Sigma$,
parentheses for grouping, and omit variable sorts when understood.
For example, if $\Nat \in S$ and
$\_+\_, \_*\_ \in \Sigma_{\Nat \times \Nat, \Nat}$
then we may write $(x + y)*z$ instead of
$\_*\_(\_+\_(x\cln\Nat,y\cln\Nat),z\cln\Nat)$.

\improvement{I think we also need to talk about: other logical connectives
as derived, free variables, capture-free substitution, equality.
Add more as we need them.}

A matching logic \emph{theory} is a triple $(S, \Sigma, A)$ where
$(S,\Sigma)$ is a signature and $A$ is a set of patterns called \emph{axioms}.
Like in many logics, sets of patterns may be presented as \emph{schemas}
making use of meta-variables ranging over patterns, sometimes constrained
to subsets of patterns using side conditions.
For example:
$$
\begin{array}{rl}
\varphi[\varphi_1/x] \wedge (\varphi_1 = \varphi_2) \rightarrow \varphi[\varphi_2/x]
&\textrm{where $\varphi$ is any pattern and $\varphi_1$, $\varphi_2$} \\
& \textrm{are any patterns of same sort as $x$}
\\[2ex]
(\lambda x . \varphi)\varphi' = \varphi[\varphi'/x]
& \textrm{where $\varphi$, $\varphi'$ are \emph{syntactic patterns}, that is,}
\\
& \textrm{ones formed only with variables and symbols}
\\[2ex]
\varphi_1 \mathrel{\texttt{+}} \varphi_2 = \varphi_1 +_\Nat \varphi_2
& \textrm{where $\varphi$, $\varphi'$ are \emph{ground} syntactic patterns}
\\
&\textrm{of sort $\Nat$, that is, patterns built only}
\\
&\textrm{with symbols \texttt{zero} and \texttt{succ}}
\\[2ex]
(\varphi_1 \rightarrow \varphi_2) \rightarrow
(\varphi[\varphi_1 / x] \rightarrow \varphi[\varphi_2 / x])
& \textrm{where $\varphi$ is a \emph{positive context in $x$}, that is,}
\\
& \textrm{a pattern
containing only one occurrence}
\\
&\textrm{of $x$ with no negation ($\neg$) on the path to}
\\
&\textrm{$x$, and where $\varphi_1$, $\varphi_2$ are any patterns}
\\
&\textrm{having the same sort}
\end{array}
$$

One of the major goals of this paper is to propose a formal language
and an implementation, that allows us to write such pattern schemas.

\change{Let's introduce this when needed.  Also, ``equal'' is not a good word.

``Two theories are \emph{equal} if they have the same set of sorts and symbols, and they deduce the same set of theorems.''}


\section{A Calculus of Matching Logic}
In this section, we propose a calculus of matching logic as a matching logic 
theory. 
\todo[inline, author = Xiaohong]{Defining the meta-level in matching logic 
seems to be a good idea ... }
\begin{displayquote}
	Many people have developed calculi for mathematical reasoning. 
	A calculus of logics is often called a \emph{logical framework}.
	I prefer to speak of a \emph{meta-logic} and its \emph{object-logic}. \\
	By L. Paulson, \emph{The Foundation of a Generic Theorem Prover}
\end{displayquote}
In this proposal, the \emph{object-logic} refers to matching logic,
and we propose to use matching logic itself as the 
\emph{meta-logic}\footnote{Coq and Isabelle use 
fragments of higher-order logic as their meta-logics.}. 
The calculus of matching logic, denoted as $M = (S_M, \Sigma_M, A_M)$, is 
matching logic theory
where $S_M$ is a set of sorts, $\Sigma_M$ is a set of symbols, and $A_M$ is a 
set of equations, defined as the next Maude theory: \todo{Change it to a ML 
theory.}

\begin{Verbatim}[fontsize=\small]
  fth M is
    protecting STRING .
    
    sort Sort . op #sort : String -> Sort .
    sort SortList .          ---- comma-separated lists
    
    sort Symbol .
    op #symbol : String      ---- unique identity / name / reference
                 SortList    ---- argument sorts
                 Sort        ---- result sort
                 -> Symbol .
    
    sorts K KList .          ---- Grigore proposed to name it K 
                             ---- instead of Pattern
    
    op #variable : String    ---- unique identity / name / reference
                   Sort -> K .
    op #and : K K -> K .
    op #not : K -> K .
    op #exists : String      ---- id of binding variable
                 Sort        ---- sort of binding variable
                 K -> K .
    op #application : Symbol KList -> K .
    op #value : String       ---- encoding of domain values
                Sort         ---- sort of values
                -> K .       ---- not sure about #value
    
    op well-formed : K -> Bool .
    op getSort : K -> [Sort] .
    op isSort : K Sort -> Bool .
    
    cmb getSort(K:K) : Sort if well-formed(K:K) [nonexe] .
    eq isSort(K:K, S:Sort) = (getSort(K:K) = S:Sort) [nonexe] .
    
    op getFreeVariables : K 
                          -> ... .   ---- a collection of variables
    
    ---- fine-grained-controlled substitution
    op replace : K           ---- the main pattern 
                 K           ---- the "replace" pattern
                 K           ---- the "find" pattern
                 ...         ---- some controlling arguments
                 -> K .
    
    op freshName : StringList      ---- a collection of used names.
                   -> String .
    
    ---- the following is about the proof system of matching logic.
    ---- Reference: [L. Paulson] The Foundation of a Generic Theorem Prover
    
    sorts InferenceRule      ---- a function from theorems to theorems
          Tactic             ---- the "reverse" of an inference rule
          Validation         ---- the "certificate" returned by a tactic
          Tactical .         ---- control structures applied on tactics
    
    op deducible : K -> Bool .
    
    ---- not finished
  endth
\end{Verbatim}

\comment{It is strongly recommend that readers of this proposal read L. 
	Paulson's \emph{The Foundation of a Generic Theorem Prover}, especially 
	Section 
	2, 3, and 4.}

Suppose $L$ is a syntactic matching logic theory whose axiom set is~$A$.
Let $\# L$ be the meta-level theory of $L$ obtained by adding 
$$\Bracket{A} = 
\{\textit{deducible}\left(\Bracket{\varphi}\right)
\mid 
\varphi \in A\}$$
as axioms to the meta-logic theory $M$,
where the double bracket $\Bracket{\_}$ is a function that maps object-patterns 
to their meta-representations in $M$. 
The following definition is inspired by Paulson's paper (Definition 1). 
\begin{definition}
	Let $L$ be a matching logic theory and $\#L$ is its meta-logic theory. 
	Let	$\varphi_1,\dots,\varphi_n$ and $\psi$ be patterns of $L$.	
	Then say
	\begin{itemize}
		\item $\#L$ is \emph{sound} for $L$, if for every $\#L$-proof of 
		$\mathit{deducible}\left(\Bracket{\psi}\right)$ from 
		$\mathit{deducible}\left(\Bracket{\varphi_1}\right),\\ \dots, 
		\mathit{deducible}\left(\Bracket{\varphi_n}\right)$, there is an 
		$L$-proof of $\psi$ from 
		$\varphi_1,\dots,\varphi_n$.
		\item $\#L$ is \emph{complete} for $L$, if for every $L$-proof of 
		$\psi$ from $\varphi_1,\dots,\varphi_n$, there is a $\#L$-proof of 
		$\mathit{deducible}\left(\Bracket{\psi}\right)$ from 
		$\mathit{deducible}\left(\Bracket{\varphi_1}\right), \dots, 
		\mathit{deducible}\left(\Bracket{\varphi_n}\right)$.
		\item $\#L$ is \emph{faithful} for $L$ if it is both sound and complete.
	\end{itemize}
    As a result of $\#L$ being faithful for $L$, for any pattern $\varphi$, 
    $\varphi$ is deducible in $L$ iff $\mathit{deducible}(\varphi)$ is 
    deducible in $\#L$.
\end{definition}


For example, the next Maude functional theory defines the meta-logic of lambda 
calculus in matching logic:

\begin{Verbatim}[fontsize=\small]
fth M-LAMBDA is
  extending M .
  
  ---- the following syntactic sugar is just for readability. 

  ops app lambda0 : -> Symbol .
  eq app = #symbol("app", ("Exp", "Exp"), "Exp") .
  eq lambda0 = #symbol("lambda0", ("Exp", "Exp"), "Exp") .
  
  op lambda_._ : String K -> K .
  eq lambda X:VariableId . E:K
   = #exists(X:VariableId, "Exp", 
     #application(lambda0, (#variable(X:VariableId, "Exp"), E:K)))) .
  op _[_] : K K -> K .
  eq E1:K[E2:K] 
   = #application(app, (E1:K, E2:K))) .
   
  ---- side conditions checker
  
  op isLTerm : K -> Bool .

  eq isLTerm(#variable(X:VariableId, "Exp")) = true .
  
  eq isLTerm(E1:K[E2:K])
   = isLTerm(E1:K) and isLTerm(E2:K) .
   
  eq isLTerm(lambda(X:VariableId, E:K))
   = isLTerm(E:K) .
  
  ---- the (Beta) axiom

  cmb #equal((lambda X:VariableId . E1:K)[E2:K],
              replace(...)) : Theorem
   if isLTerm(E1:K) and isLTerm(E2:K) .
endth
\end{Verbatim}

One can see how complex it is to write meta-logic theories, but it is an aspect 
of life. 
In the next section, we will introduce the Kore language that lets one define 
theories in the object-level. 

\section{The Kore Language}

We have shown a meta-logic theory $M$ in which we can specify everything about 
matching logic theories, for example, whether a pattern is well-formed, what 
sort a patter has, which patterns are deducible, free variables, fresh 
variables generation, substitution and replacement, alpha-renaming, etc.
This meta-logic theory provides a universe of (meta-representations of) 
patterns, the proof system of matching logic, the entailment relation, etc. 
together with all kinds of operations and functions. 
On the other hand, it is easier to work in the object-level rather than the 
meta-level. 
Even if all reasoning in the object-logic $L$ can be faithfully lifted to the 
meta-logic theory $\#L$, it does not mean one should always do so. 

The Kore language is proposed to help writing a matching logic theory $L$ 
mainly at the object-level, and only go to the meta-level if it is explicitly 
required. The outcomes are called Kore definitions, whose semantics is given by 
defining a transformation that maps a Kore definition \texttt{module.kore} 
to a meta-logic theory $\#L$. In this case we say that \texttt{module.kore} 
defines the matching logic theory $L$. 

We propose the next Kore syntax. 

\begin{Verbatim}[fontsize=\small]
// Namespaces for sorts, variables, metavariables,
// symbols, and Kore modules.
SortId         = String
VariableId     = String
MetaVariableId = String
SymbolId       = String
ModuleId       = String

Sort           = SortId

Variable       = VariableId:SortId
MetaVariable   = MetaVariableId::SortId

Pattern        = Variable | MetaVariable
               | \and(Pattern, Pattern)
               | \not(Pattern)
               | \exists(Variable, Pattern)
               | SymbolId(List{Pattern})

Signature      = syntax SortId
               | syntax SortId ::= SymbolId(List{SortId})
               | Signature Signature

Axioms         = axiom Pattern
               | Axioms Axioms
               
Imports        = import ModuleId
               | import K

Module         = module ModuleId
                   Imports
                   Signature
                   Axioms
                 endmodule
\end{Verbatim}

\subsection{Semantics of Kore}

Kore definitions semantics is given as a translation, denoted as \texttt{\#up},
to meta-logic theories, as shown in the following rules.
The main principle is that every object-level constructors are translated to 
ground terms (ASTs) while meta-variables are translated to variables in the 
meta-logic. The sorts of meta-variables are collected by \texttt{\#metacond} 
and become the premises of the predicate \texttt{deducible(\#up)}. 

\begin{Verbatim}
#up(X:S) => #variable("X", #sort("S"))
#up(X::S) => \and(X:Pattern, isSort(X:Pattern, #sort("S")))
#up(\and(P, Q)) => #and(#up(P), #up(Q))
#up(\not(P)) => #not(#up(P))
#up(\exists(X:S, P)) => #exists("X", #sort("S"), #up(P))

#metacond(X:S) => \top
#metacond(X::S) => isSort(X:Pattern, #sort("S"))
#metacond(\and(P, Q)) => \and(#metacond(P), #metacond(Q))
#metacond(\not(P)) => #metacond(P)
#metacond(\exists(X:S, P)) => #metacond(P)

#up(axiom P) => \implies(#metacond(P), deducible(#up(P)))
\end{Verbatim} 

Kore definitions without \texttt{import K} are considered as object-level 
modules. Kore definitions with \texttt{import K} are considered as meta-level 
modules, in which every patterns are at meta-level. Object-level patterns are 
still allowed, but they are considered as syntactic sugar and are automatically 
lifted to the meta-level. 
the meta-level

\subsection{Example Kore Definitions}

\todo{I haven't checked the following paragraph so there might be inconsistency 
between it with the previous.}

\paragraph{The {\small BOOL} module.}\quad
\begin{Verbatim}
module BOOL
  syntax Bool
  syntax Bool ::= trueBool | falseBool | notBool(Bool)
                | andBool(Bool, Bool) | orBool(Bool, Bool)
  axiom  \or(trueBool, falseBool)
  axiom  \exists(X:Bool, \equal(X:Bool, trueBool))
  axiom  \exists(X:Bool, \equal(X:Bool, notBool(Y:Bool)))
  axiom  ... ...
endmodule
\end{Verbatim}

\paragraph{The {\small NAT} module.}\quad  
\begin{Verbatim}
module NAT
  import BOOL
  syntax Nat
  syntax Nat ::= zero | succ(Nat) | plus(Nat, Nat) 
               | mult(Nat, Nat)
  syntax Bool ::= gt(Nat, Nat) | gte(Nat, Nat)
  axiom  \equal(mult(X:Nat, zero), zero)
  axiom  \equal(mult(X::Nat, Y::Nat), mult(Y::Nat, X::Nat))
  axiom  ... ...
  // hook to a model (not finished)
  hook-sort Nat "external-model Naturals"
  hook-symbol zero \value("0", Nat)
  hook-symbol succ \value("succ", Nat)
  ... ...
endmodule
\end{Verbatim}

\paragraph{The {\small LAMBDA} module.}\quad
\begin{Verbatim}
module LAMBDA
  import M      ---- import the meta-logic theory M
                ---- we can rename it to K ...
  syntax Exp
  syntax Exp ::= app(Exp, Exp)
               | lambda0(Exp, Exp)
  syntax M.Bool ::= isLTerm(K)     ---- I think the Bool here is the
                                   ---- one in the meta-logic M, not
                                   ---- not one in the Kore module 
                                   ---- BOOL
  axiom  \equals(app(\exists(X:Exp, lambda0(X:Exp, E::Exp)), E'::Exp),
                 \replace(E::Exp, E'::Exp, X:Exp))
  requires \isLTerm(E::Exp) M.and \isLTerm(E'::Exp) ---- requires is a sugar
  
  axiom isLTerm(X:Exp) = M.true
  axiom isLTerm(app(E::Exp, E'::Exp)) = isLTerm(E::Exp) M.and isLTerm(E'::Exp)
  ...
      
endmodule
\end{Verbatim}



\subsection{Lambda Calculus}

\begin{Verbatim}
module LAMBDA
  syntax Exp
  syntax Exp  ::= lambda0(Exp, Exp)
                | app(Exp, Exp)
  syntax Bool ::= isLTerm(Pattern)
  axiom isLTerm(X:Exp) = true
  axiom isLTerm(\exists(X:Exp, lambda0(X:Exp, E:Exp)))
      = isLTerm(E:Exp)
  axiom isLTerm(app(E:Exp, E':Exp))
      = isLTerm(E:Exp) andBool isLTerm(E':Exp)
  axiom app(\exists(X:Exp, lambda0(X:Exp, E::Exp)), E'::Exp)
      = E::Exp[E'::Exp / X:Exp]
  requires isLTerm(E::Exp) andBool isLTerm(E'::Exp)
endmodule
\end{Verbatim}

\comment{Many discussions in the next section (Sec.4 Object-level and Meta-level) should be moved to Section 3 as examples. Sec.5 Binders and Sec.6 Contexts should also move to a subsection of Sec.3 as applications and examples. }

\section{Object-level and Meta-level}

It is an aspect of life in mathematical logics to distinguish the \emph{object-level} and \emph{meta-level} concepts. In matching logic, we put more emphasize and care on metavariables and their range, that is, the set of patterns that they stand for. It turns out that having metavariables that range over all well-formed patterns will lead us to inconsistency theories immediately. As an example, consider the ($\beta$) axiom in the matching logic theory $\LAMBDA$ of lambda calculus:
\begin{equation*}
(\lambda x . e) [e'] = e[e' / x].
\end{equation*}
If we do not put any restriction on the range of metavariables $e$ and $e'$, we have an inconsistency issue as the following reasoning shows:
\begin{align*}
\bot \xeq{(N)} (\lambda x . \top)[\bot] \xeq{($\beta$)} \top[\bot / x] = \top.
\end{align*}

Therefore, in matching logic, one should explicitly specify the range of metavariables whenever he uses them.

\begin{definition}[Restricted metavariables]
	Let $\varphi$ be a metavariable of sort $s \in S$. The range of $\varphi$ is a set of patterns of sort $s$. We write $\varphi :: R$ if the range of $\varphi$ is $R \subseteq \mathrm{Pattern}_s$.
\end{definition}

\begin{remark}[Metavariables in first-order logic]
In first-order logic, one often uses metavariables in axiom schemata, but the inconsistency issue does not arise. This is because in first-order logic, we do not need to distinguish metavariables for terms from logic variables, thanks to the next (Substitution) rule:
\begin{equation*}
\forall x . \varphi(x) \to \varphi(t).
\end{equation*}
The predicate metavariables are not a problem because there are no object level symbols on top of them. \comment{I don't get the point of predicate metavariables.}
\end{remark}

\paragraph{Variables and metavariables for variables}

For any matching logic theory $\mathsf{T} = (S, \Sigma, A)$, it comes for each sort $s \in S$ a countably infinite set $V_s$ of variables. We use $\mathsf{x:s}, \mathsf{y:s}, \mathsf{z:s}, \dots$ for variables in $V_s$, and omit their sorts when that is clear from the contexts. Different sorts have disjoint sets of variables, so $\mathrm{Var}_s \cap \mathrm{Var}_{s'} = \emptyset$ if $s \neq s'$.



\begin{proposition}
\label{prop:explicitly_universal_quantified_justification}
Let $A$ be a set of axioms and $\bar{A} = \forall A$ be the universal quantification closure of $A$, then for any pattern $\varphi$, $A \vdash \varphi$ iff $\bar{A} \vdash \varphi$.
\end{proposition}

\begin{remark}[Free variables in axioms]
\label{rmk:free_variables_in_axioms_are_universal_quantified}
The free variables appearing in the axioms of a theory can be regarded as implicitly universal quantified, because a theory and its universal quantification closure are equal.
\end{remark}

\begin{example}
  \begin{align*}
  A_1 &= \{{\sf mult(x, 0) = 0}\} \\
  A_2 &= \{{\sf \forall x . mult(x, 0) = 0}\} \\
  A_3 &= \{{\sf \forall y . mult(y, 0) = 0}\} \\
  A_4 &= \{\mathsf{mult}(x, \mathsf{0}) = \mathsf{0}\} \\
  A_5 &= \{\forall x . \mathsf{mult}(x, \mathsf{0}) = \mathsf{0}\} \\
  A_6 &= \{\forall y . \mathsf{mult}(y, \mathsf{0}) = \mathsf{0}\} \\
  A_7 &= \{{\sf mult(x, 0) = 0, mult(y, 0) = 0, mult(z, 0) = 0, \dots}\} \\
  A_8 &= \{{\sf \forall x . mult(x, 0) = 0, \forall y . mult(y, 0) = 0, \forall z . mult(z, 0) = 0, \dots}\}
  \end{align*}
  
  All the eight theories are equal. Theories $A_4, A_5, A_6$ are finite representations of theories $A_7, A_8, A_8$ respectively. 
\end{example}

\begin{remark}
\label{no_need_to_have_metavariables_for_variables}
There is no need to have metavariables for variables in the Kore language, because (1) if they are used as bound variables, then replacing them with any (matching logic) variables will result in the same theories, thanks to alpha-renaming; and (2) if they are used as free variables, then it makes no difference to consider the universal quantification closure of them and we get to the case (1). 
\comment{\sout{Given said that, there are cases when metavariables for variables make sense. In those cases we often want our metavariables to range over all variables of all sorts, in order to make our Kore definitions compact.} No, we do not need metavariables over variables. I was thinking of the definedness symbols. We might want to write only one axiom schema of $\ceil{x}$ instead many $\ceil{x \cln s}_s^{s'}$'s, but we cannot do that unless we allow polymorphic and overloaded symbols in Kore definitions.}
\end{remark}


\paragraph{Patterns and metavariables for patterns}

It is in practice more common to use metavariables that range over all patterns. One typical example is axiom schemata. For example, $\vdash \varphi \to \varphi$ in which $\varphi$ is the metavariable that ranges all well-formed patterns. 

\comment{There has been an argument on whether metavariables for patterns should be sorted or not. Here are some observations. Firstly, since all symbols are decorated and not overloaded, in most cases, the sort of a metavariable for patterns can be inferred from its context. Secondly, the only counterexample against the first point that I can think of is when they appear alone, which is not an interesting case anyway. Thirdly, we do want the least amount of reasoning and inferring in using Kore definitions, so it breaks nothing if not helping things to have metavariables for patterns carrying their sorts.}

\begin{example}
\begin{align*}
A_1 &= \{{\sf merge(h1, h2) = merge(h2, h1)}\} \\
A_2 &= \{{\sf \forall h1 \forall h2 . merge(h1, h2) = merge(h2, h1)}\} \\
A_3 &= \{\mathsf{merge}(\varphi, \psi) = \mathsf{merge}(\psi, \varphi)\}
\end{align*}
All three theories are equal. It is easier to see that fact from a model theoretic point of view, since all theories require that the interpretation of $\mathsf{merge}$ is commutative and nothing more. On the other hand, it is not straightforward to obtain that conclusion from a proof theoretic point of view. For example, to deduce $\mathsf{merge}(\mathsf{list}(\mathsf{one}, \mathsf{cons}(\mathsf{two}, \mathsf{epsilon})), \mathsf{top}) = \mathsf{merge}(\mathsf{top}, \mathsf{list}(\mathsf{one}, \mathsf{cons}(\mathsf{two}, \mathsf{epsilon})))$ needs only one step in $A_3$, but will need a lot more in either $A_1$ or $A_2$, because one cannot simply substitute any patterns for universal quantified variables in matching logic.

\end{example}



\section{Binders}

In matching logic there is a unified representation of binders. We will be using the theory of lambda calculus $\LAMBDA$ as an example in this section. Recall that the syntax for untyped lambda calculus is
\begin{align*}
\Lambda \Coloneqq V \mid \lambda V . \Lambda \mid \Lambda \ \Lambda
\end{align*}
where $V$ is a countably infinite set of atomic $\lambda$-terms, a.k.a. variables in lambda calculus. The set of all $\lambda$-terms, denoted as $\Lambda$, is the smallest set satisfying the above grammar.

The matching logic theory $\LAMBDA$ has one sort $\mathsf{Exp}$ for lambda expressions. It also has in its signature a binary symbol $\mathsf{lambda}_0$ that builds a $\lambda$-terms, and a binary symbol $\mathsf{app}$ for lambda applications. To mimic the binding behavior of $\lambda$ in lambda calculus, we define syntactic sugar $\lambda x . e = \exists x . \mathsf{lambda}_0(x, e)$  and $e_1e_2 = \mathsf{app}(e_1, e_2)$ in theory $\LAMBDA$. Notice that by defining $\lambda$ as a syntactic sugar using the existential quantifier $\exists x$, we get alpha-renaming for free. The $\beta$-reduction is captured by the next axiom:
\begin{equation*}
(\lambda x . e)e' = e[e'/x] \quad \text{, where $e$ and $e'$ are metavariables for $\lambda$-terms.}
\end{equation*}

Two important observations are made about the ($\beta$) axiom. Firstly, $e$ and $e'$ cannot be replaced by logic variables, because $\lambda$-terms in matching logic are (often) not functional patterns. Secondly, metavariables $e$ and $e'$ cannot range over all patterns of sort $\mathsf{Exp}$, but only those which are (syntactic sugar of) $\lambda$-terms. Allowing $e$ and $e'$ to range over all patterns of $\mathsf{Exp}$ will quickly lead to an inconsistent theory, because of the next contradiction:
\begin{equation*}
\bot 
\xeq{(N)} (\lambda x . \top)[\bot]
\xeq{($\beta$)} \top.
\end{equation*}

Therefore, when defining the lambda calculus, we need a way 

\begin{theorem}[Consistency]
	Consider a theory of a binder $\alpha$, with a sort $S$ and two binary symbols $\alpha_0$ and $\_ \ \_$. Define $\alpha x . e$ as syntactic sugar of $\exists x . \alpha (x, e)$ where $x$ is a variable and $e$ is a pattern. Define $\alpha$-terms be patterns satisfying the next grammar 
	\begin{align*}
      T_\alpha &\Coloneqq V_s \mid \alpha x .T_\alpha \mid T_\alpha T_\alpha.
	\end{align*}
	If a theory contains only axioms of the form $e = e'$ where $e$ and $e'$ are $\alpha$-terms, then the theory is consistent.
\end{theorem}
\begin{proof}
	The final model $M$ exists, in which the carrier set is a singleton set, and the two symbols are interpreted as the total function over the singleton set. One can then prove that all $\alpha$-terms interpret to the total set, so all axioms hold in the final model.
\end{proof}

\begin{corollary}
	The theory $\LAMBDA$ is consistent.
\end{corollary}


\begin{definition}[Common ranges of metavariables]
\quad
\begin{itemize}
\item Full range $\mathrm{Pattern}_s$;
\item Syntactic terms range (variables plus symbols without logic connectives);
\item Ground syntactic terms range (symbols only); 
\item Variable range $\mathrm{Var}_s$ (metavariables for variables).
\end{itemize}
\end{definition}

\begin{remark}
Syntactic terms (and ground syntactic terms) are purely defined syntactically and not equal to terms or functional patterns. When all symbols are functional symbols, the set of syntactic terms equals the set of terms, and both of them are included in the set of all functional patterns. 
\end{remark}

\begin{remark}
We need to design a syntax for specifying ranges of metavariables in the Kore language. 
\end{remark}

\begin{remark}
We have not proved that matching logic is a conservative extension of untyped lambda calculus, which bothers me a lot. I will remain skeptical about everything we do in this section until we prove that conservative extension result. 
\end{remark}

\comment{The benefit of such a unified theory of binders and binding structures in matching logic is more of theoretical interest. In practice (K backends), one will never want to implement the lambda calculus by desugaring $\lambda x . e$ as $\exists x . \lambda_0(x, \varphi)$ but rather dealing with $\lambda x . \varphi$ directly. }

\begin{example}[Lambda calculus in Kore]
\quad
\begin{Verbatim}[fontsize=\small]
module LAMBDA
  import BOOL
  import META-LEVEL
  
  syntax Exp
  syntax Exp ::= app(Exp, Exp)
               | lambda0(Exp, Exp)
  
  axiom \implies(true = andBool(#isLTerm(#up(E:Exp)),
                                #isLTerm(#up(E':Exp))), 
    app(\exists(x:Exp, lambda0(x:Exp, E:Exp)), E':Exp)
      = E:Exp(E':Exp / x:Exp)
  
  // Q1: what is substitution?
  // Q2: we know #up is not a part of the logic, so what does
  //     it mean?
  
  syntax Bool ::= #isLTerm(Pattern)
  axiom #isLTerm(#variable(x:Name, s:Sort)) = true
  axiom #isLTerm(#application(
    #symbol(#name("app"), #appendSortList(...), #sort("Exp")))),
    #appendPatternList(#PatternListAsPattern(#P),
                       #PatternListAsPattern(#P')))))
  = andBool(#isLTerm(#P), #isLTerm(#P'))
  ...
endmodule
\end{Verbatim}
\end{example}

\todo[inline]{Rewriting logic}

\section{Contexts}

Introduce a binder $\gamma$ together with its application symbol which we write as~$\_[\_]$. Binding variables of the binder $\gamma$ are often written as $\square$, but in this proposal and hopefully in future work we will use regular variables $x, y, z, \dots$ instead of $\square$, in order to show that there is nothing special about contexts but simply a theory in matching logic. Patterns of the form $\gamma x . \varphi$ are often called \emph{contexts}, denoted by metavariables $C, C_0, C_1, \dots$. Patterns of the form $\varphi[\psi]$ are often called \emph{applications}. 
\begin{definition}
	The context $\gamma x . x$ is called the identity context, denoted as $\I$. Identity context has the axiom schema $\I[\varphi]=\varphi$ where $\varphi$ is any pattern.
\end{definition}

\begin{example}
	$\I[\I] = \I$.
\end{example}

\begin{definition}
	Let $\sigma \in \Sigma_{s_1\dots s_n, s}$ is an $n$-arity symbol. We say $\sigma$ is \emph{active} on its $i$th argument ($1 \le i \le n$), if
	$$\sigma(\varphi_1,\dots, C[\varphi_i], \dots, \varphi_n)
	= (\gamma x . \sigma(\varphi_1,\dots,C[x], \dots, \varphi_n))[\varphi_i],$$
	where $\varphi_1,\dots,\varphi_n$, and $C$ are any patterns. Orienting the equation from the left to the right is often called \emph{heating}, while orienting it from the right to the left is called \emph{cooling}.
\end{definition}

\begin{example} Assume the next theory of $\IMP$.
\label{example:IMP}

\begin{align*}
  A = \{&\impite(C[\varphi], \psi_1, \psi_2) = (\gamma x . \impite(C[x], \psi_1, \psi_2))[\varphi], \\
        &\impwhile(C[\varphi], \psi) = (\gamma x . \impwhile(C[x], \psi))[\varphi], \\
        &\impseq(C[\varphi], \psi) = (\gamma x . \impseq(C[x], \psi))[\varphi], \\
        &C[\impite(\imptt, \psi_1, \psi_2)] \Rightarrow C[\psi_1], \\
        &C[\impite(\impff, \psi_1, \psi_2)] \Rightarrow C[\psi_2], \\
        &C[\impwhile(\varphi, \psi)] \Rightarrow C[\impite(\varphi, \impseq(\psi, \impwhile(\varphi, \psi)), \impskip)], \\
        &C[\impseq(\impskip,\psi)] \Rightarrow C[\psi] \}.
\end{align*}

\comment{We can simply require that $\psi_1, \psi_2, \psi_3$, and $C$ are any patterns. That will allow us to do any reasoning that we need, but will that lead to inconsistency?}

\paragraph{Example \ref{example:IMP}(a).} 
	\begin{align*}
	\impseq(\impskip,\impskip)
	&= \mathsf{I}[\impseq(\impskip,\impskip)] \\
	&\Rightarrow \mathsf{I}[\impskip] \\
	&= \impskip.
	\end{align*}
	
\paragraph{Example \ref{example:IMP}(b).} 
	\begin{align*}
	\impseq(\impite(\imptt, \psi_1, \psi_2), \psi_3) 
	&= \impseq(\I[\impite(\imptt, \psi_1, \psi_2)], \psi_3) \\
	&= (\gamma x . \impseq(\I[x], \psi_3))[\impite(\imptt, \psi_1, \psi_2)] \\
	&\Rightarrow (\gamma x . \impseq(\I[x], \psi_3))[\psi_1] \\
	&= \impseq(\I[\psi_1], \psi_3) \\
	&= \impseq(\psi_1, \psi_3).
	\end{align*}
\end{example}

\begin{example}
Consider the following theory written in the Kore language:
\begin{Verbatim}
module IMP
  import ...
  syntax AExp
  syntax AExp ::= plusAExp(AExp, AExp)
  syntax AExp ::= minusAExp(AExp, AExp)
  syntax AExp ::= AExpAsNat(Nat)
  syntax BExp
  syntax BExp ::= geBExp(AExp, AExp)
  syntax BExp ::= BExpAsBool(Bool)
  syntax Pgm
  syntax Pgm  ::= skip()
  syntax Pgm  ::= seq(Pgm Pgm)
  syntax Pgm  ::= 
  syntax Heap
  syntax Cfg
  
endmodule
\end{Verbatim}

\end{example}


\begin{example}
Following the above example, extend $A$ with the next axioms:
\begin{align*}
  \{&C[x][\impmapsto(x, v)] \Rightarrow C[v][\impmapsto(x, v)], \\
    &C[\impasgn(x, v)][\impmapsto(x, v')] \Rightarrow C[\impskip][\impmapsto(x,v)], \\
    &C[\impasgn(x, v)][\varphi] \Rightarrow C[\impskip][\impmerge(\varphi, \impmapsto(x, v))]\}
\end{align*}
\end{example}
\comment{The above example is meant to show the loopup rule, but it does not work because the third axiom is incorrect. Instead of simply writing $\varphi$, we should say that $\varphi$ does not assign any value to $x$. One solution (that is used in the current K backend) is to introduce a strategy language and to extend theories with strategies. }

\begin{example}
	Suppose $f$ and $g$ are binary symbols who are active on their first argument. Suppose $a, b$ are constants, and $x$ is a variable. Let $\square_1$ and $\square_2$ be two hole variables. Define two contexts $C_1 = \gamma \square_1 . f(\square_1, a)$ and $C_2 = \gamma \square_2 . g(\square_2, b)$. 
	
	Because $f$ is active on the first argument, 
	\begin{align*}
       C_1[\varphi]
       &= (\gamma \square_1 . f(\square_1, a)) [\varphi] \\
       &= (\gamma \square_1 . f(\I[\square_1], a)) [\varphi] \\
       &= f(\I[\varphi], a) \\
       &= f(\varphi, a), \text{ for any pattern $\varphi$.}
	\end{align*}
	And for the same reason, $C_2[\varphi] = g(\varphi, b)$. Then we have
	\begin{align*}
	C_1[C_2[x]]
	&= C_1[f(x,a)] \\
	&= g(f(x,a), b).
	\end{align*}
	On the other hand, 
	\begin{align*}
    g(f(x,a), b)
    &= g(C_1[x], b) \\
    &= (\gamma \square . g(C_1[\square], b))[x] \\
    &= (\gamma \square . g(f(\square, a), b))[x].
	\end{align*}
	Therefore, the context $\gamma \square . g(f(\square, a), b))$ is often called the \emph{composition} of $C_1$ and $C_2$, denoted as $C_1 \circ C_2$.

\end{example}

\begin{example}
	Suppose $f$ is a binary symbol with all its two arguments active. Suppose $C_1$ and $C_2$ are two contexts and $a, b$ are constants. Then easily we get
	\begin{align*}
	f(C_1[a],C_2[b])
	&= (\gamma \square_2 . f(C_1[a], C_2[\square_2]))[b] \\
	&= (\gamma \square_2 . ((\gamma \square_1 . f(C_1[\square_1], C_2[\square_2])) [a] )) [b].
	\end{align*}
	What happens above is similar to \emph{curring} a function that takes two arguments. It says that there exists a context $C_a$, related with $C_1, C_2, f$ and $a$ of course, such that $C_a[b]$ returns $f(C_1[a],C_2[b])$. The context $C_a$ has a binding hole $\square_2$, and a body that itself is another context $C_a'$ applied to $a$. In other words, there exists $C_a$ and $C_a'$ such that 
	\begin{itemize}
	\item $f(C_1[a],C_2[b]) = C_a[b]$,
	\item $C_a = \gamma \square_2 . (C_a'[a])$,
	\item $C_a' = \gamma \square_1 . f(C_1[\square_1], C_2[\square_2])$.
	\end{itemize}
	
	A natural question is whether there is a context $C$ such that $C[a][b] = f(C_1[a],C_2[b])$. 
\end{example}

\begin{proposition}
	$C_1[C_2[\varphi]] = C [\varphi], \text{ where } C = \gamma \square . C_1[C_2[\square]].$
\end{proposition}

\subsubsection{Normal forms}

In this section, we consider \emph{decomposition} of patterns. A decomposition of a pattern $P$ is a pair $\langle C, R \rangle $ such that $C[R] = P$. Let us now consider patterns that do not have logical connectives.

\todo[inline]{Fixed points}

\section{Appendix: The First Kore Language}

The next grammar is the firstly-proposed Kore language at \href{https://github.com/kframework/kore/wiki/KORE-Language-Syntax}{\underline{here}}.

\begin{Verbatim}[fontsize=\small]

Definition = Attributes
Set{Module}

Module = module ModuleName
Set{Sentence}
endmodule
Attributes

Sentence =  import ModuleName Attributes
| syntax Sort Attributes                           // sort declarations
| syntax Sort ::= Symbol(List{Sort}) Attributes    // symbol declarations
| rule Pattern Attributes
| axiom Pattern Attributes

Attributes = [ List{Pattern} ]

Pattern =  Variable
| Symbol(List{Pattern})                             // symbol applications
| Symbol(Value)                                     // domain values
| \top()
| \bottom()
| \and(Pattern, Pattern)
| \or(Pattern, Pattern)
| \not(Pattern)
| \implies(Pattern, Pattern)
| \exists(Variable, Pattern)
| \forall(Variable, Pattern)
| \next(Pattern)
| \rewrite(Pattern, Pattern)
| \equals(Pattern, Pattern)

Variable =  Name:Sort                                        // variables

ModuleName = RegEx1
Sort       = RegEx2
Name       = RegEx2
Symbol     = RegEx2
Value      = RegEx3

RegEx1 == [A-Z][A-Z0-9-]*
RegEx2 == [a-zA-Z0-9.@#$%^_-]+ | ` [^`]* `
RegEx3 == <Strings>   // Java-style string literals, enclosed in quotes

\end{Verbatim}
In the grammar above, {\small\verb|List{X}|} is a special non-terminal corresponding to possibly empty comma-separated lists of {\small\verb|X|} words (trivial to define in any syntax formalism). {\small\verb|Set{X}|}, on the other hand, is a special non-terminal corresponding to possibly empty space-separated sets of X words. Syntactically, there is no difference between the two (except for the separator), but Kore tools may choose to implement them differently.

\subsection{Builtin theories}

\begin{Verbatim}
module BOOL
syntax Bool
syntax Bool ::= true | false | notBool(Bool)
| andBool(Bool, Bool) | orBool(Bool, Bool)

// axioms for functional symbols
axiom \exists(T:Bool, \equals(T:Bool, true))
axiom \exists(T:Bool, \equals(T:Bool, false))
axiom \exists(T:Bool, \equals(T:Bool, \notBool(X:Bool)))
axiom \exists(T:Bool, \equals(T:Bool, andBool(X:Bool, Y:Bool)))
axiom \exists(T:Bool, \equals(T:Bool, orBool(X:Bool, Y:Bool)))

// axioms for commutativity
axiom \equals(andBool(X:Bool, Y:Bool), andBool(Y:Bool, X:Bool))
axiom \equals(orBool(X:Bool, Y:Bool), orBool(Y:Bool, X:Bool))

// the no-junk axiom for constructors
axiom \or(true, false)

axiom \equals(notBool(true), false)
axiom \equals(notBool(false), true)
axiom \equals(andBool(true, T:Bool), T:Bool)
axiom \equals(andBool(false, T:Bool), false)
axiom \equals(orBool(true, T:Bool), true)
axiom \equals(orBool(false, T:Bool), T:Bool)
endmodule
\end{Verbatim}

\begin{Verbatim}
module META-LEVEL
syntax 
endmodule
\end{Verbatim}

\begin{Verbatim}
module LAMBDA
syntax Exp
syntax Exp ::= lambda0(Exp, Exp) | app(Exp, Exp)

endmodule
\end{Verbatim}



\end{document}