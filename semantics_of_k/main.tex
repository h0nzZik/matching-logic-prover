\documentclass[UTF8]{article}

%\usepackage{xcolor}
\usepackage[pdftex,dvipsnames]{xcolor}  % Coloured text etc.
\usepackage{xargs}                      % Use more than one optional parameter in a new commands

  % Select what to do with todonotes: 
  % \usepackage[disable]{todonotes} % notes not showed
  %  \usepackage[draft]{todonotes} % notes showed
\usepackage[colorinlistoftodos,prependcaption,textsize=tiny]{todonotes}
\newcommandx{\unsure}[2][1=]{\todo[linecolor=red,backgroundcolor=red!25,bordercolor=red,#1]{#2}}
\newcommandx{\change}[2][1=]{\todo[linecolor=blue,backgroundcolor=blue!25,bordercolor=blue,#1]{#2}}
\newcommandx{\info}[2][1=]{\todo[linecolor=OliveGreen,backgroundcolor=OliveGreen!25,bordercolor=OliveGreen,#1]{#2}}
\newcommandx{\improvement}[2][1=]{\todo[linecolor=Plum,backgroundcolor=Plum!25,bordercolor=Plum,#1]{#2}}
\newcommandx{\thiswillnotshow}[2][1=]{\todo[disable,#1]{#2}}

  % Select what to do with command \comment:  
  % \newcommand{\comment}[1]
      {} %comment not showed
  \newcommand{\comment}[1]
    {\par {\bfseries \color{blue} #1 \par}} %comment showed
    
  \usepackage{amsmath}
  \usepackage{amssymb}
  
  \usepackage{amsthm}
  
  % Declare a global counter for theorem environments:
  \newcounter{thmcounter}
  
  % Define new theorem styles:
  \theoremstyle{plain}
  \newtheorem{theorem}[thmcounter]{Theorem}
  \newtheorem{corollary}[thmcounter]{Corollary}
  \newtheorem{lemma}[thmcounter]{Lemma}
  \newtheorem{proposition}[thmcounter]{Proposition}
  \theoremstyle{definition}
  \newtheorem{definition}[thmcounter]{Definition}
  \newtheorem{example}[thmcounter]{Example}
  \theoremstyle{remark}
  \newtheorem{remark}[thmcounter]{Remark}
  \newtheorem{notation}[thmcounter]{Notation}
  
  
  % Package for changing fonts in the Verbatim environment:
  \usepackage{fancyvrb}
  
  % Package for URLs:
  \usepackage{hyperref}  
  
  % Define serif fonts for ML theories used in math mode:
  \newcommand{\PA}{\mathsf{PA}}
  \newcommand{\SEQ}{\mathsf{SEQ}}
  \newcommand{\HEAP}{\mathsf{HEAP}}
  \newcommand{\IMP}{\mathsf{IMP}}
  \newcommand{\FIX}{\mathsf{FIX}}
  \newcommand{\LAMBDA}{\mathsf{LAMBDA}}
  \newcommand{\CTXT}{\mathsf{CTXT}}
  \newcommand{\DEF}{\mathsf{DEF}}
  \newcommand{\METALEVEL}{\mathsf{META-LEVEL}}
  
  % Define serif fonts for symbols:
  \newcommand{\impite}{\mathsf{ite}}
  \newcommand{\impwhile}{\mathsf{while}}
  \newcommand{\imptt}{\mathsf{tt}}
  \newcommand{\impff}{\mathsf{ff}}
  \newcommand{\impskip}{\mathsf{skip}}
  \newcommand{\impseq}{\mathsf{seq}}
  \newcommand{\impasgn}{\mathsf{asgn}}
  
  \newcommand{\impmapsto}{\mathsf{mapsto}}
  \newcommand{\impmerge}{\mathsf{merge}}
  
  \newcommand{\up}{\mathsf{\#up}}
  \newcommand{\down}{\mathsf{\#down}}
  \newcommand{\isGround}{\mathsf{isGround}}
  \newcommand{\xfalse}{\mathsf{false}}
  \newcommand{\xtrue}{\mathsf{true}}
  
  
  % Define identity context
  \newcommand{\I}{\mathsf{I}}
  
  % Define the colon ":" that is used in "x:s"
  % with less spacing around.
  \newcommand{\cln}{{:}}
 
  
  % Define ceiling and flooring symbols:
  \usepackage{mathtools}
  \DeclarePairedDelimiter{\ceil}{\lceil}{\rceil}

  % Package for underlining and strikethrough texts.
  \usepackage[normalem]{ulem}
  
  % Define text over equality
  \usepackage{mathtools}
  \newcommand{\xeq}[1]
    {\stackrel{\mathclap{\normalfont\tiny\mbox{#1}}}{=}}
    
  % Package for display-mode quotations.
  \usepackage{csquotes}
  
  % Package for double-bracket [[P]] (known as the semantics bracket)
  \usepackage{stmaryrd}
  \newcommand{\Bracket}[1]
    {\llbracket#1\rrbracket}


  % Title and authors
  \title{The Semantics of K}
  \author{Formal Systems Laboratory \\
          University of Illinois}

\begin{document}

\maketitle

\comment{Please feel free to contribute to this report in all ways.
\info{Follow the FSL rules for editing, though; e.g., <80 characters per line,
each sentence on a new line, etc.}
You could add new contents, remove redundant ones, refactor and
organize the texts, and correct typos.}

\section{Matching Logic}

\newcommand{\Var}{\textit{Var}}
\newcommand{\Nat}{\textit{Nat}}

Let us recall the basic grammar of matching logic
from~\cite{rosu-2017-lmcs}.\improvement{Add references.}
~
Let $\Var$ be a countable set of
\emph{variables}.\unsure{Not sure why you prefer to work with only one set of
variables, instead of a set $\Var_s$ for each sort $s$.}
~
Assume a matching logic \emph{signature} $(S, \Sigma)$.
For simplicity, here we assume that the sets of \emph{sorts} $S$
and of \emph{symbols} $\Sigma$ are finite.
We partition $\Sigma$ in sets of symbols
$\Sigma_{s_1 \ldots s_n, s}$ of \emph{arity} $s_1\ldots s_n,s$, where
$s_1,\ldots, s_n, s \in S$.
Then \emph{patterns} of sort $s \in S$ are generated by the following grammar:
\begin{align*}
\varphi_s \Coloneqq\  &x \cln s \quad \text{where $x \in \Var$} \\
\mid\  &\varphi_s \wedge \varphi_s \\
\mid\  &\neg \varphi_s \\
\mid\  &\exists x \cln s' . \varphi_s \quad \text{where $x \in N$ and $s' \in S$} \\
\mid\  &\sigma(\varphi_{s_1},\dots,\varphi_{s_n}) \quad \text{where $\sigma \in \Sigma$ has $n$ arguments, and \dots}
\end{align*}
The grammar above only defines the syntax of (well-formed) patterns of sort
$s$.
It says nothing about their semantics.
For example, patterns $x\cln s \wedge y \cln s$ and
$y\cln s \wedge x \cln s$ are distinct elements in the language
of the grammar, in spite of them being semantically/provably equal
in matching logic.

For notational convenience, we take the liberty to use mix-fix syntax for
operators in $\Sigma$,
parentheses for grouping, and omit variable sorts when understood.
For example, if $\Nat \in S$ and
$\_+\_, \_*\_ \in \Sigma_{\Nat \times \Nat, \Nat}$
then we may write $(x + y)*z$ instead of
$\_*\_(\_+\_(x\cln\Nat,y\cln\Nat),z\cln\Nat)$.

\improvement{I think we also need to talk about: other logical connectives
as derived, free variables, capture-free substitution, equality.
Add more as we need them.}

\comment{
\begin{remark}
The above\unsure{I think we do not need all this discussion here;
we want to keep the document clean and short, to serve as an authoritative
reference}
~\emph{is} a \href{https://en.wikipedia.org/wiki/Formal_grammar}{formal grammar}, whose semantics\footnote{Semantics as a formal grammar, not the matching logic semantics.} is well studied and crystal clear. The grammar defines for each sort $s$ exactly one set of well-formed patterns of sort $s$. We are defining a \emph{set}, that is to say, following the above grammar, one is able to (1) distinguish well-formed patterns from ill-formed ones; and (2) decide whether two well-formed patterns are the same pattern or not. The next remark provides an example of (2). 
\end{remark}

\begin{remark}
	Assume $x, y\in N$ and $s \in S$, pattern $x\cln s \wedge y \cln s$ is a well-formed pattern of sort $s$, by definition. It is also \emph{distinct} from pattern $y\cln s \wedge x \cln s$, by definition. The fact that (after introducing equalities as syntactic sugar in the logic) one can use some proof systems of matching logic and establish $$\vdash x\cln s \wedge y \cln s = y\cln s \wedge x \cln s,$$ or use the semantics of matching logic and establish $$\vDash x\cln s \wedge y \cln s = y\cln s \wedge x \cln s,$$
	has \emph{nothing} to do with the formal grammar itself and does not change the fact that $x\cln s \wedge y \cln s$ and $y\cln s \wedge x \cln s$ are two distinct patterns in matching logic. 
\end{remark}
}

%\begin{definition}[Matching Logic Theory]
%\label{ML_theory}
A matching logic \emph{theory} is a triple $(S, \Sigma, A)$ where
$(S,\Sigma)$ is a signature and $A$ is a set of patterns called \emph{axioms}.
%\end{definition}
Like in many logics, sets of patterns may be presented as \emph{schemas}
making use of meta-variables ranging over patterns, sometimes constrained
to subsets of patterns using side conditions.
For example:
$$
\begin{array}{rl}
\varphi[\varphi_1/x] \wedge (\varphi_1 = \varphi_2) \rightarrow \varphi[\varphi_2/x]
&\textrm{where $\varphi$ is any pattern and $\varphi_1$, $\varphi_2$} \\
& \textrm{are any patterns of same sort as $x$}
\\[2ex]
(\lambda x . \varphi)\varphi' = \varphi[\varphi'/x]
& \textrm{where $\varphi$, $\varphi'$ are \emph{syntactic patterns}, that is,}
\\
& \textrm{ones formed only with variables and symbols}
\\[2ex]
\varphi_1 \mathrel{\texttt{+}} \varphi_2 = \varphi_1 +_\Nat \varphi_2
& \textrm{where $\varphi$, $\varphi'$ are \emph{ground} syntactic patterns}
\\
&\textrm{of sort $\Nat$, that is, patterns built only}
\\
&\textrm{with symbols \texttt{zero} and \texttt{succ}}
\\[2ex]
(\varphi_1 \rightarrow \varphi_2) \rightarrow
(\varphi[\varphi_1 / x] \rightarrow \varphi[\varphi_2 / x])
& \textrm{where $\varphi$ is a \emph{positive context in $x$}, that is,}
\\
& \textrm{a pattern
containing only one occurrence}
\\
&\textrm{of $x$ with no negation ($\neg$) on the path to}
\\
&\textrm{$x$, and where $\varphi_1$, $\varphi_2$ are any patterns}
\\
&\textrm{having the same sort}
\end{array}
$$

One of the major goals of this paper is to propose a formal language
and an implementation, that allows us to write such pattern schemas.

\change{Let's introduce this when needed.  Also, ``equal'' is not a good word.

``Two theories are \emph{equal} if they have the same set of sorts and symbols, and they deduce the same set of theorems.''}


\section{A Calculus of Matching Logic}
In this section, we propose a calculus of matching logic.
\begin{displayquote}
	Many people have developed calculi for mathematical reasoning. 
	A calculus of logics is often called a \emph{logical framework}.
	I prefer to speak of a \emph{meta-logic} and its \emph{object-logic}. \\
	By L. Paulson, \emph{The Foundation of a Generic Theorem Prover}
\end{displayquote}

The family of equational logics have been thoroughly studied since the proposal 
paper~\cite{}.
In this proposal, we use a variant called \emph{order-sorted equational logic} 
as the meta-logic. Order-sorted equational logic is well supported by 
Maude~\cite{}, a fast rewriting engine. We use Maude's syntax to write 
equational logic theories. 
\emph{The theory of matching logic}, denoted as $M$, is an order-sorted 
equational logic defined as the next Maude functional theory.
Equations and membership equations are all labeled with the \texttt{nonexe} 
attribute, because we do not care about the executability about $U$, but simply 
use Maude's syntax to specify it. 
For simplicity, we do not provide all equations and membership equations, but 
only important ones. 

\comment{
The main task of this proposal is to find a nice way to specify (and probably reason with) matching logic theories. We spent lots of time considering the design of the Kore language, with which we specify matching logic theories, and we decided to go for meta-logic. This paragraph is a summary that serves as a justification of our choice. 

Suppose we allow users to write infinite axioms to specify theories. In that case, there is no need to go for a meta-logic, since one can always enumerate all axioms in Kore definitions, as long as they are recursively enumerable~(r.e.). Theories who do not have a r.e. set of axioms are not considered as of interest of practice. 

However, we cannot afford our definitions to run forever. We look for a finite representation of them. This is when the concept of meta-variables comes in and plays a role. And soon one realizes that we do not only need meta-variables, but also some notations in the meta-level, too, serving as methods that help us finitely represent the infinite sets of axioms we want to specify. One typical such notation is the substitution $\varphi[\psi/x]$, where $\_[\_/\_]$ is the mathematical notation, in the meta-level, for substitution, which is not part of the object-logic. Other examples include side-conditions on meta-variables and context.

We look for a generic way that helps us represent infinite axioms in a finite way. And there is a natural one. Since axioms are r.e. sets, by definition there are semi-decision procedures that define them, and semi-decision procedures have finite representation. Therefore, instead of enumerating all the axioms, one simply write down the corresponding semi-decision procedure. 

In this section, we will propose a meta-logic that serves as \emph{a logic for 
matching logic and its proof system.} We believe such as meta-logic will result 
in a direct implementation of Kore and matching logic provers. 

The meta-logic needs not to be the matching logic. In fact, it can simply be a 
rewriting logic or even equational logic, and we can write it down as a Maude 
theory. We only use Maude's syntax to specify theories in the meta-logic, so 
those Maude modules (theories) need no to be executable. In fact, we assume 
every equations are labeled with the attribute \texttt{nonexe}.

\begin{definition}[Theory of Matching Logic]
	The theory of matching logic, denoted as $U$, is a theory of meta-logic together with a lifting operator $\langle \ \cdot \ \rangle$, such that for any matching logic theory $T$ and pattern $\varphi$, 
	\begin{equation*}
	T \vdash \varphi \quad \text{iff} \quad U \vdash \langle T \vdash \varphi \rangle.
	\end{equation*}
	The theory $U$ is also called the \emph{universal theory}. 
\end{definition}



\begin{remark}
	Think of the universal theory $U$ as \emph{the theory of ASTs of patterns.}
\end{remark}
\begin{remark}
	The universal theory $U$ is like the universal Turing machine.
\end{remark}
}

\begin{Verbatim}[fontsize=\small]
  fth M is
    protecting STRING .
    
    sort Sort . subsort String < Sort .
    sort SortList .          ---- comma-separated lists
    
    sort Symbol .
    op #symbol : String      ---- unique identity / name / reference
                 SortList    ---- argument sorts
                 Sort        ---- result sort
                 -> Symbol .
    
    sorts Pattern
          PatternList .      ---- comma-separated lists

    ---- we might want to give each connectives / constructors
    ---- a sort, and make Pattern the supersort of all of them.
    ---- this will help to define some ops (e.g. getFreeVariables).
    
    op #variable : String    ---- unique identity / name / reference
                   Sort -> Pattern .
    op #and : Pattern Pattern -> Pattern .
    op #not : Pattern -> Pattern .
    op #exists : String      ---- id of binding variable
                 Sort        ---- sort of binding variable
                 Pattern -> Pattern .
    op #application : Symbol PatternList -> Pattern .
    op #value : String       ---- encoding of domain values
                Sort         ---- sort of values
                -> Pattern .
    
    op well-formed : Pattern -> Bool .
    op getSort : Pattern -> [Sort] .
    op isSort : Pattern Sort -> Bool .
    
    cmb getSort(P:Pattern) : Sort if well-formed(P:Pattern) [nonexe] .
    eq isSort(P:Pattern, S:Sort) = (getSort(P:Pattern) = S:Sort) [nonexe] .
    
    ---- getFreeVariables or getFreeVariable ?
    op getFreeVariables : Pattern 
                          -> ... .   ---- a collection of variables
    
    ---- fine-grained-controlled substitution
    op replace : Pattern     ---- the main pattern 
                 Pattern     ---- the "replace" pattern
                 Pattern     ---- the "find" pattern
                   ...       ---- some controlling arguments
                 -> Pattern .
    
    op freshName : StringList      ---- a collection of used names.
                   -> String .
    
    ---- the following is about the proof system of matching logic.
    ---- Reference: [L. Paulson] The Foundation of a Generic Theorem Prover
    
    sorts InferenceRule      ---- a function from theorems to theorems
          Tactic             ---- the "reverse" of an inference rule
          Validation         ---- the "certificate" returned by a tactic
          Tactical .         ---- control structures applied on tactics
          
    sort Theorem .           ---- patterns that can be deducted
    subsort Theorem < Pattern .
    
    ---- not finished
  endth
\end{Verbatim}

\comment{It is strongly recommend that readers of this proposal read L. 
Paulson's \emph{The Foundation of a Generic Theorem Prover}, especially Section 
2, 3, and 4.}

It remains a question whether the meta-logic faithfully captures the 
object-logic. 
To answer this question, we introduce some notations.
The double bracket $\Bracket{\_}$ is a function that maps object-patterns to 
their meta-representation in the meta-logic $M$.
The following definition is inspired by Paulson's paper (Definition 1). 
\begin{definition}
	Let $L$ be a matching logic theory and $\varphi_1,\dots,\varphi_n$ and 
	$\psi$ be patterns of $L$.
	Let $M_L$ be a meta-logic theory obtained from 	$M$ by adding operators and 
	equational axioms. 
	Then say
	\begin{itemize}
		\item $M_L$ is \emph{sound} for $L$, if for every $M_L$-proof of 
		$\Bracket{\psi}$ from $\Bracket{\varphi_1}, \dots, 
		\Bracket{\varphi_n}$, there is an $L$-proof of $\psi$ from 
		$\varphi_1,\dots,\varphi_n$.
		\item $M_L$ is \emph{complete} for $L$, if for every $L$-proof of 
		$\psi$ from $\varphi_1,\dots,\varphi_n$, there is a $M_L$-proof of 
		$\Bracket{\psi}$ from $\Bracket{\varphi_1}, \dots, \Bracket{\varphi_n}$.
		\item $M_L$ is \emph{faithful} for $L$ if it is both sound and complete.
	\end{itemize}
\end{definition}

\todo{I am working on a theorem that justifies the meta-logic. Xiaohong.}


The next example is (the meta-representation of) the theory of lambda calculus. Again, equations are assumed to have the attribute \texttt{nonexe}. 

\begin{Verbatim}
fth LAMBDA
  including META-LEVEL .
  
  ---- the following syntactic sugar is just for readability. 

  ops app lambda0 : -> Symbol .
  eq app = #symbol("app", ("Exp", "Exp"), "Exp") .
  eq lambda0 = #symbol("lambda0", ("Exp", "Exp"), "Exp") .
  
  op lambda_._ : String Pattern -> Pattern .
  eq lambda X:VariableId . E:Pattern
   = #exists(X:VariableId, "Exp", 
     #application(lambda0, (#variable(X:VariableId, "Exp"), 
                           E:Pattern)))) .
  op _[_] : Pattern Pattern -> Pattern .
  eq E1:Pattern[E2:Pattern] 
   = #application(app, (E1:Pattern, E2:Pattern))) .
   
  ---- side conditions checker
  
  op isLTerm : Pattern -> Bool .

  eq isLTerm(#variable(X:VariableId, "Exp")) = true .
  
  eq isLTerm(E1:Pattern[E2:Pattern])
   = isLTerm(E1:Pattern) and isLTerm(E2:Pattern) .
   
  eq isLTerm(lambda(X:VariableId, E:Pattern))
   = isLTerm(E:Pattern) .
  
  ---- the (Beta) axiom
  ---- we haven't defined #equal in the meta-logic yet
  ---- nor #substitute
  cmb #equal((lambda X:VariableId . E1:Pattern)[E2:Pattern],
             #substitute(...)) : Theorem
   if isLTerm(E1:Pattern) and isLTerm(E2:Pattern) .
endth
\end{Verbatim}

\section{The Kore Language}

We have a meta-logic (the equational logic) to specify everything about 
matching logic theories, including whether a pattern is well-formed, what sort 
a patter has, which patterns are deducible, free variables, fresh variables 
generation, substitution, alpha-renaming, etc. This theory of meta-level we 
have just defined provides you a universe of (meta-representations of) 
patterns, together with all kinds of operations and functions that help you do 
whatever you want, so one has full control in the meta-logic. 

On the other hand, working in the object-level is always more intuitive and friendly than working in the meta-level. The meta-level exists so that we know we are able to do everything, but it does not necessarily mean one should always go to meta-level and work there. We propose the Kore language, which provides users a friendly way to write theories in the object-level, which will eventually be desugared to the meta-logic. 

\begin{definition}[The Kore Language]
The Kore language is a language to write matching logic theories. The outcomes are called Kore definitions. Kore definitions are mainly served as the interface between a K frontend and a K backend, but a human should be able to read and write Kore definitions of simple theories, too. The Kore language is designed in a way that it can be desugared to a theory in the meta-logic in a deterministic way.
\end{definition}

\begin{definition}[Frontend]
A K frontend is an artifact that generates Kore definitions.
\end{definition}

\begin{definition}[Backend]
A K backend is an artifact that consumes a Kore definition of a theory $\mathsf{T}$ and does some work. Whatever it does can and should be algorithmically reduced to the task of proving $\mathsf{T} \vdash \varphi$ where $\varphi$ ``encodes'' that work. A K backend should justify its results by generating formal proofs that can be proof-checked by the oracle matching logic proof checker. Examples of K backends include concrete execution engines, symbolic executions engines, matching logic provers, verification tools, etc.
\end{definition}

We proposed the next Kore language syntax. 

\begin{Verbatim}
// Namespaces for sorts, variables, metavariables,
// symbols, and Kore modules.
SortId         = ...
VariableId     = ...
MetaVariableId = ...
SymbolId       = ...
ModuleId       = ...

Variable       = VariableId:SortId
MetaVariable   = MetaVariableId::SortId

Pattern        = Variable | MetaVariable
               | \and(Pattern, Pattern)
               | \not(Pattern)
               | \exists(Variable, Pattern)
               | SymbolId(List{Pattern})

Signature      = syntax SortId
               | syntax SortId ::= SymbolId(List{SortId})
               | Signature Signature

Axioms         = axiom Pattern
               | Axioms Axioms

Module         = module ModuleId
                   Signature
                   Axioms
                 endmodule
\end{Verbatim}

\subsection{Semantics of Kore}

We give Kore definitions semantics by showing how to translate (desugar) them to meta-logic theories. 

\todo[inline]{Desugaring Kore definitions to meta-logic theories. This has top priority now. Once we have that transformation, we can claim a formal semantics of Kore.}

The following rules transform Kore objects to their meta-representations. The principle is that every object-level things in Kore become ground terms in the meta-logic. Every meta-level things in Kore, for example meta-variables, become variables in the meta-logic. 

\todo[inline]{The next transformation needs to be nailed down a bit.}
\begin{Verbatim}
#up(X:Nat) => #variable("X", "Nat")
#up(X::Nat) => X:Pattern "with" isSort(X:Pattern, "Nat")
#up(\and(P, Q)) => #and(#up(P), #up(Q))
#up(\not(P)) => #not(#up(P))
#up(\exists(X:Nat, P)) => #exists("X", "Nat", #up(P))

#up(axiom P) => cmb #up(P) : Theorem if isSort(...) /\ ... .

\end{Verbatim} 

\subsection{Lambda Calculus}

\begin{Verbatim}
module LAMBDA
  syntax Exp
  syntax Exp  ::= lambda0(Exp, Exp)
                | app(Exp, Exp)
  syntax Bool ::= isLTerm(Pattern)
  axiom isLTerm(X:Exp) = true
  axiom isLTerm(\exists(X:Exp, lambda0(X:Exp, E:Exp)))
      = isLTerm(E:Exp)
  axiom isLTerm(app(E:Exp, E':Exp))
      = isLTerm(E:Exp) andBool isLTerm(E':Exp)
  axiom app(\exists(X:Exp, lambda0(X:Exp, E::Exp)), E'::Exp)
      = E::Exp[E'::Exp / X:Exp]
  requires isLTerm(E::Exp) andBool isLTerm(E'::Exp)
endmodule
\end{Verbatim}

\comment{Many discussions in the next section (Sec.4 Object-level and Meta-level) should be moved to Section 3 as examples. Sec.5 Binders and Sec.6 Contexts should also move to a subsection of Sec.3 as applications and examples. }

\section{Object-level and Meta-level}

It is an aspect of life in mathematical logics to distinguish the \emph{object-level} and \emph{meta-level} concepts. In matching logic, we put more emphasize and care on metavariables and their range, that is, the set of patterns that they stand for. It turns out that having metavariables that range over all well-formed patterns will lead us to inconsistency theories immediately. As an example, consider the ($\beta$) axiom in the matching logic theory $\LAMBDA$ of lambda calculus:
\begin{equation*}
(\lambda x . e) [e'] = e[e' / x].
\end{equation*}
If we do not put any restriction on the range of metavariables $e$ and $e'$, we have an inconsistency issue as the following reasoning shows:
\begin{align*}
\bot \xeq{(N)} (\lambda x . \top)[\bot] \xeq{($\beta$)} \top[\bot / x] = \top.
\end{align*}

Therefore, in matching logic, one should explicitly specify the range of metavariables whenever he uses them.

\begin{definition}[Restricted metavariables]
	Let $\varphi$ be a metavariable of sort $s \in S$. The range of $\varphi$ is a set of patterns of sort $s$. We write $\varphi :: R$ if the range of $\varphi$ is $R \subseteq \mathrm{Pattern}_s$.
\end{definition}

\begin{remark}[Metavariables in first-order logic]
In first-order logic, one often uses metavariables in axiom schemata, but the inconsistency issue does not arise. This is because in first-order logic, we do not need to distinguish metavariables for terms from logic variables, thanks to the next (Substitution) rule:
\begin{equation*}
\forall x . \varphi(x) \to \varphi(t).
\end{equation*}
The predicate metavariables are not a problem because there are no object level symbols on top of them. \comment{I don't get the point of predicate metavariables.}
\end{remark}

\paragraph{Variables and metavariables for variables}

For any matching logic theory $\mathsf{T} = (S, \Sigma, A)$, it comes for each sort $s \in S$ a countably infinite set $V_s$ of variables. We use $\mathsf{x:s}, \mathsf{y:s}, \mathsf{z:s}, \dots$ for variables in $V_s$, and omit their sorts when that is clear from the contexts. Different sorts have disjoint sets of variables, so $\mathrm{Var}_s \cap \mathrm{Var}_{s'} = \emptyset$ if $s \neq s'$.



\begin{proposition}
\label{prop:explicitly_universal_quantified_justification}
Let $A$ be a set of axioms and $\bar{A} = \forall A$ be the universal quantification closure of $A$, then for any pattern $\varphi$, $A \vdash \varphi$ iff $\bar{A} \vdash \varphi$.
\end{proposition}

\begin{remark}[Free variables in axioms]
\label{rmk:free_variables_in_axioms_are_universal_quantified}
The free variables appearing in the axioms of a theory can be regarded as implicitly universal quantified, because a theory and its universal quantification closure are equal.
\end{remark}

\begin{example}
  \begin{align*}
  A_1 &= \{{\sf mult(x, 0) = 0}\} \\
  A_2 &= \{{\sf \forall x . mult(x, 0) = 0}\} \\
  A_3 &= \{{\sf \forall y . mult(y, 0) = 0}\} \\
  A_4 &= \{\mathsf{mult}(x, \mathsf{0}) = \mathsf{0}\} \\
  A_5 &= \{\forall x . \mathsf{mult}(x, \mathsf{0}) = \mathsf{0}\} \\
  A_6 &= \{\forall y . \mathsf{mult}(y, \mathsf{0}) = \mathsf{0}\} \\
  A_7 &= \{{\sf mult(x, 0) = 0, mult(y, 0) = 0, mult(z, 0) = 0, \dots}\} \\
  A_8 &= \{{\sf \forall x . mult(x, 0) = 0, \forall y . mult(y, 0) = 0, \forall z . mult(z, 0) = 0, \dots}\}
  \end{align*}
  
  All the eight theories are equal. Theories $A_4, A_5, A_6$ are finite representations of theories $A_7, A_8, A_8$ respectively. 
\end{example}

\begin{remark}
\label{no_need_to_have_metavariables_for_variables}
There is no need to have metavariables for variables in the Kore language, because (1) if they are used as bound variables, then replacing them with any (matching logic) variables will result in the same theories, thanks to alpha-renaming; and (2) if they are used as free variables, then it makes no difference to consider the universal quantification closure of them and we get to the case (1). 
\comment{\sout{Given said that, there are cases when metavariables for variables make sense. In those cases we often want our metavariables to range over all variables of all sorts, in order to make our Kore definitions compact.} No, we do not need metavariables over variables. I was thinking of the definedness symbols. We might want to write only one axiom schema of $\ceil{x}$ instead many $\ceil{x \cln s}_s^{s'}$'s, but we cannot do that unless we allow polymorphic and overloaded symbols in Kore definitions.}
\end{remark}


\paragraph{Patterns and metavariables for patterns}

It is in practice more common to use metavariables that range over all patterns. One typical example is axiom schemata. For example, $\vdash \varphi \to \varphi$ in which $\varphi$ is the metavariable that ranges all well-formed patterns. 

\comment{There has been an argument on whether metavariables for patterns should be sorted or not. Here are some observations. Firstly, since all symbols are decorated and not overloaded, in most cases, the sort of a metavariable for patterns can be inferred from its context. Secondly, the only counterexample against the first point that I can think of is when they appear alone, which is not an interesting case anyway. Thirdly, we do want the least amount of reasoning and inferring in using Kore definitions, so it breaks nothing if not helping things to have metavariables for patterns carrying their sorts.}

\begin{example}
\begin{align*}
A_1 &= \{{\sf merge(h1, h2) = merge(h2, h1)}\} \\
A_2 &= \{{\sf \forall h1 \forall h2 . merge(h1, h2) = merge(h2, h1)}\} \\
A_3 &= \{\mathsf{merge}(\varphi, \psi) = \mathsf{merge}(\psi, \varphi)\}
\end{align*}
All three theories are equal. It is easier to see that fact from a model theoretic point of view, since all theories require that the interpretation of $\mathsf{merge}$ is commutative and nothing more. On the other hand, it is not straightforward to obtain that conclusion from a proof theoretic point of view. For example, to deduce $\mathsf{merge}(\mathsf{list}(\mathsf{one}, \mathsf{cons}(\mathsf{two}, \mathsf{epsilon})), \mathsf{top}) = \mathsf{merge}(\mathsf{top}, \mathsf{list}(\mathsf{one}, \mathsf{cons}(\mathsf{two}, \mathsf{epsilon})))$ needs only one step in $A_3$, but will need a lot more in either $A_1$ or $A_2$, because one cannot simply substitute any patterns for universal quantified variables in matching logic.

\end{example}



\section{Binders}

In matching logic there is a unified representation of binders. We will be using the theory of lambda calculus $\LAMBDA$ as an example in this section. Recall that the syntax for untyped lambda calculus is
\begin{align*}
\Lambda \Coloneqq V \mid \lambda V . \Lambda \mid \Lambda \ \Lambda
\end{align*}
where $V$ is a countably infinite set of atomic $\lambda$-terms, a.k.a. variables in lambda calculus. The set of all $\lambda$-terms, denoted as $\Lambda$, is the smallest set satisfying the above grammar.

The matching logic theory $\LAMBDA$ has one sort $\mathsf{Exp}$ for lambda expressions. It also has in its signature a binary symbol $\mathsf{lambda}_0$ that builds a $\lambda$-terms, and a binary symbol $\mathsf{app}$ for lambda applications. To mimic the binding behavior of $\lambda$ in lambda calculus, we define syntactic sugar $\lambda x . e = \exists x . \mathsf{lambda}_0(x, e)$  and $e_1e_2 = \mathsf{app}(e_1, e_2)$ in theory $\LAMBDA$. Notice that by defining $\lambda$ as a syntactic sugar using the existential quantifier $\exists x$, we get alpha-renaming for free. The $\beta$-reduction is captured by the next axiom:
\begin{equation*}
(\lambda x . e)e' = e[e'/x] \quad \text{, where $e$ and $e'$ are metavariables for $\lambda$-terms.}
\end{equation*}

Two important observations are made about the ($\beta$) axiom. Firstly, $e$ and $e'$ cannot be replaced by logic variables, because $\lambda$-terms in matching logic are (often) not functional patterns. Secondly, metavariables $e$ and $e'$ cannot range over all patterns of sort $\mathsf{Exp}$, but only those which are (syntactic sugar of) $\lambda$-terms. Allowing $e$ and $e'$ to range over all patterns of $\mathsf{Exp}$ will quickly lead to an inconsistent theory, because of the next contradiction:
\begin{equation*}
\bot 
\xeq{(N)} (\lambda x . \top)[\bot]
\xeq{($\beta$)} \top.
\end{equation*}

Therefore, when defining the lambda calculus, we need a way 

\begin{theorem}[Consistency]
	Consider a theory of a binder $\alpha$, with a sort $S$ and two binary symbols $\alpha_0$ and $\_ \ \_$. Define $\alpha x . e$ as syntactic sugar of $\exists x . \alpha (x, e)$ where $x$ is a variable and $e$ is a pattern. Define $\alpha$-terms be patterns satisfying the next grammar 
	\begin{align*}
      T_\alpha &\Coloneqq V_s \mid \alpha x .T_\alpha \mid T_\alpha T_\alpha.
	\end{align*}
	If a theory contains only axioms of the form $e = e'$ where $e$ and $e'$ are $\alpha$-terms, then the theory is consistent.
\end{theorem}
\begin{proof}
	The final model $M$ exists, in which the carrier set is a singleton set, and the two symbols are interpreted as the total function over the singleton set. One can then prove that all $\alpha$-terms interpret to the total set, so all axioms hold in the final model.
\end{proof}

\begin{corollary}
	The theory $\LAMBDA$ is consistent.
\end{corollary}


\begin{definition}[Common ranges of metavariables]
\quad
\begin{itemize}
\item Full range $\mathrm{Pattern}_s$;
\item Syntactic terms range (variables plus symbols without logic connectives);
\item Ground syntactic terms range (symbols only); 
\item Variable range $\mathrm{Var}_s$ (metavariables for variables).
\end{itemize}
\end{definition}

\begin{remark}
Syntactic terms (and ground syntactic terms) are purely defined syntactically and not equal to terms or functional patterns. When all symbols are functional symbols, the set of syntactic terms equals the set of terms, and both of them are included in the set of all functional patterns. 
\end{remark}

\begin{remark}
We need to design a syntax for specifying ranges of metavariables in the Kore language. 
\end{remark}

\begin{remark}
We have not proved that matching logic is a conservative extension of untyped lambda calculus, which bothers me a lot. I will remain skeptical about everything we do in this section until we prove that conservative extension result. 
\end{remark}

\comment{The benefit of such a unified theory of binders and binding structures in matching logic is more of theoretical interest. In practice (K backends), one will never want to implement the lambda calculus by desugaring $\lambda x . e$ as $\exists x . \lambda_0(x, \varphi)$ but rather dealing with $\lambda x . \varphi$ directly. }

\begin{example}[Lambda calculus in Kore]
\quad
\begin{Verbatim}[fontsize=\small]
module LAMBDA
  import BOOL
  import META-LEVEL
  
  syntax Exp
  syntax Exp ::= app(Exp, Exp)
               | lambda0(Exp, Exp)
  
  axiom \implies(true = andBool(#isLTerm(#up(E:Exp)),
                                #isLTerm(#up(E':Exp))), 
    app(\exists(x:Exp, lambda0(x:Exp, E:Exp)), E':Exp)
      = E:Exp(E':Exp / x:Exp)
  
  // Q1: what is substitution?
  // Q2: we know #up is not a part of the logic, so what does
  //     it mean?
  
  syntax Bool ::= #isLTerm(Pattern)
  axiom #isLTerm(#variable(x:Name, s:Sort)) = true
  axiom #isLTerm(#application(
    #symbol(#name("app"), #appendSortList(...), #sort("Exp")))),
    #appendPatternList(#PatternListAsPattern(#P),
                       #PatternListAsPattern(#P')))))
  = andBool(#isLTerm(#P), #isLTerm(#P'))
  ...
endmodule
\end{Verbatim}
\end{example}

\todo[inline]{Rewriting logic}

\section{Contexts}

Introduce a binder $\gamma$ together with its application symbol which we write as~$\_[\_]$. Binding variables of the binder $\gamma$ are often written as $\square$, but in this proposal and hopefully in future work we will use regular variables $x, y, z, \dots$ instead of $\square$, in order to show that there is nothing special about contexts but simply a theory in matching logic. Patterns of the form $\gamma x . \varphi$ are often called \emph{contexts}, denoted by metavariables $C, C_0, C_1, \dots$. Patterns of the form $\varphi[\psi]$ are often called \emph{applications}. 
\begin{definition}
	The context $\gamma x . x$ is called the identity context, denoted as $\I$. Identity context has the axiom schema $\I[\varphi]=\varphi$ where $\varphi$ is any pattern.
\end{definition}

\begin{example}
	$\I[\I] = \I$.
\end{example}

\begin{definition}
	Let $\sigma \in \Sigma_{s_1\dots s_n, s}$ is an $n$-arity symbol. We say $\sigma$ is \emph{active} on its $i$th argument ($1 \le i \le n$), if
	$$\sigma(\varphi_1,\dots, C[\varphi_i], \dots, \varphi_n)
	= (\gamma x . \sigma(\varphi_1,\dots,C[x], \dots, \varphi_n))[\varphi_i],$$
	where $\varphi_1,\dots,\varphi_n$, and $C$ are any patterns. Orienting the equation from the left to the right is often called \emph{heating}, while orienting it from the right to the left is called \emph{cooling}.
\end{definition}

\begin{example} Assume the next theory of $\IMP$.
\label{example:IMP}

\begin{align*}
  A = \{&\impite(C[\varphi], \psi_1, \psi_2) = (\gamma x . \impite(C[x], \psi_1, \psi_2))[\varphi], \\
        &\impwhile(C[\varphi], \psi) = (\gamma x . \impwhile(C[x], \psi))[\varphi], \\
        &\impseq(C[\varphi], \psi) = (\gamma x . \impseq(C[x], \psi))[\varphi], \\
        &C[\impite(\imptt, \psi_1, \psi_2)] \Rightarrow C[\psi_1], \\
        &C[\impite(\impff, \psi_1, \psi_2)] \Rightarrow C[\psi_2], \\
        &C[\impwhile(\varphi, \psi)] \Rightarrow C[\impite(\varphi, \impseq(\psi, \impwhile(\varphi, \psi)), \impskip)], \\
        &C[\impseq(\impskip,\psi)] \Rightarrow C[\psi] \}.
\end{align*}

\comment{We can simply require that $\psi_1, \psi_2, \psi_3$, and $C$ are any patterns. That will allow us to do any reasoning that we need, but will that lead to inconsistency?}

\paragraph{Example \ref{example:IMP}(a).} 
	\begin{align*}
	\impseq(\impskip,\impskip)
	&= \mathsf{I}[\impseq(\impskip,\impskip)] \\
	&\Rightarrow \mathsf{I}[\impskip] \\
	&= \impskip.
	\end{align*}
	
\paragraph{Example \ref{example:IMP}(b).} 
	\begin{align*}
	\impseq(\impite(\imptt, \psi_1, \psi_2), \psi_3) 
	&= \impseq(\I[\impite(\imptt, \psi_1, \psi_2)], \psi_3) \\
	&= (\gamma x . \impseq(\I[x], \psi_3))[\impite(\imptt, \psi_1, \psi_2)] \\
	&\Rightarrow (\gamma x . \impseq(\I[x], \psi_3))[\psi_1] \\
	&= \impseq(\I[\psi_1], \psi_3) \\
	&= \impseq(\psi_1, \psi_3).
	\end{align*}
\end{example}

\begin{example}
Consider the following theory written in the Kore language:
\begin{Verbatim}
module IMP
  import ...
  syntax AExp
  syntax AExp ::= plusAExp(AExp, AExp)
  syntax AExp ::= minusAExp(AExp, AExp)
  syntax AExp ::= AExpAsNat(Nat)
  syntax BExp
  syntax BExp ::= geBExp(AExp, AExp)
  syntax BExp ::= BExpAsBool(Bool)
  syntax Pgm
  syntax Pgm  ::= skip()
  syntax Pgm  ::= seq(Pgm Pgm)
  syntax Pgm  ::= 
  syntax Heap
  syntax Cfg
  
endmodule
\end{Verbatim}

\end{example}


\begin{example}
Following the above example, extend $A$ with the next axioms:
\begin{align*}
  \{&C[x][\impmapsto(x, v)] \Rightarrow C[v][\impmapsto(x, v)], \\
    &C[\impasgn(x, v)][\impmapsto(x, v')] \Rightarrow C[\impskip][\impmapsto(x,v)], \\
    &C[\impasgn(x, v)][\varphi] \Rightarrow C[\impskip][\impmerge(\varphi, \impmapsto(x, v))]\}
\end{align*}
\end{example}
\comment{The above example is meant to show the loopup rule, but it does not work because the third axiom is incorrect. Instead of simply writing $\varphi$, we should say that $\varphi$ does not assign any value to $x$. One solution (that is used in the current K backend) is to introduce a strategy language and to extend theories with strategies. }

\begin{example}
	Suppose $f$ and $g$ are binary symbols who are active on their first argument. Suppose $a, b$ are constants, and $x$ is a variable. Let $\square_1$ and $\square_2$ be two hole variables. Define two contexts $C_1 = \gamma \square_1 . f(\square_1, a)$ and $C_2 = \gamma \square_2 . g(\square_2, b)$. 
	
	Because $f$ is active on the first argument, 
	\begin{align*}
       C_1[\varphi]
       &= (\gamma \square_1 . f(\square_1, a)) [\varphi] \\
       &= (\gamma \square_1 . f(\I[\square_1], a)) [\varphi] \\
       &= f(\I[\varphi], a) \\
       &= f(\varphi, a), \text{ for any pattern $\varphi$.}
	\end{align*}
	And for the same reason, $C_2[\varphi] = g(\varphi, b)$. Then we have
	\begin{align*}
	C_1[C_2[x]]
	&= C_1[f(x,a)] \\
	&= g(f(x,a), b).
	\end{align*}
	On the other hand, 
	\begin{align*}
    g(f(x,a), b)
    &= g(C_1[x], b) \\
    &= (\gamma \square . g(C_1[\square], b))[x] \\
    &= (\gamma \square . g(f(\square, a), b))[x].
	\end{align*}
	Therefore, the context $\gamma \square . g(f(\square, a), b))$ is often called the \emph{composition} of $C_1$ and $C_2$, denoted as $C_1 \circ C_2$.

\end{example}

\begin{example}
	Suppose $f$ is a binary symbol with all its two arguments active. Suppose $C_1$ and $C_2$ are two contexts and $a, b$ are constants. Then easily we get
	\begin{align*}
	f(C_1[a],C_2[b])
	&= (\gamma \square_2 . f(C_1[a], C_2[\square_2]))[b] \\
	&= (\gamma \square_2 . ((\gamma \square_1 . f(C_1[\square_1], C_2[\square_2])) [a] )) [b].
	\end{align*}
	What happens above is similar to \emph{curring} a function that takes two arguments. It says that there exists a context $C_a$, related with $C_1, C_2, f$ and $a$ of course, such that $C_a[b]$ returns $f(C_1[a],C_2[b])$. The context $C_a$ has a binding hole $\square_2$, and a body that itself is another context $C_a'$ applied to $a$. In other words, there exists $C_a$ and $C_a'$ such that 
	\begin{itemize}
	\item $f(C_1[a],C_2[b]) = C_a[b]$,
	\item $C_a = \gamma \square_2 . (C_a'[a])$,
	\item $C_a' = \gamma \square_1 . f(C_1[\square_1], C_2[\square_2])$.
	\end{itemize}
	
	A natural question is whether there is a context $C$ such that $C[a][b] = f(C_1[a],C_2[b])$. 
\end{example}

\begin{proposition}
	$C_1[C_2[\varphi]] = C [\varphi], \text{ where } C = \gamma \square . C_1[C_2[\square]].$
\end{proposition}

\subsubsection{Normal forms}

In this section, we consider \emph{decomposition} of patterns. A decomposition of a pattern $P$ is a pair $\langle C, R \rangle $ such that $C[R] = P$. Let us now consider patterns that do not have logical connectives.

\todo[inline]{Fixed points}

\section{Appendix: The First Kore Language}

The next grammar is the firstly-proposed Kore language at \href{https://github.com/kframework/kore/wiki/KORE-Language-Syntax}{\underline{here}}.

\begin{Verbatim}[fontsize=\small]

Definition = Attributes
Set{Module}

Module = module ModuleName
Set{Sentence}
endmodule
Attributes

Sentence =  import ModuleName Attributes
| syntax Sort Attributes                           // sort declarations
| syntax Sort ::= Symbol(List{Sort}) Attributes    // symbol declarations
| rule Pattern Attributes
| axiom Pattern Attributes

Attributes = [ List{Pattern} ]

Pattern =  Variable
| Symbol(List{Pattern})                             // symbol applications
| Symbol(Value)                                     // domain values
| \top()
| \bottom()
| \and(Pattern, Pattern)
| \or(Pattern, Pattern)
| \not(Pattern)
| \implies(Pattern, Pattern)
| \exists(Variable, Pattern)
| \forall(Variable, Pattern)
| \next(Pattern)
| \rewrite(Pattern, Pattern)
| \equals(Pattern, Pattern)

Variable =  Name:Sort                                        // variables

ModuleName = RegEx1
Sort       = RegEx2
Name       = RegEx2
Symbol     = RegEx2
Value      = RegEx3

RegEx1 == [A-Z][A-Z0-9-]*
RegEx2 == [a-zA-Z0-9.@#$%^_-]+ | ` [^`]* `
RegEx3 == <Strings>   // Java-style string literals, enclosed in quotes

\end{Verbatim}
In the grammar above, {\small\verb|List{X}|} is a special non-terminal corresponding to possibly empty comma-separated lists of {\small\verb|X|} words (trivial to define in any syntax formalism). {\small\verb|Set{X}|}, on the other hand, is a special non-terminal corresponding to possibly empty space-separated sets of X words. Syntactically, there is no difference between the two (except for the separator), but Kore tools may choose to implement them differently.

\subsection{Builtin theories}

\begin{Verbatim}
module BOOL
syntax Bool
syntax Bool ::= true | false | notBool(Bool)
| andBool(Bool, Bool) | orBool(Bool, Bool)

// axioms for functional symbols
axiom \exists(T:Bool, \equals(T:Bool, true))
axiom \exists(T:Bool, \equals(T:Bool, false))
axiom \exists(T:Bool, \equals(T:Bool, \notBool(X:Bool)))
axiom \exists(T:Bool, \equals(T:Bool, andBool(X:Bool, Y:Bool)))
axiom \exists(T:Bool, \equals(T:Bool, orBool(X:Bool, Y:Bool)))

// axioms for commutativity
axiom \equals(andBool(X:Bool, Y:Bool), andBool(Y:Bool, X:Bool))
axiom \equals(orBool(X:Bool, Y:Bool), orBool(Y:Bool, X:Bool))

// the no-junk axiom for constructors
axiom \or(true, false)

axiom \equals(notBool(true), false)
axiom \equals(notBool(false), true)
axiom \equals(andBool(true, T:Bool), T:Bool)
axiom \equals(andBool(false, T:Bool), false)
axiom \equals(orBool(true, T:Bool), true)
axiom \equals(orBool(false, T:Bool), T:Bool)
endmodule
\end{Verbatim}

\begin{Verbatim}
module META-LEVEL
syntax 
endmodule
\end{Verbatim}

\begin{Verbatim}
module LAMBDA
syntax Exp
syntax Exp ::= lambda0(Exp, Exp) | app(Exp, Exp)

endmodule
\end{Verbatim}



\end{document}