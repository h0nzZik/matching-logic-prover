\documentclass{article}
  \usepackage{xcolor}

  % Select what to do with todonotes: 
  % \usepackage[disable]{todonotes} % notes not showed
  \usepackage[draft]{todonotes} % notes showed

  % Select what to do with command \comment:  
  % \newcommand{\comment}[1]
      {} %comment not showed
  \newcommand{\comment}[1]
    {\par {\bfseries \color{blue} #1 \par}} %comment showed
    
  \usepackage{amsmath}
  \usepackage{amssymb}
  
  \usepackage{amsthm}
  
  % Declare a global counter for theorem environments:
  \newcounter{thmcounter}
  
  % Define new theorem styles:
  \theoremstyle{plain}
  \newtheorem{theorem}[thmcounter]{Theorem}
  \newtheorem{lemma}[thmcounter]{Lemma}
  \newtheorem{proposition}[thmcounter]{Proposition}
  \theoremstyle{definition}
  \newtheorem{definition}[thmcounter]{Definition}
  \newtheorem{example}[thmcounter]{Example}
  \theoremstyle{remark}
  \newtheorem{remark}[thmcounter]{Remark}
  \newtheorem{notation}[thmcounter]{Notation}
  
  % Define serif fonts for ML theories used in math mode:
  \newcommand{\PA}{\mathsf{PA}}
  \newcommand{\SEQ}{\mathsf{SEQ}}
  \newcommand{\HEAP}{\mathsf{HEAP}}
  \newcommand{\IMP}{\mathsf{IMP}}
  \newcommand{\FIX}{\mathsf{FIX}}
  \newcommand{\LAMBDA}{\mathsf{LAMBDA}}
  \newcommand{\CTXT}{\mathsf{CTXT}}
  \newcommand{\DEF}{\mathsf{DEF}}
  
  % Define identity context
  \newcommand{\I}{\mathsf{I}}
  
  % Define the colon ":" that is used in "x:s"
  % with less spacing around.
  \newcommand{\cln}{{:}}
  
  % Define ceiling and flooring symbols:
  \usepackage{mathtools}
  \DeclarePairedDelimiter{\ceil}{\lceil}{\rceil}

  % Package for underlining and strikethrough texts.
  \usepackage[normalem]{ulem}
  
  % Define text over equality
  \usepackage{mathtools}
  \newcommand\xeq[1]
    {\stackrel{\mathclap{\normalfont\tiny\mbox{#1}}}{=}}


  % Title and authors
  \title{The Semantics of K}
  \author{Formal Systems Laboratory \\
          University of Illinois}

\begin{document}

\maketitle

\comment{Please feel free to contribute to this report in all ways. You could add new contents, remove redundant ones, refactor and organize the texts, and correct typos.} 

\begin{definition}[Matching Logic Theory]
\label{ML_theory}
A matching logic theory $(S, \Sigma, A)$ is a triple that contains a nonempty finite set of sorts, a finite set of symbols, and a recursive set of axioms. Two theories are \emph{equal} if they have the same set of sorts and symbols, and they deduce the same set of theorems.
\end{definition}

\begin{example}
We use {\sf serif fonts} to denote matching logic theories. Some of the commonly used ones are the theory (theories) of definedness $\DEF$, the theory of Presburger arithmetic $\PA$, the theory of sequences of natural numbers $\SEQ$, the theory of memory heaps $\HEAP$, the theory of {IMP} programs $\IMP$, the theory (theories) of fixed-points $\FIX$, and the theory (theories) of contexts $\CTXT$.
\end{example}


\begin{definition}[The Kore Language]
\comment{We haven't come to an agreement on the syntax of the Kore language yet. One could, though, refer to the Kore text representation at the wiki page at kframework repos on Github, whose link I cannot find any more, which is considered as the first step towards that direction.}
The Kore language is a language to write matching logic theories. The outcomes are called Kore definitions. Kore definitions are mainly served as the interface between a K frontend and a K backend, but a human should be able to read and write Kore definitions of simple theories, too. The Kore language is designed in a way that:
\begin{itemize}
\item Every Kore definition defines exactly one matching logic theory;
\item Every matching logic theory can be defined as a Kore definition;
\item There is no parsing ambiguity.
\item The least amount of inferring is needed;
\item Symbols are decorated with their argument sorts and result sort;
\item There is no polymorphic or overloaded symbols, so every symbol has a unique name (reference). 
\comment{The above two points will lead to some redundancy in Kore definitions, though. For example, there will be $n^2$ definedness symbol if there are $n$ sorts in the theory. Similarly, $n^2$ equalities are need, too.}
\item User-defined (matching logic) variables are allowed as in theory $\LAMBDA$. We shouldn't fix a syntax for variables. Please refer to later sections about theory $\LAMBDA$ for more discussions.
\item And more \dots
\end{itemize}
\end{definition}

\begin{definition}[Frontend]
A K frontend is an artifact that generates Kore definitions.
\end{definition}

\begin{definition}[Backend]
A K backend is an artifact that consumes a Kore definition of a theory $\mathsf{T}$ and does some work. Whatever it does can and should be algorithmically reduced to the task of proving $\mathsf{T} \vdash \varphi$ where $\varphi$ ``encodes'' that work. A K backend should justify its results by generating formal proofs that can be proof-checked by the oracle matching logic proof checker.
\end{definition}

\section{Object-level and meta-level}

It is an aspect of life in mathematical logics to distinguish the \emph{object-level} and \emph{meta-level} concepts. The basic principle is to use serif fonts letters ($\mathsf{x}$) for object-level concepts and normal math fonts letters for meta-level concepts ($x$). 

\paragraph{Variables and metavariables for variables}

For any matching logic theory $\mathsf{T} = (S, \Sigma, A)$, it comes for each sort $s \in S$ a countably infinite set $V_s$ of variables. We use $\mathsf{x:s}, \mathsf{y:s}, \mathsf{z:s}, \dots$ for variables in $V_s$, and omit their sorts when that is clear from the contexts. Different sorts have disjoint sets of variables, so $\mathrm{Var}_s \cap \mathrm{Var}_{s'} = \emptyset$ if $s \neq s'$.



\begin{proposition}
\label{prop:explicitly_universal_quantified_justification}
Let $A$ be a set of axioms and $\bar{A} = \forall A$ be the universal quantification closure of $A$, then for any pattern $\varphi$, $A \vdash \varphi$ iff $\bar{A} \vdash \varphi$.
\end{proposition}

\begin{remark}[Free variables in axioms]
\label{rmk:free_variables_in_axioms_are_universal_quantified}
The free variables appearing in the axioms of a theory can be regarded as implicitly universal quantified, because a theory and its universal quantification closure are equal.
\end{remark}

\begin{example}
  \begin{align*}
  A_1 &= \{{\sf mult(x, 0) = 0}\} \\
  A_2 &= \{{\sf \forall x . mult(x, 0) = 0}\} \\
  A_3 &= \{{\sf \forall y . mult(y, 0) = 0}\} \\
  A_4 &= \{\mathsf{mult}(x, \mathsf{0}) = \mathsf{0}\} \\
  A_5 &= \{\forall x . \mathsf{mult}(x, \mathsf{0}) = \mathsf{0}\} \\
  A_6 &= \{\forall y . \mathsf{mult}(y, \mathsf{0}) = \mathsf{0}\} \\
  A_7 &= \{{\sf mult(x, 0) = 0, mult(y, 0) = 0, mult(z, 0) = 0, \dots}\} \\
  A_8 &= \{{\sf \forall x . mult(x, 0) = 0, \forall y . mult(y, 0) = 0, \forall z . mult(z, 0) = 0, \dots}\}
  \end{align*}
  
  All the eight theories are equal. Theories $A_4, A_5, A_6$ are finite representations of theories $A_7, A_8, A_8$ respectively. 
\end{example}

\begin{remark}
\label{no_need_to_have_metavariables_for_variables}
There is no need to have metavariables for variables in the Kore language, because (1) if they are used as bound variables, then replacing them with any (matching logic) variables will result in the same theories, thanks to alpha-renaming; and (2) if they are used as free variables, then it makes no difference to consider the universal quantification closure of them and we get to the case (1). 
\comment{\sout{Given said that, there are cases when metavariables for variables make sense. In those cases we often want our metavariables to range over all variables of all sorts, in order to make our Kore definitions compact.} No, we do not need metavariables over variables. I was thinking of the definedness symbols. We might want to write only one axiom schema of $\ceil{x}$ instead many $\ceil{x \cln s}_s^{s'}$'s, but we cannot do that unless we allow polymorphic and overloaded symbols in Kore definitions.}
\end{remark}

\paragraph{Patterns and metavariables for patterns}

It is in practice more common to use metavariables that range over all patterns. One typical example is axiom schemata. For example, $\vdash \varphi \to \varphi$ in which $\varphi$ is the metavariable that ranges all well-formed patterns. 

\comment{There has been an argument on whether metavariables for patterns should be sorted or not. Here are some observations. Firstly, since all symbols are decorated and not overloaded, in most cases, the sort of a metavariable for patterns can be inferred from its context. Secondly, the only counterexample against the first point that I can think of is when they appear alone, which is not an interesting case anyway. Thirdly, we do want the least amount of reasoning and inferring in using Kore definitions, so it breaks nothing if not helping things to have metavariables for patterns carrying their sorts.}

\begin{example}
\begin{align*}
A_1 &= \{{\sf merge(h1, h2) = merge(h2, h1)}\} \\
A_2 &= \{{\sf \forall h1 \forall h2 . merge(h1, h2) = merge(h2, h1)}\} \\
A_3 &= \{\mathsf{merge}(\varphi, \psi) = \mathsf{merge}(\psi, \varphi)\}
\end{align*}
All three theories are equal. It is easier to see that fact from a model theoretic point of view, since all theories require that the interpretation of $\mathsf{merge}$ is commutative and nothing more. On the other hand, it is not straightforward to obtain that conclusion from a proof theoretic point of view. For example, to deduce $\mathsf{merge}(\mathsf{list}(\mathsf{one}, \mathsf{cons}(\mathsf{two}, \mathsf{epsilon})), \mathsf{top}) = \mathsf{merge}(\mathsf{top}, \mathsf{list}(\mathsf{one}, \mathsf{cons}(\mathsf{two}, \mathsf{epsilon})))$ needs only one step in $A_3$, but will need a lot more in either $A_1$ or $A_2$, because one cannot simply substitute any patterns for universal quantified variables in matching logic.
\comment{This is a nice example that shows the power of metavariables and how they greatly shorten formal proofs, but this is not a good example to convince people that we need metavariables for patterns in order to embrace more expressiveness. There is an example in the theory $\LAMBDA$ that clearly shows metavariables give us more expressiveness power, and we will cover that example in later sections.}
\end{example}

\section{Binders}

In matching logic there is a unified representation of binders. We will be using the theory of lambda calculus $\LAMBDA$ as an example in this section. Recall that the syntax for untyped lambda calculus is
\begin{align*}
\Lambda \Coloneqq V \mid \lambda V . \Lambda \mid \Lambda \ \Lambda
\end{align*}
where $V$ is a countably infinite set of atomic $\lambda$-terms. The set of all $\lambda$-terms is the smallest set satisfying the above grammar.

The theory $\LAMBDA$ in matching logic has one sort $\mathsf{Exp}$ for lambda expressions. It also has in its signature a binary symbol $\mathsf{\#lambda}$ that builds a $\lambda$-terms, and a binary symbol $\mathsf{app}$ for lambda applications. To mimic the binding behavior of $\lambda$ in lambda calculus, we define syntactic sugar $\mathsf{lambda}x . e = \exists x . \mathsf{\#lambda}(x, e)$  and $e_1e_2 = \mathsf{app}(e_1, e_2)$ in theory $\LAMBDA$. Notice that by defining $\mathsf{lambda}$ as a syntactic sugar using existential quantifier, we get alpha-renaming for free. The $\beta$-reduction is captured in $\LAMBDA$ by the next ($\beta$) axiom:
\begin{equation*}
(\mathsf{lambda} x . e)e' = e[e'/x] \quad \text{, where $e$ and $e'$ are metavariables for $\lambda$-terms.}
\end{equation*}

We have two important observations about the ($\beta$) axiom. Firstly, metavaraibles $e$ and $e'$ cannot be replaced by matching logic variables, because $\lambda$-terms in matching logic are (often) not functional patterns. Secondly, metavariables $e$ and $e'$ cannot range over all patterns of sort $\mathsf{Exp}$, but only those which are (syntactic sugar) of $\lambda$-terms. Allowing $e$ and $e'$ range over all patterns of $\mathsf{Exp}$ in the ($\beta$) axiom will quickly lead to an inconsistent theory, because the next contradiction becomes an instance of the ($\beta$) axiom.
\begin{equation*}
\bot 
\xeq{(N)} \mathsf{app}((\mathsf{lambda} x . \top), \bot)
\xeq{($\beta$)} \top.
\end{equation*}

\comment{The above example is a strong evidence that we need metavariables that range over only a restricted set of patterns instead of all of them. Such a restricted set of patterns is called the \emph{range} (or maybe \emph{domain}?) of metavariables, which we will formally define later in this section. However, before we get into that, here are some observations that against having such restricted metavariables.
\begin{enumerate}
\item We found no example that has such inconsistency issue except theories that contain binders and applications. Therefore, restricted metavariables, even if we do introduce them in the Kore language, will be used in a quite limited way in defining theories that have binders, such as the lambda calculus and the theory of contexts, and will hardly be used in theories that don't have binders;
\item The reason why we need metavariables is because binding structures, such as $\lambda$-terms, are defined in matching logic as syntactic sugar with existential quantification. This makes those binding structures, such as $\lambda$-terms, no longer matching logic terms, and thus cannot substitute for matching logic variables, while they can (and should) be able to substitute for variables in their original calculus.
\item Introducing restrictive metavariables does solve the inconsistency issue, but it is apparently not the only solution. An alternative solution requires us to reexamine binders and binding structures in matching logic. If we could find a way to encode, say $\lambda$-terms, as \emph{functional patterns} in matching logic, then using variables is sufficient, and we can get rid of restrictive metavariables.
\item Having a unified theory of binders in matching logic is a good idea. Splitting binding structures into the process of constructing a term and the process of create a binding is also a promising way to go. We know how to construct a term in matching logic by simply using symbols. The issue is how to create a binding between variables and terms (or patterns in general).
\item A quantifier, given it a universal or existential one, creates a binding between a variable and a pattern \emph{and does something more}. According the semantics of matching logic, A universal quantifier creates the binding and calculates the big conjunction of all instances while an existential quantifier creates the binding and calculates the big disjunction of them. 
\item On the other hand, most binders that we use simply construct a term and create a binding between a variable and the term, and we should not pour any semantics upon them. However, when we use the existential quantifier to create a binding relation, we do put extra semantics upon those user-defined binders. That is the fundamental reason why $\lambda$-terms, even though they should be terms, become nonfunctional patterns in matching logic as we have seen, and thus we need to design the Kore language to support restricted metavariables.
\item Why not introduce a ``pure'' binder that creates a binding between variables and patterns and does nothing else at all? All other binders such as the $\lambda$ in the lambda calculus, the $\mu$ and $\nu$ in theories of fixed point, the $\gamma$ in theory of contexts, and even the universal quantifier $\forall$ and existential quantifier $\exists$, can all be defined using that ``pure'' binder.
\end{enumerate}
}
\begin{definition}[Restricted metavariables]
Let $\varphi$ be a metavariable of sort $s \in S$. The range of $\varphi$ is a subset of all patterns of the sort $s$. We write $\varphi :: R$ if the range of $\varphi$ is $R \subseteq \mathrm{Pattern}_s$.
\end{definition}

\begin{definition}[Common ranges of metavariables]
\quad
\begin{itemize}
\item The full range $\mathrm{Pattern}_s$;
\item The logic-free range (variables plus symbols without logic connectives);
\item The ground logic-free range (symbols only); 
\item The variable range $\mathrm{Var}_s$;
\end{itemize}
\end{definition}

\begin{remark}
We need to design a syntax for specifying ranges of metavariables in the Kore language. 
\end{remark}

\begin{remark}
We have not proved that matching logic is a conservative extension of untyped lambda calculus, which bothers me a lot. I will remain skeptical about everything we do in this section until we prove that conservative extension result. 
\end{remark}

\todo[inline]{Rewriting logic}

\section{Contexts}

Fix a signature $(S, \Sigma)$. For each sort $s \in S$, introduce an infinite number of \emph{hole} variables, written as $\square_1, \square_2, \cdots$. Think of hole variables as normal matching logic variables, but lie in a disjoint namespace. Extend the grammar by adding the following.

\begin{align}
\label{ml_grammar}
P \Coloneqq\  & \cdots \nonumber \\
\mid\  & \square \nonumber \\
\mid\  & \gamma \square . P \nonumber \\
\mid\  & P[P'] . \nonumber
\end{align}

The sort of $\gamma \square . P$ is the sort of $P$. The sort of $P[P']$ is the sort of $P$, too. Think of $\gamma \square$ as a binder. Alpha-renaming is always assumed. Patterns of the form $\gamma \square . P$ are often called \emph{contexts}, denoted by $C, C_0, C_1, \dots$. The pattern $P[P']$ is often called an \emph{application}. The $\_[\_]$ operator is left associative.

\begin{definition}
	The context $\gamma \square . \square$ is called the identity context, denoted as $\I$. Identity context has the axiom schema $\I[P]=P$ where $P$ is any pattern.
\end{definition}

\begin{example}
	$\I[\I] = \I$.
\end{example}

\begin{example}
	Consider a signature $(S,\Sigma)$ of a simple imperative programming language, with $S = \{{BExp},{Pgm}\}$, and $\Sigma = \{skip, {ite}, {seq}, true, false\}$. Add axiom schemata $${ite}(C_1[B], P, Q) = (\gamma \square . {ite}(C_1[\square], P, Q))[B]$$ and $${seq}(C_2[P],Q) = (\gamma \square . {seq}(C_2[\square], Q))[P],$$ where $P, Q$ are ${Pgm}$ patterns, $B$ is a ${BExp}$ pattern, $C_1$ is a ${BExp}$ context, and $C_2$ is a ${Pgm}$ context.
	
	Suppose we have the rewrite rules (schemata):
	\begin{itemize}
		\item $C[{ite}({true}, P, Q)] \Rightarrow C[P]$,
		\item $C[{ite}({false}, P, Q)] \Rightarrow C[Q]$,
		\item $C[{seq}({skip},Q)] \Rightarrow C[Q]$.
	\end{itemize}
	
	Example (a). Rewrite $seq(skip,skip)$.
	\begin{align*}
	seq(skip,skip)
	&= \mathsf{I}[seq(skip,skip)] \\
	&\Rightarrow \mathsf{I}[skip] \\
	&= skip.
	\end{align*}
	
	Example (b). Rewrite $ite(true, P, Q); R$.
	\begin{align*}
	seq(ite(true, P, Q), R) 
	&= seq(\I[ite(true, P, Q)], R) \\
	&= (\gamma \square . seq(\I[\square], R))[ite(true, P, Q)] \\
	&\Rightarrow (\gamma \square . seq(\I[\square], R))[P] \\
	&= seq(\I[P], R) \\
	&= seq(P, R).
	\end{align*}
\end{example}

\begin{definition}
	Let $\sigma \in \Sigma_{s_1\dots s_n, s}$ is an $n$-arity symbol. We say $\sigma$ is \emph{active} on its $i$th argument ($1 \le i \le n$), if
	$\sigma(P_1,\dots, C[P_i], \dots, P_n)
	= (\gamma \square . \sigma(P_1,\dots,C[\square], \dots, P_n))[P_i]$. Orienting the equation from the left to the right is often called \emph{heating}, while orienting from the right to the left is called \emph{cooling}.
\end{definition}

\begin{example}
	Suppose $f$ and $g$ are binary symbols who are active on their first argument. Suppose $a, b$ are constants, and $x$ is a variable. Let $\square_1$ and $\square_2$ be two hole variables. Define two contexts $C_1 = \gamma \square_1 . f(\square_1, a)$ and $C_2 = \gamma \square_2 . g(\square_2, b)$. 
	
	Because $f$ is active on the first argument, 
	\begin{align*}
       C_1[\varphi]
       &= (\gamma \square_1 . f(\square_1, a)) [\varphi] \\
       &= (\gamma \square_1 . f(\I[\square_1], a)) [\varphi] \\
       &= f(\I[\varphi], a) \\
       &= f(\varphi, a), \text{ for any pattern $\varphi$.}
	\end{align*}
	And for the same reason, $C_2[\varphi] = g(\varphi, b)$. Then we have
	\begin{align*}
	C_1[C_2[x]]
	&= C_1[f(x,a)] \\
	&= g(f(x,a), b).
	\end{align*}
	On the other hand, 
	\begin{align*}
    g(f(x,a), b)
    &= g(C_1[x], b) \\
    &= (\gamma \square . g(C_1[\square], b))[x] \\
    &= (\gamma \square . g(f(\square, a), b))[x].
	\end{align*}
	Therefore, the context $\gamma \square . g(f(\square, a), b))$ is often called the \emph{composition} of $C_1$ and $C_2$, denoted as $C_1 \circ C_2$.

\end{example}

\begin{example}
	Suppose $f$ is a binary symbol with all its two arguments active. Suppose $C_1$ and $C_2$ are two contexts and $a, b$ are constants. Then easily we get
	\begin{align*}
	f(C_1[a],C_2[b])
	&= (\gamma \square_2 . f(C_1[a], C_2[\square_2]))[b] \\
	&= (\gamma \square_2 . ((\gamma \square_1 . f(C_1[\square_1], C_2[\square_2])) [a] )) [b].
	\end{align*}
	What happens above is similar to \emph{curring} a function that takes two arguments. It says that there exists a context $C_a$, related with $C_1, C_2, f$ and $a$ of course, such that $C_a[b]$ returns $f(C_1[a],C_2[b])$. The context $C_a$ has a binding hole $\square_2$, and a body that itself is another context $C_a'$ applied to $a$. In other words, there exists $C_a$ and $C_a'$ such that 
	\begin{itemize}
	\item $f(C_1[a],C_2[b]) = C_a[b]$,
	\item $C_a = \gamma \square_2 . (C_a'[a])$,
	\item $C_a' = \gamma \square_1 . f(C_1[\square_1], C_2[\square_2])$.
	\end{itemize}
	
	A natural question is whether there is a context $C$ such that $C[a][b] = f(C_1[a],C_2[b])$. 
\end{example}

\begin{proposition}
	$C_1[C_2[\varphi]] = C [\varphi], \text{ where } C = \gamma \square . C_1[C_2[\square]].$
\end{proposition}

\subsubsection{Normal forms}

In this section, we consider \emph{decomposition} of patterns. A decomposition of a pattern $P$ is a pair $\langle C, R \rangle $ such that $C[R] = P$. Let us now consider patterns that do not have logical connectives.

\todo[inline]{Fixed points}



\end{document}