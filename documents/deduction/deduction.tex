\documentclass{amsart}

\input{preamble}

\title{Sound and Complete Deduction in Matching Logic}

\author{Xiaohong Chen}
\address{University of Illinois at Urbana-Champaign}
\email{xc3@illinois.edu}



\begin{document}

\begin{abstract}

This paper presents a sound and complete proof system of matching logic.
The proof system implies a strong connection between matching logic
and many-sorted polyadic first-order modal logic.

\end{abstract}

\maketitle

\section{Background and Motivation}

Matching logic was initially proposed to specify and reason about
static properties about computer program configurations. 
Recently, we noticed a huge potential of matching logic to be used
in a much wider context.

\section{Syntax and Semantics of Matching Logic}

\begin{definition}[Signatures and Patterns]
\label{def_syntax}
A matching logic signature is a triple
$\sig = (\Var, S, \Sigma)$
that consists of
an $S$-indexed family of countably infinite variable sets
$\Var = \{ \Var_s \}_{s \in S}$,
a countable (finite or infinite) sort set $S$,
and an $(S^* \times S)$-indexed countable (finite or infinite)
symbol set $\Sigma = \{ \SigmaSub{s_1 \dots s_n ,s} \}_{s_1 \ddd s_n , s \in S}$.
We write $\SigmaSub{s_1 \dots s_n , s}$ as
$\SigmaSub{\lambda , s}$ if $n = 0$.
The set of all $\sig$-patterns of sort $s$,
denoted as $\Pattern_s(\sig)$,
is defined by the following grammar
\begin{center}
\begin{tabular}{rcll}
$\varphi_s$
& $\Coloneqq$
& $x \in \Var_s$
& \doubleslash Variable
\\
& $|$
& $\sigma(\varphi_{s_1} \ddd \varphi_{s_n})$
  with $\sigma \in \SigmaSub{s_1 \dots s_n , s}$
& \doubleslash Structure
\\
& $|$
& $\neg \varphi_s$
& \doubleslash Complement
\\
& $|$
& $\varphi_s \wedge \varphi_s$
& \doubleslash Intersection
\\
& $|$
& $\exists x . \varphi_s$
  with $x \in \Var_{s'}$ (of any sort $s' \in S$)
& \doubleslash Binding
\end{tabular}
\end{center}
Let $\Pattern(\sig) = \{ \Pattern_s(\sig) \}_{s \in S}$
be the $S$-indexed family set of all patterns.
\end{definition}


When $\Var$ is clear from the context,
we often omit it and just write $\sig = (S, \Sigma)$.
If $S$ is also clear, we refer to a signature
by just $\Sigma$.
When the signature $\sig$ is clear
we write $\Pattern_s$ to denote 
the set of all $\sig$-patterns of sort $s$.
Throughout the paper, we use $S$ to denote a fixed sort set
and $s,s_1,s_2,\dots$ to denote individual sorts.

By abuse use of language,
we blur the distinction between
a family of sets and their union set.
In particular, 
we write $\Var = \bigcup_{s \in S} \Var_s$
and $\Pattern = \bigcup_{s \in S} \Pattern_s$
to denote the set of all variables and patterns respectively.
To ease our notation,
$\varphi \in \Pattern$ means $\varphi$ is a pattern,
and $\varphi_s \in \Pattern$ or $\varphi \in \Pattern_s$ means
it has sort~$s$.
Similarly, $\sigma \in \Sigma$ means $\sigma$ is a symbol.
If $\sigma \in \SigmaSub{\lambda, s}$, we say $\sigma$
is a constant symbol of sort $s$, and
we write $\sigma$ instead of~$\sigma()$.
We write $x \cln s$ to emphasize that $x$ is a variable of sort $s$.

Derived constructs in propositional and FOL reasoning
are defined in their usual way:
\begin{center}
\begin{tabular}{rclp{1cm}rcl}
$\top_s$ & $\equiv$ & $\exists x \cln s . x \cln s$
&&
$\bot_s$ & $\equiv$ & $\neg \top_s$
\\
$\varphi_1 \vee \varphi_2$ & $\equiv$ & 
$\neg (\neg \varphi_1 \wedge \neg \varphi_2)$
&&
$\varphi_1 \imp \varphi_2$ & $\equiv$ &
$\neg \varphi_1 \vee \varphi_2$
\\
$\varphi_1 \dimp \varphi_2$ & $\equiv$ &
$(\varphi_1 \imp \varphi_2) \wedge (\varphi_2 \imp \varphi_1)$
&&
$\forall x . \varphi$ & $\equiv$ &
$\neg (\exists x . \neg \varphi)$
\end{tabular}
\end{center}
We feel free to drop their sorts when there is no confusion.
The precedence of these constructs are the same as in FOL.
Negation ($\neg$) binds the tightest, followed by
conjunction ($\wedge$),
disjunction ($\vee$),
implication ($\imp$),
and double implication ($\dimp$).
Binders ($\exists$ and $\forall$) bind to the rightmost.
Implication is right associative, so
$\varphi_1 \imp \varphi_2 \imp \varphi_3$
means
$\varphi_1 \imp (\varphi_2 \imp \varphi_3)$,
but we are generous in using parenthesis 
to prevent potential parsing ambiguity from humans.

As in FOL, we can define the notions of free variables,
variable-capture-free substitution,
and alpha-renaming.

\begin{definition}[Free variables, substitution, and alpha-renaming]
\label{def_fv_etal}
Let $\varphi \in \Pattern$.
The set of free variables in $\varphi$, denoted as $\FV(\varphi)$,
is defined as follows:
\begin{center}
\begin{tabular}{ccc}
$\FV(x) = \{ x \}$ &
$\FV(\neg \varphi) = \FV(\varphi)$ &
$\FV(\varphi_1 \wedge \varphi_2) = \FV(\varphi_1) \cup \FV(\varphi_2)$
\end{tabular}
\begin{tabular}{cc}
$\FV(\sigma(\varphi_1 \ddd \varphi_n)) 
 = \bigcup_{1 \le i \le n} \FV(\varphi_i)$ &
$\FV(\exists x . \varphi) = \FV(\varphi) \setminus \{ x \}$
\end{tabular}
\end{center}
Variable-capture-free substitution is defined in the usual way:
\begin{center}
\begin{tabular}{ccc}
$x [ \psi / x ] = \psi$   &
$y [ \psi / x ] = y$ if $y$ is distinct from $x$ &
$(\neg \varphi)[\psi / x] = \neg (\varphi [\psi / x])$
\end{tabular}
\begin{tabular}{cc}
$(\varphi_1 \wedge \varphi_2) [\psi / x]
 = \varphi_1 [\psi / x] \wedge \varphi_2 [\psi / x]$ &
$\sigma(\varphi_1 \ddd \varphi_n)[\psi / x]
 = \sigma( \varphi_1[\psi/x] \ddd \varphi_n[\psi/x] )$
\end{tabular}
\begin{tabular}{cc}
$(\exists x . \varphi) [\psi / x] = \exists x . \varphi$ &
$(\exists y . \varphi) [\psi / x] = \exists y . (\varphi [\psi/x])$
if $y$ is distinct from $x$ and $y \not\in \FV(\psi)$
\end{tabular}
\end{center}
Finally, alpha-renaming allows to avoid variable capture:
\begin{center}
$\exists x . \varphi \equiv \exists y . (\varphi[y/x])$
\quad if $y \not\in \FV(\varphi)$.
\end{center}
\end{definition}

\begin{example}[Variable-capture-free substitution]
\label{example_vcf_substitution}
Let $x$, $y$, and $z$ be distinct variables.
\begin{center}
\begin{tabular}{rll}
$(\exists x . (x \wedge y)) [x / y]$
& $\equiv (\exists z . ((x \wedge y) [z / x])) [x / y]$
& \doubleslash alpha-renaming
\\
& $= (\exists z . (z \wedge y)) [x / y]$
& \doubleslash variable-capture-free substitution
\\
& $= \exists z . ( (z \wedge y) [x / y] )$
& \doubleslash variable-capture-free substitution
\\
& $= \exists z . (z \wedge x)$
& \doubleslash variable-capture-free substitution
\end{tabular}
\end{center}
\end{example}
As a convention, we consider patterns that are alpha-equivalent the same,
so $\exists x . (x \wedge y)$ and $\exists z . (z \wedge y)$
are the same pattern.

\begin{definition}[Models, valuations, and satisfaction]
\label{def_models}
Let $\sig = (S, \Sigma)$ be a signature.
A $\sig$-model is a pair
$\MM = (M, \interpM)$ with
$M = \{M_s\}_{s \in S}$ an $S$-indexed family of nonempty sets called
the carrier sets,
and $\interpM = \{ \sigmaM \}_{\sigma \in \Sigma}$
a $\Sigma$-indexed interpretation mapping:
\begin{itemize}
\item each $\sigma \in \SigmaSub{s_1 \dots s_n , s}$
      maps to a function
      $\sigmaM \colon M_{s_1} \times \dots \times M_{s_n} \to \pset{M_s}$,
\end{itemize}
where $2^{M_s}$ means the set of all subsets of $M_s$.
In particular, each constant symbol
$\sigma \in \SigmaSub{\lambda,s}$ 
maps to a subset $\sigmaM \subseteq M_s$;
An $\MM$-valuation is a mapping
$\rho \colon \Var \to M$
such that for every $x \in \Var_s$, $\rho(x) \in M_s$ for every sort $s \in S$.
Two $\MM$-valuations $\rho_1$ and $\rho_2$ are called 
\emph{equal modulo $x$},
denoted as $\rho_1 \simx \rho_2$,
if $\rho_1(y) = \rho_2(y)$ for every $y$ distinct from $x$.
A valuation $\rho$ can be extended to a mapping
$\barrho \colon \Pattern \to \pset{M}$
such that $\barrho(\varphi_s) \subseteq M_s$.
The extended valuation $\barrho$ is inductively defined as follows:
\begin{itemize}
\item $\barrho(x) = \{ \rho(x) \}$, for every $x \in \Var_s$;
\item $\barrho(\sigma(\varphi_1 \ddd \varphi_n))
       = \sigmaM( \barrho(\varphi_1) \ddd \barrho(\varphi_n) )$,
      for every $\sigma \in \SigmaSub{s_1 \dots s_n , s}$
      and appropriate $\varphi_1 \ddd \varphi_n$
\item $\barrho(\neg \varphi) = M_s \setminus \barrho(\varphi)$,
      for every $\varphi \in \Pattern_s$;
\item $\barrho(\varphi_1 \wedge \varphi_2)
       = \barrho(\varphi_1) \cap \barrho(\varphi_2)$,
      for every $\varphi_1,\varphi_2$ of the same sort;
\item $\barrho(\exists x . \varphi)
       = \bigcup \{ \barrhop(\varphi) 
                    \mid \text{for every $\rhop \simx \rho$} \}$.
\end{itemize}
Given a model $\MM$ and a valuation $\rho$,
we say $\MM$ and $\rho$ satisfy a pattern $\varphi_s$,
denoted as $\MM,\rho \vDash \varphi_s$,
if $\barrho(\varphi) = M_s$.
We say $\MM$ satisfies $\varphi_s$
or $\varphi_s$ holds in $\MM$,
denoted as $\MM \vDash \varphi_s$,
if $\MM , \rho \vDash \varphi_s$ for every valuation $\rho$.
We say $\varphi_s$ is valid if
it holds in every model.
Let $\Gamma$ be a pattern set.
We say $\MM$ satisfies $\Gamma$, if
$\MM \vDash \varphi$ for every $\varphi \in \Gamma$.
We say $\Gamma$ semantically entails $\varphi$,
denoted as $\Gamma \vDash \varphi$,
if for every model $\MM$ such that $\MM \vDash \Gamma$,
$\MM \vDash \varphi$.
When $\Gamma$ is the empty set, we abbreviate
$\emptyset \vDash \varphi$ as just $\vDash \varphi$,
which is equivalent to $\varphi$ is valid.
\end{definition}

Various basic properties about the semantics of matching logic
can be found in~\cite{rosu-2017-lmcs}.
Here we only introduce the Substitution Lemma,
which is needed in the proof of the completeness theorems.
Substitution Lemma connects the semantic valuation modification
and the syntactic substitution.
Let $\rho$ be a valuation.
For any $x \in \Var_s$ and $v \in M_s$,
the modified valuation $\rhop = \rho [ v / x ]$ is defined as follows
$$
\rhop(y) = 
\begin{cases*}
\rho(y) & if $y$ is distinct from $x$ \\
v       & if $y$ is $x$
\end{cases*}
$$
\begin{lemma}[Substitution Lemma]
\label{lemma_substitution_lemma}
For any pattern $\varphi$ and valuation $\rho$,
$$
\barrho(\varphi[y/x]) =
\barrhop(\varphi)
$$
where $\rho' = \rho[\rho(y)/x]$.
\end{lemma}
\begin{proof}
The proof is by induction on the structure of $\varphi$.
The only nontrivial case is when $\varphi \equiv \exists z . \psi$.
Without loss of generality, let us assume $z$ is distinct from $x$ and $y$.
If not, apply alpha-renaming to make them different.
Then
\begin{center}
\begin{tabular}{ll}
\quad $\barrho( (\exists z . \psi)  [y/x] )$ \\
$\equiv \barrho( \exists z . (\psi[y/x]) )$
& \doubleslash variable-capture-free substitution \\
$\equiv \bigcup \{ \barrhox{1} ( \psi[y/x] )
    \mid \rhox{1} \simz \rho \}$
& \doubleslash Definition~\ref{def_models} \\
$\equiv \bigcup \{ \barrhopx{1} ( \psi )
    \mid \rhox{1} \simz \rho
    \txtand
    \rhopx{1} = \rhox{1}[\rhox{1}(y)/x] \}$
& \doubleslash Induction hypothesis \\
$\equiv \bigcup \{ \barrhopx{1} ( \psi )
    \mid \rhox{1} \simz \rho
    \txtand
    \rhopx{1} = \rhox{1}[\rho(y)/x] \}$
& \doubleslash $\rhox{1}(y) = \rho(y)$ \\
$\equiv \bigcup \{ \barrhopx{1} ( \psi )
    \mid \rhox{1} \simz \rho[\rho(y)/x] \}$
& \doubleslash $\rhox{1}(x) = \rho(y)$ \\
$\equiv \bigcup \{ \barrhopx{1} ( \psi )
    \mid \rhox{1} \simz \rhop \}$
& \doubleslash Definition of $\rhop$ \\
$\equiv \barrhop(\exists z . \psi)$
& \doubleslash Definition~\ref{def_models}
\end{tabular}
\end{center}
\end{proof}

\section{Proof System of Matching Logic}

In this section,
we study the proof system of matching logic.
Firstly, let us define the notions of a context and context application.

\begin{definition}[Contexts, Symbol Contexts, and Context Application]
A context $C$ is a pattern with a placeholder variable
$\hole \in \Var$ that has exactly one free occurrence
and no bound occurrence in $C$.
For any pattern $\varphi$ of the same sort as $\hole$,
context application $C[\varphi]$ is the result of
replacing $\hole$ for $\varphi$ in $C$ (without any alpha-renaming).
Symbol contexts are a special family of contexts defined as follows
\begin{itemize}
\item The pattern $\hole$ is a symbol context called the identity context;
\item The pattern
      $\sigma(\varphi_1 \ddd \varphi_{i-1}, 
              \hole , 
              \varphi_{i+1} \ddd \varphi_n)$
      is a symbol context.
      When patterns 
      $\varphi_1 \ddd \varphi_{i-1},\\ \varphi_{i+1} \ddd \varphi_n$
      are not of interest,
      we just write the pattern as $\Csigmai$ or simply $\Csigma$;
\item The pattern of the form
      $
      \CSub{\sigma_1}[\CSub{\sigma_2}[\dots  \CSub{\sigma_n}[\hole] \dots]]
      $
      is a symbol context
      where $\sigma_1 \ddd \sigma_n$ are symbols (not necessarily distinct).
\end{itemize}
\end{definition}

\begin{remark}
Unlike variable-capture-free substitution,
context application $C[\varphi]$ may bind free variables in $\varphi$.
For example,
let $C$ be $\exists x . (x \wedge \hole)$ and $\varphi$ be $x$,
then $C[\varphi]$ is $\exists x . (x \wedge x)$, 
where the free variable $x$ in $\varphi$
is bound in $C[\varphi]$.
Compare this example with Example~\ref{example_vcf_substitution} to get
a better understanding of
the difference between variable-capture-free substitution and context 
application.
\end{remark}

\Figure{fig_proofsystem} 
is a sound and complete Hilbert-style proof system of matching logic.
It has 13 proof rules in total.
A proof rule has the form
$$
\begin{prftree}
{\varphi_1}
{\dots}
{\varphi_n}
{\varphi}
\end{prftree}
$$
where patterns above the bar are called premises of the rule
and the pattern below is called the conclusion.
A proof rule with no premises is called an axiom,
denoted as
\begin{center}
\begin{tabular}{ccc}
$$
\begin{prftree}
{\cdot}
{\varphi}
\end{prftree}
$$
&
or simply
&
$\varphi$
\end{tabular}
\end{center}

\begin{figure}[hbtp]
\begin{tabular}{ll}
	\hline
	\prule{Proposition$_1$} &
	$\varphi_1 \imp (\varphi_2 \imp \varphi_1) $
	\\
	\prule{Proposition$_2$} &
	$(\varphi_1 \imp (\varphi_2 \imp \varphi_3))
	 \imp (\varphi_1 \imp \varphi_2)
	 \imp (\varphi_1 \imp \varphi_3)$
	\\
	\prule{Proposition$_3$} &
	$(\neg \varphi_1 \imp \neg \varphi_2)
	 \imp (\varphi_2 \imp \varphi_1)$
	\\
	\modusponens &
	$$
	\begin{prftree}
	{\varphi_1}{\varphi_1 \imp \varphi_2}
	{\varphi_2}
	\end{prftree}
	$$
	\\
	\hline
	\variablesubstitution &
	$\forall x . \varphi \imp \varphi[y/x]$
	\\
	\prule{$\forall$} &
	$\forall x . (\varphi_1 \imp \varphi_2) 
	 \imp (\varphi_1 \imp \forall x . \varphi_2)$
	 \quad if $x \not\in \FV(\varphi_1)$
	\\
	\universalgeneralization &
	$$
	\begin{prftree}
	{\varphi}
	{\forall x . \varphi}
	\end{prftree}
	$$
	\\
	\hline
	\propagationbottom &
	$\Csigma[\bot] \imp \bot$
	\\
	\propagationvee &
	$\Csigma[\varphi_1 \vee \varphi_2]
	 \imp \Csigma[\varphi_1] \vee \Csigma[\varphi_2] $
	\\
	\prule{Propagation$_\exists$} &
	$\Csigma[\exists x . \varphi]
	 \imp \exists x . \Csigma[\varphi]$
	 \quad if $x \not\in \FV(\Csigmaapp{\exists x . \varphi})$
	\\
	\hline
	\framing &
	$$
	\begin{prftree}
	{\varphi_1 \imp \varphi_2}
	{\Csigma[\varphi_1] \imp \Csigma[\varphi_2]}
	\end{prftree}
	$$
	\\
	\hline
	\existence &
	$\exists x . x$
	\\
	\singletonvariable &
	$\neg (C_1[x \wedge \varphi] \wedge C_2[x \wedge \neg \varphi])$
	\\ & where $C_1$ and $C_2$ are symbol contexts.
	\\
	\hline
\end{tabular}
\caption{Sound and Complete Proof System of Matching Logic}
\label{fig_proofsystem}
\end{figure}

\begin{definition}[Hilbert-Style Proofs]
\label{def_proof}
Let $\Gamma$ be pattern set called the hypothesis set.
A $\Gamma$-proof (or simply a proof when $\Gamma$ is clear from the context)
is a finite sequence of patterns
$\varphi_1 \ddd \varphi_n$ for some $n \ge 1$, such that
for every $1 \le k \le n$,
$\varphi_k$ is either an axiom,
or a member in $\Gamma$,
or the conclusion of a rule
with $\varphi_1 \ddd \varphi_{k-1}$ as available premises.
We say $\Gamma$ syntactically entails $\varphi$ or 
$\varphi$ is provable from $\Gamma$,
denoted as $\Gamma \vdash \varphi$,
if there is a $\Gamma$-proof of $\varphi$.
When $\Gamma$ is the empty set,
we abbreviate $\emptyset \vdash \varphi$
as $\vdash \varphi$.
\end{definition}

We can prove a few useful results about the proof system.
In the following, let $\Gamma$ be any set of patterns.

\begin{proposition}[Sound FOL Reasoning]
\label{prop_sound_FOL_reasoning}
Let $\sig = (S, \Sigma)$ be a matching logic signature.
Let $(S,\Pi,F)$ be any first-order logic signature
with $\Pi = \{ \Pi_s \}_{s \in S}$ a set of constant predicate symbols
and $F = \emptyset$ a set of function symbols.
For any predicate logic formula
$\Psi(\pi_1 \ddd \pi_n)$ where
$\pi_1 \ddd \pi_n \in \Pi$,
if $\Psi(\pi_1 \ddd \pi_n)$ is derivable in FOL,
then $\Psi(\varphi_1 \ddd \varphi_n)$ is derivable in matching logic,
where $\varphi_i$ has the same sort as $\pi_i$ for $1 \le i \le n$.
\end{proposition}
\begin{proof}
Notice that $F = \emptyset$, so the only FOL terms are variables.
Under that condition, the first seven rules in Figure~\ref{fig_proofsystem}
forms a complete FOL proof system as in~\cite{hamilton1988logic}.
\end{proof}

\begin{remark}
In literature, FOL with no function symbols is often called 
the ``pure predicate logic'',
so Proposition~\ref{prop_sound_FOL_reasoning} may better be called
``sound predicate logic reasoning''.
Recently, in~\cite{rosu-2017-lmcs} the author established a more general result
and proved that full FOL reasoning is also sound in matching logic.
In this paper, however, we stick to
our less general result Proposition~\ref{prop_sound_FOL_reasoning}
and call it ``sound FOL reasoning'', 
because it is good enough for our purposes
and it requires fewer words to say
than ``sound predicate logic reasoning''.
\end{remark}
\begin{remark}
As a special case, propositional reasoning is sound in matching logic.
\end{remark}

Matching logic enjoys frame reasoning.
Even though rule \framing only allows basic frame reasoning
at one argument of one symbol, 
it is not hard to extend it to multiple arguments
or multiple symbol applications.

\begin{proposition}[Sound Frame Reasoning]
	\label{prop_framing}
For any $\sigma \in \SigmaSub{s_1 \dots s_n , s}$ and 
$\varphi_i, \varphi'_i \in \Pattern_{s_i}$
such that $\Gamma \vdash \varphi_i \imp \varphi'_i$
for any $1 \le i \le n$,
then $\Gamma \vdash 
\sigma(\varphi_1 \ddd \varphi_n) \imp
\sigma(\varphi'_1 \ddd \varphi'_n)$.
For any symbol context $C$ and $\varphi_i, \varphi'_i$ such that
$\Gamma \vdash \varphi_i \imp \varphi'_i$,
then $\Gamma \vdash C[\varphi] \imp C[\varphi'_i]$.
\end{proposition}
\begin{proof}
For the first case,
it suffices to show that
\begin{align*}
&\Gamma \vdash \sigma(\varphi_1 , \varphi_2 \ddd \varphi_n)
          \imp \sigma(\varphi'_1, \varphi_2 \ddd \varphi_n) \\
&\Gamma \vdash \sigma(\varphi'_1 , \varphi_2 \ddd \varphi_n)
          \imp \sigma(\varphi'_1, \varphi'_2 \ddd \varphi_n) \\
& \dots \\
&\Gamma \vdash \sigma(\varphi'_1 , \varphi'_2 \ddd \varphi_n)
          \imp \sigma(\varphi'_1, \varphi'_2 \ddd \varphi'_n) \\
\end{align*}
which directly follow by \framing.

For the second case,
the proof is by structure induction on $C$.
If $C$ is the identity context, the conclusion is obvious.
If $C$ has the form $\Csigmaapp{C'}$, the conclusion follows from
induction hypothesis and \framing.
\end{proof}

\begin{proposition}[Propagation of Symbol Application]
\label{prop_propgation_of_symbol_application}
For any symbol context $C$ and patterns $\varphi_1, \varphi_2, \varphi$,
the following propositions hold.
\begin{itemize}
	\item $\Gamma \vdash 
	          C[\bot] \dimp 
	          \bot$
	\item $\Gamma \vdash 
	          C[\varphi_1 \vee \varphi_2] \dimp
	          C[\varphi_1] \vee
	          C[\varphi_2]$
	\item $\Gamma \vdash
	          C[\exists x . \varphi] \dimp
	          \exists x . C[\varphi] $
	       \quad if $x \not\in \FV(C[\exists x . \varphi])$
\end{itemize}
The following results are often useful in practice, whose proofs can
be obtained by standard propositional reasoning with the above propositions:
\begin{itemize}
	\item $\Gamma \vdash 
	          C[\varphi_1 \vee \varphi_2]$
	      iff
	      $\Gamma \vdash C[\varphi_1] \vee
	                     C[\varphi_2]$
	\item $\Gamma \vdash
	          C[\exists x . \varphi] $
	      iff
	      $\Gamma \vdash \exists x . C[\varphi]$
	      \quad if $x \not\in \FV(C[\exists x . \varphi])$
\end{itemize}
\end{proposition}
\begin{proof}
The proof is by structure induction on the symbol context $C$.
If $C$ is the identity context then the conclusion is obvious.
Now assume $C = \Csigmaapp{C'}$ where $C'$ is a symbol context
for which the conclusion holds.

Firstly, let us prove 
$\Gamma \vdash \Csigmaapp{C'[\bot]} \dimp \bot$.
The implication from right to left is by simple propositional reasoning.
For the other direction,
notice by induction hypothesis
$\Gamma \vdash C'[\bot] \imp \bot$
and by \framing
$\Gamma \vdash \Csigmaapp{C'[\bot]} \imp \Csigmaapp{\bot}$.
In addition by \propagationbottom,
$\Gamma \vdash \Csigmaapp{\bot} \imp \bot$,
and the rest of the proof is by standard propositional reasoning.

Secondly, let us prove
$\Gamma \vdash 
	          \Csigmaapp{C'[\varphi_1 \vee \varphi_2]} \dimp
	          \Csigmaapp{C'[\varphi_1]} \vee
	          \Csigmaapp{C'[\varphi_2]}$.
For the implication from right to left, 
it suffices to prove
$\Gamma \vdash \Csigmaapp{C'[\varphi_i]} 
  \imp \Csigmaapp{C'[\varphi_1 \vee \varphi_2]}$
for $i = 1, 2$.
By \framing, it suffices to prove
$\Gamma \vdash C'[\varphi_i]
  \imp C'[\varphi_1 \vee \varphi_2]$,
which follows from the induction hypothesis.
For the implication from left to right,
the proof is the same as 
how we proved $\Gamma \vdash \Csigmaapp{C'[\bot]} \imp \bot$,
while instead of \propagationbottom we use \propagationvee.

Finally, let us prove
$\Gamma \vdash
	          \Csigmaapp{C'[\exists x . \varphi]} \dimp
	          \exists x . \Csigmaapp{C'[\varphi]} $
for $x \not\in \FV(\Csigmaapp{C'[\exists x . \varphi]})$.
In fact the proof is the same as above, while instead of
\propagationvee we use \propagationexists.
\end{proof}

\begin{proposition}[Congruence of Provably Equivalence]
\label{prop_congruence_provability_equiv}
For any context $C$ (not necessarily just symbol context),
$\Gamma \vdash \varphi_1 \dimp \varphi_2$
implies
$\Gamma \vdash C[\varphi_1] \dimp C[\varphi_2]$.
\end{proposition}
\begin{proof}
The proof is by induction on the structure of $C$.
If $C$ is the identity context the conclusion is obvious.
If $C$ is of the form 
$\neg C'$, 
$\psi \wedge C'$,
or $C' \wedge \psi$
where $C'$ is a context and $\psi$ is a pattern
(notice $\psi$ does not have the placeholder variable $\hole$ in it),
the conclusion is by standard propositional reasoning.
If $C$ has the form $\exists x . C'$,
the conclusion follows from standard FOL reasoning.
If $C$ has the form $\Csigmaapp{C'}$,
the conclusion follows from Proposition~\ref{prop_framing}.
\end{proof}

\subsection{The Definedness Symbols and Completeness}

In~\cite{rosu-2017-lmcs},
the author proposed a sound and complete proof system of matching logic,
which is shown in \Figure{fig_proofsystem_definedness}.
That proof system, however, assumes the existence of
a special family of symbols in the signature called the definedness symbols.
Using definedness symbols,
we can easily define equality and membership
as derived constructs,
and proved they have the expected semantics.
We refer to~\cite{rosu-2017-lmcs} for more details,
and only summarize the definitions of definedness symbols, 
equality, and membership as follows.

\begin{definition}
For any sorts $s_1,s_2 \in S$, the definedness symbol
$\ceil{\_}_{s_1}^{s_2} \in \SigmaSub{s_1,s_2}$
is a unary symbol which has an axiom
$
\ceil{x \cln s_1}_{s_1}^{s_2}
$.
For any $\varphi,\varphi' \in \Pattern_{s_1}$,
define the equality construct
$
\varphi =_{s_1}^{s_2} \varphi'
\equiv
\neg \ceil{ \neg ( \varphi \dimp \varphi' ) }_{s_1}^{s_2}
$
and the membership construct
$
x \cln s_1 \in_{s_1}^{s_2} \varphi
\equiv
\ceil{ x \cln s_1 \wedge \varphi }_{s_1}^{s_2}
$.
We feel free to drop the sorts when they are clear from the context.
\end{definition}





\begin{figure}[hbtp]
	\begin{tabular}{ll}
		\hline
		\propositionaltautology &
		$\varphi$, if $\varphi$ is a proposition tautology
		\\
		\modusponens &
		From $\varphi_1$ and $\varphi_1 \imp \varphi_2$, deduce $\varphi_2$.
		\\
		\hline
		\functionalsubstitution &
		$(\forall x . \varphi) \wedge (\exists y . \varphi' = y)
		\imp \varphi[\varphi'/x]$ if $y \not\in\FV(\varphi')$
		\\
		\forallrule &
		$\forall x . (\varphi_1 \imp \varphi_2) 
		\imp (\varphi_1 \imp \forall x . \varphi_2)$
		if $x \not\in \FV(\varphi_1)$
		\\
		\universalgeneralization &
		From $\varphi$, deduce $\forall x . \varphi$.
		\\
		\hline
		\prule{Equality Introduction} &
		$\varphi = \varphi$
		\\
		\equalityelimination &
		$(\varphi_1 = \varphi_2) \wedge \psi[\varphi_1/x] 
		\imp \psi[\varphi_2 / x]$
		\\
		\hline
		\membershipintroduction &
		From $\varphi$, deduce $\forall x . (x \in \varphi)$,
	    if $x \not\in \FV(\varphi)$.
		\\
		\membershipelimination &
		From $\forall x . (x \in \varphi)$, deduce $\varphi$,
		if $x \not\in \FV(\varphi)$.
		\\
		\membershipvariable &
		$(x \in y) = (x = y)$
		\\
		\membershipneg &
		$(x \in \neg \varphi) = \neg (x \in \varphi)$	
		\\
		\membershipwedge &
		$(x \in \varphi_1 \wedge \varphi_2) 
		= (x \in \varphi_1) \wedge (x \in \varphi_2)$	
		\\
		\membershipexists &
		$(x \in \exists y . \varphi) = \exists y . (x \in \varphi)$,
		where $x$ and $y$ distinct.
		\\
		\membershipsymbol &
		$x \in \Csigmaapp{\varphi}
		 = \exists y . (y \in \varphi) \wedge (x \in \Csigmaapp{y})$
		if $y \not\in \FV(\Csigmaapp{\varphi})$
	\end{tabular}
    \caption{Sound and Complete Proof System with Definedness Symbols}
    \label{fig_proofsystem_definedness}
\end{figure}

\begin{comment}
We denote the provability relation of 
this proof system with definedness symbols as ``$\vdashd$''
to distinguish it from the one that we defined in 
Definition~\ref{def_proof}.
Formally, we have the next definition.

\begin{definition}
	\label{def_proofd}
	Let $\Gamma$ be a set of patterns containing all instances of the
	axiom schema $\forall x . \ceil{x}$ for definedness symbols.
	
	The set of all theorems deduced from $\Gamma$ is defined as
	the smallest set that contains $\Gamma$
	and is closed under the proof rules of the proof system.
	If $\varphi$ is in the set of all theorems deduced from $\Gamma$,
	we write $\Gamma \vdash \varphi$
	and say $\varphi$ is a theorem of $\Gamma$.
	When $\Gamma$ is the empty set, 
	we abbreviate $\emptyset \vdash \varphi$ as just
	$\vdash \varphi$.
\end{definition}
\end{comment}

The proof system in Figure~\ref{fig_proofsystem_definedness}
contains rules that use equality and membership constructs,
so it cannot be used when definedness symbols are not
in the signature.
Its completeness is given through a reduction to predicate logic.
In contrary, the proof system in \Figure{fig_proofsystem}
is generic and does not depend on definedness symbols.
The technique we use to prove its completeness
(in Section~\ref{sec_sound_and_completeness})
is also different from~\cite{rosu-2017-lmcs}.

The main purpose of this section is to show that
all rules in Figure~\ref{fig_proofsystem_definedness}
are in fact derivable using our proof system
in Figure~\ref{fig_proofsystem} plus the definedness axioms.
Here are some quick ones.
Rule \propositionaltautology follows from
Proposition~\ref{prop_sound_FOL_reasoning}.
Rules \modusponens, \forallrule, and \universalgeneralization
are themselves rules in Figure~\ref{fig_proofsystem}.
To prove the rest,
we need some lemmas and a form of the Deduction Theorem.
To ease our notation, we refer to
Proposition~\ref{prop_sound_FOL_reasoning} as ``by FOL reasoning'',
Proposition~\ref{prop_framing} as ``by \eframing'',
and
Proposition~\ref{prop_propgation_of_symbol_application} as
``by \epropagation''.

We will see that many rules in modal logic have their
counterparts in matching logic.
Let us first define the compliment of a symbol.

\begin{definition}[Compliment of Symbols]
For any $\sigma \in \SigmaSub{s_1 \dots s_n, s}$,
define its compliment $\sigmabar$ as follows:
$$
\sigmabar(\varphi_1 \ddd \varphi_n) \equiv
\neg \sigma(\neg \varphi_1 \ddd \neg \varphi_n)
$$
%In particular when $n = 0$,
%$\sigmabar = \neg \sigma$.
%Similarly we can define the compliment of a context $C$ as follows:
%$$
%\Cbar[\varphi] = \neg C [ \neg \varphi ]
%$$
In particular, the compliment of the definedness symbol is denoted as
$\floor{\varphi} \equiv \neg \ceil{\neg \varphi}$.
Using this notation, the definition of equality can also be written as
$(\varphi_1 =_{s_1}^{s_2} \varphi_2) \equiv 
 \floor{\varphi_1 \dimp \varphi_2}_{s_1}^{s_2} $.
\end{definition}

We will see that the compliments of symbols are the counterparts of modalities
in model logic.

\begin{lemma}
\label{lemma_necessitation}
For any symbol context $C$,
$\Gamma \vdash \varphi$ implies
$\Gamma \vdash \neg C[\neg \varphi]$.
In particular, $\Gamma \vdash \varphi$ implies
$\Gamma \vdash \sigmabar(\dots, \varphi, \dots)$
for any symbol $\sigma$.
\end{lemma}
\begin{proof}\quad
\begin{center}
\begin{tabular}{l|ll}
1 & $\varphi$ & hypothesis \\
2 & $\neg \varphi \imp \bot$ & by 1, FOL reasoning \\
3 & $C[\neg \varphi] \imp C[\bot]$ 
  & by 2, \eframing \\
4 & $C[\bot] \imp \bot$ 
  & by \epropagation \\
5 & $C[\neg \varphi] \imp \bot$
  & by 3 and 4, FOL reasoning \\
6 & $\neg C[\neg \varphi]$
  & by 5, FOL reasoning
\end{tabular}
\end{center}
\end{proof}

\begin{remark}
When $\sigma$ takes exactly one argument,
$\Gamma \vdash \varphi$ implies $\Gamma \vdash \sigmabar(\varphi)$
is known as the \necessitation rule in modal logic.
\end{remark}

The next lemma is useful in establishing an equality.

\begin{lemma}
\label{lemma_equality_establishment}
$\Gamma \vdash \varphi_1 \dimp \varphi_2$ implies
$\Gamma \vdash \varphi_1 = \varphi_2$.
\end{lemma}
\begin{proof}\quad
\begin{center}
\begin{tabular}{l|ll}
		1 & $\varphi_1 \dimp \varphi_2$ & hypothesis \\
		2 & $\neg \ceil{\neg (\varphi_1 \dimp \varphi_2)}$ 
		  & by 1, Lemma~\ref{lemma_necessitation} \\
		3 & $\varphi_1 = \varphi_2$ 
		  & by 2, definition of equality
\end{tabular}
\end{center}
\end{proof}

\begin{lemma}
\label{lemma_equality_introduction}
\prule{Equality Introduction} is derivable.
\end{lemma}
\begin{proof}\quad
	\begin{center}
		\begin{tabular}{l|ll}
			1 & $\varphi \dimp \varphi$ 
			  & propositional tautology \\
			2 & $\varphi = \varphi$ 
			  & by 1, Lemma~\ref{lemma_equality_establishment}
		\end{tabular}
	\end{center}
\end{proof}

\begin{comment}
\begin{lemma}
\label{lemma_equality_implies_dimp}
$(\varphi_1 = \varphi_2) \imp (\varphi_1 \dimp \varphi_2)$ is derivable.
\end{lemma}
\begin{proof}
By definition of equality and FOL reasoning,
it suffices to derive
$\neg (\varphi_1 \dimp \varphi_2) 
\imp \ceil {\neg (\varphi_1 \dimp \varphi_2)}$.
The latter is derivable by Lemma~\ref{lemma_P_implies_ceil_P}.
\end{proof}
\end{comment}

\begin{lemma}
\membershipintroduction is derivable.
\end{lemma}
\begin{proof}\quad
\begin{center}
\begin{tabular}{l|ll}
1 & $\varphi$ & hypothesis \\
2 & $\varphi \to (x \to \varphi)$ & \prule{Proposition$_1$} \\
3 & $x \imp \varphi$ 
  & by 1 and 2, \modusponens  \\
4 & $x \imp x$ & propositional tautology \\
5 & $x \imp x \wedge \varphi$ & by 3 and 4, FOL reasoning\\
6 & $\ceil{x} \to \ceil{x \wedge \varphi}$ 
  & by 5, \framing \\
7 & $\ceil{x}$ & definedness axiom \\
8 & $\ceil{x \wedge \varphi}$ & by 6 and 7, \modusponens \\
9 & $x \in \varphi$ & by 8, definition of membership \\
10& $\forall x . (x \in \varphi)$ & by 9, \universalgeneralization
\end{tabular}
\end{center}
\end{proof}

\begin{lemma}
\membershipelimination is derivable.
\end{lemma}
\begin{proof}\quad
\begin{center}
\begin{tabular}{l|ll}
1 & $\forall x . (x \in \varphi)$ & hypothesis \\
2 & $(\forall x . (x \in \varphi)) \imp x \in \varphi$ & \prule{Variable 
Substitution} \\
3 & $x \in \varphi$ & by 1 and 2, \modusponens \\
4 & $\ceil{x \wedge \varphi}$ & by 3, definition of membership \\
5 & $\neg (\ceil{x \wedge \varphi} \wedge (x \wedge \neg \varphi)) $
  & \singletonvariable \\
6 & $\ceil{x \wedge \varphi} \imp (x \imp \varphi)$
  & by 5, FOL reasoning \\
7 & $x \imp \varphi$ & by 4 and 6, \modusponens \\
8 & $\forall x . (x \imp \varphi)$ 
  & by 7, \universalgeneralization \\
9 & $(\exists x . x) \imp \varphi$ 
  & by 8, FOL reasoning\\
10& $\exists x . x$ & \existence \\
11& $\varphi$ & by 10 and 9, \modusponens 
\end{tabular}
\end{center}
\end{proof}







\begin{lemma}
	\prule{Membership Variable} is derivable.
\end{lemma}
\begin{proof}
	By Lemma~\ref{lemma_equality_establishment},
	it suffices to show that both
	$(x \in y) \imp (x = y)$
	and
	$(x = y) \imp (x \in y)$
	are derivable.
	Let us first prove $(x = y) \imp (x \in y)$ is derivable.

\begin{center}
	\begin{tabular}{l|ll}
		1 & $\ceil{x}$ & definedness axiom \\
		2 & $\ceil{x} \vee \ceil{y}$ & by 1, FOL reasoning \\
		3 & $\ceil{x \vee y}$ 
		  & by 2, \Prop{prop_propgation_of_symbol_application} \\
		4 & $\ceil{\neg (x \dimp y) \vee (x \wedge y)}$
		  & by 3, FOL reasoning \\
		5 & $\ceil{\neg (x \dimp y)} \vee \ceil{x \wedge y}$
		  & by 4, \Prop{prop_propgation_of_symbol_application} \\
		6 & $\neg \ceil{\neg (x \dimp y)} \imp \ceil{x \wedge y} $
		  & by 5, FOL reasoning \\
		7 & $(x = y) \imp (x \in y)$ 
		  & by 6, definition of equality and membership
	\end{tabular}
\end{center}

Let us now prove 	$(x \in y) \imp (x = y)$ is derivable.

\begin{center}
	\begin{tabular}{l|ll}
		1 & $\neg (\ceil{x \wedge y} \wedge \ceil{x \wedge \neg y})$ 
		  & by \singletonvariable \\
		2 & $\neg (\ceil{x \wedge y} \wedge \ceil{\neg x \wedge y})$ 
		  & by \singletonvariable \\
		3 & $\ceil{x \wedge y} \imp \neg \ceil{x \wedge \neg y}$
		  & by 1, FOL reasoning\\
		4 & $\ceil{x \wedge y} \imp \neg \ceil{\neg x \wedge y}$
		  & by 2, FOL reasoning \\
		5 & $\ceil{x \wedge y} \imp
		     \neg \ceil{x \wedge \neg y} \wedge
		     \neg \ceil{\neg x \wedge y}$
		  & by 3 and 4, FOL reasoning\\
		6 & $\ceil{x \wedge y} \imp
		  \neg (\ceil{x \wedge \neg y} \vee
		        \ceil{\neg x \wedge y})$
		  & by 5, FOL reasoning \\
		7 & $\ceil{x \wedge y} \imp 
		      \neg \ceil{(x \wedge \neg y) \vee (\neg x \wedge y)} $
		  & by 6, \Prop{prop_propgation_of_symbol_application} \\
		8 & $\ceil{x \wedge y} \imp 
		     \neg \ceil{\neg (x \dimp y)} $
		  & by 7, FOL reasoning\\
		9 & $(x \in y) \imp (x = y)$
		  & by 8, definition of equality and membership
	\end{tabular}
\end{center}

\end{proof}

\begin{lemma}
	\label{lemma_membership_neg}
	\membershipneg is derivable.
\end{lemma}
\begin{proof}
We first prove $(x \in \neg \varphi) \imp \neg (x \in \varphi)$ is derivable.
\begin{center}
	\begin{tabular}{l|ll}
		1 & $\neg (\ceil{x \wedge \varphi} \wedge 
		           \ceil{x \wedge \neg \varphi})$ 
		  & by \singletonvariable \\
		2 & $\ceil{x \wedge \neg \varphi} \imp \neg \ceil{x \wedge \varphi}$
	      & by 1, FOL reasoning \\
		3 & $(x \in \neg \varphi) \imp \neg (x \in \varphi)$
		  & by 2, definition of membership
	\end{tabular}
\end{center}
We then prove
$\neg (x \in \varphi) \imp (x \in \neg \varphi)$ is derivable.
\begin{center}
	\begin{tabular}{l|ll}
		1 & $\ceil{x}$ & definedness axiom \\
		2 & $\ceil{(x \wedge \varphi) \vee (x \wedge \neg \varphi)}$
		  & by 1, FOL reasoning \\
		3 & $\ceil{x \wedge \varphi} \vee \ceil{x \wedge \neg \varphi}$
		  & by 2, \Prop{prop_propgation_of_symbol_application} \\
		4 & $ \neg \ceil {x \wedge \varphi} \imp \ceil{x \wedge \neg \varphi}$
		  & by 3, FOL reasoning \\
		5 & $ \neg (x \in \varphi) \imp (x \in \neg \varphi)$
		  & by 4, definition of membership
	\end{tabular}
\end{center}
\end{proof}

\begin{lemma}
\label{lemma_membership_vee}
	$(x \in (\varphi_1 \vee \varphi_2)) \dimp 
	 (x \in \varphi_1) \vee (x \in \varphi_2)$ 
	 is derivable.
\end{lemma}
\begin{proof}
	Use \propagationvee and FOL reasoning.
\end{proof}

\begin{lemma}
	\membershipwedge is derivable.
\end{lemma}
\begin{proof}
Use Lemma~\ref{lemma_membership_neg} and~\ref{lemma_membership_vee},
and the fact that
$\varphi_1 \wedge \varphi_2 \dimp \neg (\neg \varphi_1 \vee \neg \varphi_2)$
 is derivable.
\end{proof}

\begin{lemma}
	\membershipexists is derivable.
\end{lemma}
\begin{proof}
	Use \propagationexists and FOL reasoning.
\end{proof}

\begin{comment}
\begin{lemma}
\label{lemma_P_implies_ceil_P}
$\varphi \imp \ceil{\varphi}$ is derivable.
\end{lemma}
\begin{proof}
Let $x$ be a variable that does not occur free in $\varphi$.
\begin{center}
\begin{tabular}{l|ll}
	1 & $\ceil{x}$ & definedness axiom \\
	2 & $x \imp (x \wedge \neg \varphi) \vee \varphi$
	  & propositional tautology \\
	3 & $\ceil{x} \imp \ceil{(x \wedge \neg \varphi) \vee \varphi}$
	  & by 2, \framing \\
	4 & $\ceil{(x \wedge \neg \varphi) \vee \varphi}$
	  & by 1 and 3, \modusponens \\
	5 & $\ceil{x \wedge \neg \varphi} \vee \ceil{\varphi}$
	  & by 4, \Prop{prop_propgation_of_symbol_application} \\
	6 & $\neg \ceil{x \wedge \neg \varphi} \imp \ceil{\varphi}$
	  & by 5, FOL reasoning \\
	7 & $(x \wedge \varphi) \imp \neg \ceil{x \wedge \neg \varphi}$
	  & by \singletonvariable and FOL reasoning \\
	8 & $x \wedge \varphi \imp \ceil{\varphi}$
	  & by 7 and 6, FOL reasoning \\
	9 & $x \imp (\varphi \imp \ceil{\varphi})$
	  & by 8, FOL reasoning \\
	10& $\forall x . (x \imp (\varphi \imp \ceil{\varphi}))$
	  & by 9, \universalgeneralization \\
	11& $(\exists x . x) \imp (\varphi \imp \ceil{\varphi})$
	  & by 10, FOL reasoning \\
	12& $\exists x . x$
	  & by \existence \\
	13& $\varphi \imp \ceil{\varphi}$
	  & by 12 and 11, \modusponens
\end{tabular}
\end{center}
\end{proof}
\end{comment}

The following is a useful lemma about the definedness symbols.

\begin{lemma}
\label{lemma_sigmacontext_implies_ceil}
For any symbol context $C$,
$\Capp{\varphi} \imp \ceil{\varphi}$
is derivable.
\end{lemma}
\begin{proof}
Let $x$ be a variable that does not occur free in $\varphi$
and $\Capp{\varphi}$ in the following proof.
\begin{center}
\begin{tabular}{l|ll}
1 & $\ceil{x}$
  & definedness axiom \\
2 & $\ceil{x} \vee \ceil{\varphi}$
  & by 1, FOL reasoning \\
3 & $\ceil{x \vee \varphi}$
  & by 2, Proposition~\ref{prop_propgation_of_symbol_application} \\
4 & $\ceil{x \wedge \neg \varphi \vee \varphi}$
  & by 3, FOL reasoning and 
          Proposition~\ref{prop_congruence_provability_equiv}\\
5 & $\ceil{x \wedge \neg \varphi} \vee \ceil{\varphi}$
  & by 4, Proposition~\ref{prop_propgation_of_symbol_application} \\
6 & $\Capp{x \wedge \varphi} \imp \neg \ceil{x \wedge \neg \varphi}$
  & by \singletonvariable and FOL reasoning \\
7 & $\neg \ceil{x \wedge \neg \varphi} \imp \ceil{\varphi}$
  & by 5, FOL reasoning \\
8 & $\Capp{x \wedge \varphi} \imp \ceil{\varphi}$
  & by 6 and 7, FOL reasoning \\
9 & $\forall x . (\Capp{x \wedge \varphi} \imp \ceil{\varphi})$
  & by 8, \universalgeneralization \\
10& $(\exists x . \Capp{x \wedge \varphi}) \imp \ceil{\varphi}$
  & by 9, FOL reasoning \\
11& $\varphi \imp (\exists x . x) \wedge \varphi$
  & by \existence and FOL reasoning \\
12& $\varphi \imp \exists x . (x \wedge \varphi)$
  & by 11, FOL reasoning \\
13& $\Capp{\varphi} \imp \Capp{\exists x . (x \wedge \varphi)}$ 
  & by 12, \eframing \\
14& $\Capp{\exists x . (x \wedge \varphi)} \imp \ceil{\varphi}$
  & by 10, Proposition~\ref{prop_propgation_of_symbol_application} \\
15& $\Capp{\varphi} \imp \ceil{\varphi}$
  & by 13 and 14, FOL reasoning
\end{tabular}
\end{center}
\end{proof}

\begin{corollary}
\label{cor_symbolcontext_implies_ceil}
For any symbol $\sigma$, 
$\Csigma[\varphi] \imp \ceil{\varphi}$
and 
$\floor{\varphi} \imp \neg \Csigma[ \neg \varphi] $
is derivable.
In particular, 
$\varphi \imp \ceil{\varphi}$
and
$\floor {\varphi} \imp \varphi$ is derivable.
\end{corollary}

Definedness symbols are important.
Corollary~\ref{cor_symbolcontext_implies_ceil}
suggests that definedness symbols are the ``maximal'' among all symbols.
In fact, this observation is endorsed by its semantics.
In any model $\MM = (M, \interpM)$, 
the definedness symbol $\ceil{\_}$
has to be interpreted to the constant function
$\ceil{\_}_\MM \colon M \to \pset{M}$
where $\ceil{a} = M$ for every $a \in M$.

Definedness symbols also give us a nice form of deduction theorem as follows.

\begin{theorem}[Deduction Theorem]
\label{thm_deduction_theorem}
	For any set $\Gamma$ of patterns and any patterns $\varphi$ and $\psi$,
	if $\Gamma \cup \{ \psi \} \vdash \varphi$ and the proof does not use
	\universalgeneralization on variables that occur free in $\psi$,
	then $\Gamma \vdash \floor{\psi} \imp \varphi$.
	In particular, if $\psi$ is closed,
	then $\Gamma \cup \{ \psi \} \vdash \varphi$
	implies $\Gamma \vdash \floor{\psi} \imp \varphi$.
\end{theorem}

The verbose condition about \universalgeneralization
is known to be necessary for the deduction theorem in FOL, 
too~\cite{hamilton1988logic}.
We will use deduction theorem to prove that
\equalityelimination is derivable, and in there the premise pattern
$\psi$ might not be a close pattern.
Therefore, we need this more general deduction theorem as stated above.
The case when $\psi$ is actually closed is a special case.

Readers familiar with modal logics should not find the conclusion
$\Gamma \vdash \floor{\psi} \imp \varphi$ unusual.
For example in~\cite{rosu-2016-rv}, the author gave a similar form of
the deduction theorem for finite-trace linear temporal logic.


\begin{proof}
The proof is based on the length of
the derivation
$\Gamma \cup \{\psi\} \vdash \varphi$.
If the length is one, then the derivation consists of just
$\varphi$ itself.
Therefore, either $\varphi$ is an axiom of the proof system,
or $\varphi \in \Gamma$, or $\varphi$ is $\psi$.
In either case, it is obvious that
$\Gamma \vdash \floor{\psi} \to \varphi$
(noticing Corollary~\ref{cor_symbolcontext_implies_ceil}
 for the case $\varphi$ is~$\psi$).
 
Now assume the conclusion holds for every pattern whose derivation is less than 
or equal to $n$ steps for some $n \ge 1$.
Assume $\varphi$ has a derivation $\Gamma \cup \{\psi\} \vdash \varphi$
of length~$n+1$: 
$$\varphi_1 \ddd \varphi_n , \varphi.$$
If $\varphi$ is an axiom, or $\varphi \in \Gamma$,
or $\varphi$ is $\psi$,
for the same reason as above,
$\Gamma \vdash \floor{\psi} \imp \varphi$.
If $\varphi$ is derived by applying \modusponens
on $\varphi_i$ and $\varphi_j$ for some
$1 \le i, j \le n$
such that $\varphi_j$ has the form $\varphi_i \imp \varphi$,
by induction hypothesis,
$\Gamma \vdash \floor{\psi} \imp \varphi_i$
and
$\Gamma \vdash \floor{\psi} \imp (\varphi_i \imp \varphi)$.
By FOL reasoning,
$\Gamma \vdash \floor{\psi} \imp \varphi$.
If $\varphi$ is derived by applying \universalgeneralization
on $\varphi_i$ for some $1 \le i \le n$,
then $\varphi$ must have the form $\forall x . \varphi_i$
where $x$ does not occur free in $\psi$.
By induction hypothesis,
$\Gamma \vdash \floor{\psi} \imp \varphi_i$.
By FOL reasoning,
$\Gamma \vdash \floor{\psi} \imp \forall x . \varphi_i$.

If $\varphi$ is derived by applying \framing on $\varphi_i$ for some
$1 \le i \le n$,
then $\varphi_i$ must have the form $\varphi'_i \imp \varphi''_i$,
and $\varphi$ must have the form 
$\Csigmaapp{\varphi'_i} \imp \Csigmaapp{\varphi''_i}$ for some symbol $\sigma$.
By induction hypothesis,
$\Gamma \vdash \floor{\psi} \imp (\varphi'_i \imp \varphi''_i)$.
We now prove 
$\floor{\psi} \imp (\Csigmaapp{\varphi'_i} \imp 
\Csigmaapp{\varphi''_i})$
is derivable.
\begin{center}
\begin{tabular}{l|ll}
1 & $\floor{\psi} \imp (\varphi'_i \imp \varphi''_i)$
  & hypothesis \\
2 & ${\varphi'_i}
     \imp {\varphi''_i} \vee \ceil{\neg \psi}$
  & by 1, FOL reasoning \\
3 & $\Csigmaapp{\ceil{\neg \psi}}
      \imp \ceil{\neg \psi}$
  & Corollary~\ref{cor_symbolcontext_implies_ceil} \\
4 & $\Csigmaapp{\varphi'_i}
      \imp \Csigmaapp{\varphi''_i \vee \ceil{\neg \psi}}$ 
  & by 2, \eframing \\
5 & $\Csigmaapp{\varphi'_i}
      \imp \Csigmaapp{\varphi''_i} \vee \Csigmaapp{\ceil{\neg \psi}}$ 
  & by 4, Proposition~\ref{prop_propgation_of_symbol_application} \\
6 & $\Csigmaapp{\varphi''_i} \vee \Csigmaapp{\ceil{\neg \psi}}
     \imp \Csigmaapp{\varphi''_i} \vee \ceil{\neg \psi} $
  & by 3, FOL reasoning \\
7 & $\Csigmaapp{\varphi'_i}
     \imp \Csigmaapp{\varphi''_i} \vee \ceil{\neg \psi} $ 
  & by 5 and 6, FOL reasoning \\
8 & $\floor{\psi} 
     \imp (\Csigmaapp{\varphi'_i} \imp \Csigmaapp{\varphi''_i})$ 
  & by 7, FOL reasoning \\
\end{tabular}
\end{center}
\end{proof}

The main difference between the deduction theorem in matching logic
and the one in FOL is that when we move a pattern $\psi$ from
the hypothesis set $\Gamma$ to the right of the derivation,
we should use $\floor{\psi}$ instead of just $\psi$.
In fact, $\Gamma \cup \{ \psi \} \vdash \varphi$ does not always
imply $\Gamma \vdash \psi \imp \varphi$.
Consider the following simple example.
By Lemma~\ref{lemma_necessitation},
it is easy to show that for every pattern $\psi$,
$\{ \psi \} \vdash \floor{\psi}$.
However, $\psi \imp \floor{\psi}$ is not a valid pattern.
According to the soundness of our proof system
(see Section~\ref{sec_soundness}),
$\psi \imp \floor{\psi}$ must not be provable.

\begin{lemma}
\label{lemma_equality_elim_derivable}
\equalityelimination is derivable.
\end{lemma}
\begin{proof}
Recall the definition of equality
$(\varphi_1 = \varphi_2) \equiv \floor{\varphi_1 \dimp \varphi_2}$.
Theorem~\ref{thm_deduction_theorem} together with
Proposition~\ref{prop_congruence_provability_equiv} give us
a nice way to deal with equality premises.
To show
$(\varphi_1 = \varphi_2)
 \imp (\psi[\varphi_1 / x] \imp \psi[\varphi_2 / x])$
is derivable, 
it suffices to show
$\{ \varphi_1 \dimp \varphi_2 \} \vdash 
 \psi[\varphi_1 / x] \imp \psi[\varphi_2 / x]$
and the proof does not use \universalgeneralization on any variable
that occurs free in $\varphi_1$ or~$\varphi_2$.
Fortunately, the proof given by 
Proposition~\ref{prop_congruence_provability_equiv}
does not use \universalgeneralization at all, and here ends the proof.
\end{proof}

\begin{lemma}
\functionalsubstitution is derivable.
\end{lemma}
\begin{proof}
Let $z$ be a fresh variable that does not occur free
in $\varphi$ and $\varphi'$, and is distinct from $x$.
Notice the side condition that $y$ does not occur free in $\varphi'$.
\begin{center}
\begin{tabular}{l|ll}
1 & $\varphi' = z \dimp z = \varphi'$
  & definition of equality, Proposition~\ref{prop_congruence_provability_equiv},
    \\ && and FOL reasoning \\
2 & $z = \varphi'
     \imp (\varphi[z / x] \imp \varphi[\varphi'/x])$ 
  & \equalityelimination and Lemma~\ref{lemma_equality_elim_derivable} \\
3 & $( \forall x . \varphi) \imp \varphi[z/x]$
  & \variablesubstitution \\
4 & $\varphi' = z
     \imp (( \forall x . \varphi) \imp \varphi[z / x]  )$ 
  & by 3, FOL reasoning \\
5 & $\varphi' = z
     \imp (\varphi[z / x] \imp \varphi[\varphi'/x])$ 
  & by 2 and 1, FOL reasoning \\
6 & $\varphi' = z
     \imp (( \forall x . \varphi) \imp \varphi[\varphi'/x] )$ 
  & by 4 and 5, FOL reasoning \\
7 & $\forall z . (\varphi' = z
     \imp (( \forall x . \varphi) \imp \varphi[\varphi'/x] ))$ 
  & by 6, \universalgeneralization \\
8 & $(\exists z . \varphi' = z)
     \imp ( (\forall x . \varphi) \imp \varphi[\varphi'/x] )$ 
  & by 7, FOL reasoning \\
9 & $(\forall x . \varphi) \wedge (\exists z . \varphi' = z)
		\imp \varphi[\varphi'/x]$
  & by 8, FOL reasoning \\
10& $(\forall x . \varphi) \wedge (\exists y . \varphi' = y)
		\imp \varphi[\varphi'/x]$
  & by 9, FOL reasoning
\end{tabular}
\end{center}
\end{proof}

The rest of the section is devoted to show that
\membershipsymbol is derivable.
We first establish some lemmas.

\begin{lemma}
\label{lemma_propagate_membership_in_application}
$\Csigmaapp{\varphi_1 \wedge (x \in \varphi_2)}
 = \Csigmaapp{\varphi_1} \wedge (x \in \varphi_2)$ is derivable.
\end{lemma}

\begin{proof}
We first derive
$\Csigmaapp{\varphi_1 \wedge (x \in \varphi_2)}
 \imp \Csigmaapp{\varphi_1} \wedge (x \in \varphi_2)$.
By FOL reasoning, it suffices to show
$\Csigmaapp{\varphi_1 \wedge (x \in \varphi_2)}
 \imp \Csigmaapp{\varphi_1}$
and
$\Csigmaapp{\varphi_1 \wedge (x \in \varphi_2)}
 \imp (x \in \varphi_2)$
are both derivable.
The first follows immediately by \framing and FOL reasoning.
The second can be derived in the following way.
\begin{center}
\begin{tabular}{l|ll}
1 & $\ceil{x}$
  & definedness axiom \\
2 & $\ceil{(x \wedge \neg \varphi_2) \vee (x \wedge \varphi_2)}$
  & by 1, FOL reasoning and
    Proposition~\ref{prop_congruence_provability_equiv} \\
3 & $\ceil{x \wedge \neg \varphi_2} \vee \ceil{x \wedge \varphi_2}$
  & by 2, \propagationvee and FOL reasoning \\
4 & $\neg \ceil{x \wedge \neg \varphi_2}
          \imp \ceil{x \wedge \varphi_2}$
     & by 3, FOL reasoning \\
5 & $\Csigmaapp{\ceil{x \wedge \varphi_2}}
      \imp \neg \ceil{x \wedge \neg \varphi_2}$
  & by \singletonvariable and FOL reasoning \\
6 & $\Csigmaapp{\ceil{x \wedge \varphi_2}}
      \imp \ceil{x \wedge \varphi_2}$ 
  & by 5 and 4, FOL reasoning \\
7 & $\Csigmaapp{\varphi_1 \wedge \ceil{x \wedge \varphi_2}}
     \imp \Csigmaapp{\ceil{x \wedge \varphi_2}}$
  & by \framing and FOL reasoning \\
8 & $\Csigmaapp{\varphi_1 \wedge \ceil{x \wedge \varphi_2}}
     \imp \ceil{x \wedge \varphi_2}$ 
  & definedness axiom \\
9 & $\Csigmaapp{\varphi_1 \wedge (x \in \varphi_2)}
     \imp (x \in \varphi_2)$ 
  & by 8, definition of membership \\
\end{tabular}
\end{center}
We now derive 
$\Csigmaapp{\varphi_1} \wedge (x \in \varphi_2)
 \imp \Csigmaapp{\varphi_1 \wedge (x \in \varphi_2)}$.

\end{proof}

\begin{comment}
\begin{lemma}
\label{lemma_definedness_lemma_C}
For any pattern set $\Gamma$,
any symbol $\sigma$,
and any pattern $\varphi$,
$\Gamma \vdash (x = y) \wedge \Csigmaapp{\varphi}
= \Csigmaapp{(x = y) \wedge \varphi }$,
if $x$ and $y$ are distinct, and $x$ does not occur free in $\varphi$.
\end{lemma}
\begin{proof}
Just use Lemma~\ref{lemma_propagate_membership_in_application}.

We first show
$\Gamma \vdash \Csigmaapp{(x = y) \wedge \varphi } \imp (x = y) \wedge 
\Csigmaapp{\varphi}$.
In fact, it follows immediately from \framing and
FOL reasoning.
We now show
$\Gamma \vdash (x = y) \wedge \Csigmaapp{\varphi}
\imp \Csigmaapp{(x = y) \wedge \varphi }$
\todo[inline]{Finish this proof.}
\end{proof}
\end{comment}

\begin{lemma}
\label{lemma_equality_lemma_A}
$\exists y . ((x = y)\wedge \varphi) = \varphi[x/y] $
is derivable,
if $x$ and $y$ are distinct variables.
\end{lemma}
\begin{proof}\quad
The proof is by induction on the structural of $\varphi$
and using Lemma~\ref{lemma_propagate_membership_in_application}.
\end{proof}

\begin{comment}

\begin{lemma}
\label{lemma_definedness_lemma_A}
For any pattern set $\Gamma$ and pattern $\varphi$,
$\Gamma \vdash 
  \ceil{ x \wedge \ceil{y \wedge \varphi}} = \ceil{ y \wedge \varphi }$, 
  where $x$ and $y$ are not necessarily distinct.
\end{lemma}
\begin{proof}
We first prove
$\Gamma \vdash
  \ceil{ y \wedge \varphi } \imp 
  \ceil{ x \wedge \ceil{y \wedge \varphi}}$,
which follows directly from \framing and FOL reasoning,
and the fact that 
$\Gamma \vdash (y \wedge \varphi) \imp \ceil{y \wedge \varphi}$
by Lemma~\ref{lemma_P_implies_ceil_P}.
We now prove
$\Gamma \vdash 
  \ceil{ x \wedge \ceil{y \wedge \varphi}} \imp \ceil{ y \wedge \varphi }$.
\todo[inline]{Finish this proof.}
\end{proof}

\end{comment}



\begin{lemma}
\label{lemma_membership_lemma_A}
$\varphi = \exists y . ( \ceil{y \wedge \varphi} \wedge y)$
is derivable,
if $y$ does not occur free in $\varphi$.
\end{lemma}
\begin{proof}
We first derive
$\exists y . ( \ceil{y \wedge \varphi} \wedge y) \imp \varphi$.
\begin{center}
\begin{tabular}{l|ll}
1 & $\neg (\ceil{y \wedge \varphi} \wedge (y \wedge \neg \varphi))$ 
  & \singletonvariable \\
2 & $\ceil{y \wedge \varphi} \wedge y \imp \varphi$
  & by 1, FOL reasoning \\
3 & $\forall y . (\ceil{y \wedge \varphi} \wedge y \imp \varphi)$
  & by 2, \universalgeneralization \\
4 & $\exists y . (\ceil{y \wedge \varphi} \wedge y) \imp \varphi$
  & by 3, FOL reasoning
\end{tabular}
\end{center}
We then derive
$\varphi \imp \exists y . ( \ceil{y \wedge \varphi} \wedge y)$.
Let $x$ be a fresh variable distinct from $y$.
\begin{center}
\begin{tabular}{l|ll}
1 & $x \in \varphi \imp x \in \varphi$
  & propositional tautology \\
2 & $x \in \varphi \imp \ceil{x \wedge \varphi}$
  & by 1, definition of membership \\
3 & $x \in \varphi \imp \ceil{ x \wedge \ceil{x \wedge \varphi}}$
  & by 2, Lemma~\ref{lemma_propagate_membership_in_application}
          and FOL reasoning \\
4 & $x \in \varphi \imp x \in \ceil{x \wedge \varphi}$
  & by 3, definition of membership \\
5 & $x \in \varphi \imp 
     \exists y . (x = y \wedge x \in \ceil{y \wedge \varphi})$
  & by 4, Lemma~\ref{lemma_equality_lemma_A} and FOL reasoning \\
6 & $x \in \varphi \imp 
     \exists y . (x \in y \wedge x \in \ceil{y \wedge \varphi})$
  & by 5, \membershipvariable and FOL reasoning \\
7 & $x \in \varphi \imp 
     \exists y . (x \in (y \wedge \ceil{y \wedge \varphi}))$
  & by 6, \membershipwedge and FOL reasoning \\
8 & $x \in \varphi \imp 
     x \in \exists y . (y \wedge \ceil{y \wedge \varphi})$
  & by 7, \membershipexists and FOL reasoning \\
9 & $x \in (\varphi \imp \exists y . (y \wedge \ceil{y \wedge \varphi}))$
  & by 8, \membershipneg, \membershipwedge, and FOL reasoning \\
10& $\forall x . 
     (x \in (\varphi \imp \exists y . (y \wedge \ceil{y \wedge \varphi})))$
  & by 9, \universalgeneralization \\
11& $\varphi \imp \exists y . (y \wedge \ceil{y \wedge \varphi})$
  & by 10, \membership
\end{tabular}
\end{center}
\end{proof}

\begin{comment}

\begin{lemma}
\label{lemma_definedness_lemma_B}
For any pattern set $\Gamma$, any symbol $\sigma$, and pattern $\varphi$,
$\Gamma \vdash 
  \Csigmaapp{\ceil{y \wedge \varphi} \wedge y} =
  \Csigmaapp{y} \wedge \ceil{y \wedge \varphi}$,
where $y$ does not occur free in $\varphi$.
\end{lemma}
\begin{proof}
We first derive
$\Csigmaapp{\ceil{y \wedge \varphi} \wedge y} \imp
  \Csigmaapp{y} \wedge \ceil{y \wedge \varphi}$.
\todo[inline]{Finish this proof.}
\end{proof}

\end{comment}

\begin{lemma}
\membershipsymbol is derivable.
\end{lemma}
\begin{proof}
We first derive
$ x \in \Csigmaapp{\varphi} 
\imp \exists y . ( y \in \varphi \wedge x \in \Csigmaapp{y} ) $.
Let
$\Psi \equiv \exists y . ( y \in \varphi \wedge x \in \Csigmaapp{y} )$.
\begin{center}
\begin{tabular}{l|ll}
1 & $\exists y . ( y \in \varphi \wedge x \in \Csigmaapp{y} ) \imp \Psi$ 
  & propositional tautology \\
2 & $\exists y . ( \ceil{y \wedge \varphi} \wedge x \in \Csigmaapp{y} ) \imp 
\Psi$
  & by 1, definition of membership \\
3 & $\exists y . ( \ceil{x \wedge \ceil{y \wedge \varphi}} \wedge x \in 
\Csigmaapp{y} ) 
     \imp \Psi$
  & by 2, Lemma~\ref{lemma_propagate_membership_in_application}
          and FOL reasoning \\
4 & $\exists y . ( x \in \ceil{y \wedge \varphi} \wedge x \in \Csigmaapp{y} ) 
     \imp \Psi$
  & by 3, definition of membership \\
5 & $\exists y . ( x \in (\ceil{y \wedge \varphi} \wedge \Csigmaapp{y}) ) \imp 
\Psi$
  & by 4, \membershipwedge and FOL reasoning \\
6 & $ x \in \exists y . (\ceil{y \wedge \varphi} \wedge \Csigmaapp{y})  \imp 
\Psi$
  & by 5, \membershipexists and FOL reasoning \\
7 & $ x \in \exists y . \Csigmaapp{\ceil{y \wedge \varphi} \wedge y}  \imp \Psi$
  & by 6, Lemma~\ref{lemma_propagate_membership_in_application}
          and FOL reasoning \\
8 & $ x \in \Csigmaapp{\exists y . \ceil{y \wedge \varphi} \wedge y}  \imp \Psi$
  & by 7, \propagationexists and FOL reasoning \\
9 & $ x \in \Csigmaapp{\varphi}  \imp \Psi$
  & by 8, Lemma~\ref{lemma_membership_lemma_A} and FOL reasoning
\end{tabular}
\end{center}
\end{proof}
We then derive
$ \exists y . ( y \in \varphi \wedge x \in C[y] )
\imp x \in C[\varphi]$.
In fact, we just need to apply the same derivation as above on
$\Psi \imp \exists y . ( y \in \varphi \wedge x \in C[y] )$.







It is known that the proof system in \Figure{fig_proofsystem_definedness} is 
complete.
And we just showed that all its proof rules are derivable using the proof 
system in \Figure{fig_proofsystem} plus the definedness axioms.
This leads us to the following completeness result.

\begin{proposition}[Completeness with Definedness Symbols]
Let $\Sigma$ be a signature with definedness symbols. Let $\Gamma$ be a set of 
$\Sigma$-patterns containing all instances of the definedness axioms.
For any pattern $\varphi$ such that $\Gamma \vDash \varphi$, 
we have $\Gamma \vdash \varphi$.
\end{proposition}
\begin{proof}
Since $\Gamma \vDash \varphi$, by completeness of the proof system in 
\Figure{fig_proofsystem_definedness}, there exists a formal proof
$\varphi_1, \dots, \varphi_n$
where $n \ge 1$ and $\varphi_n \equiv \varphi$, and 
for any $i \in \{1 \ddd n\}$, either $\varphi_i$ is an axiom in 
\Figure{fig_proofsystem_definedness}, or it is a conclusion of applying a 
proof rule in 
\Figure{fig_proofsystem_definedness} on some $\varphi_j$'s for some 
$j \in \{1 \ddd i-1\}$.
On the other hand, we have proved that all proof rules in 
\Figure{fig_proofsystem_definedness} are derivable using the proof system in
\Figure{fig_proofsystem} plus the definedness axioms.
This means that we can take the formal proof $\varphi_1 \ddd \varphi_n$ and 
turn it into a formal proof of $\varphi$ using the proof system in
\Figure{fig_proofsystem}, and thus prove that $\Gamma \vdash \varphi$.
We leave the details of the proof to readers.
\end{proof}


\section{Soundness and Completeness of the Proof System}
\label{sec_soundness_and_completeness}

\subsection{Soundness}
\label{sec_soundness}

\begin{restatable}[Soundness]{theorem}{soundness}
\label{thm_soundness}
For any pattern set $\Gamma$ and pattern $\varphi$,
$\Gamma \vdash \varphi$ implies $\Gamma \vDash \varphi$.
\end{restatable}
The proof of Theorem~\ref{thm_soundness} is by induction on the
length of the $\Gamma$-proof of $\varphi$.
Let us first prove a lemma that establishes
the soundness of each rule.

\begin{lemma}
\label{lemma_soundness_lemma}
The following hold:
\begin{enumerate}
	\item $ \vDash \varphi_1 \imp (\varphi_2 \imp \varphi_1)$
	\item $ \vDash \varphi_1 \imp (\varphi_2 \imp \varphi_3)
	\imp (\varphi_1 \imp \varphi_2)
	\imp (\varphi_1 \imp \varphi_3)$
	\item $ \vDash (\neg \varphi_1 \imp \neg \varphi_2)
	\imp (\varphi_2 \imp \varphi_1)$
	\item $ \MM,\rho \vDash \varphi_1$ and
	$ \MM,\rho \vDash \varphi_1 \imp \varphi_2$
	imply
	$ \MM,\rho \vDash \varphi_2$
	\item $ \vDash \forall x . \varphi \imp \varphi[y/x]$
	\item $ \vDash \forall x . (\varphi_1 \imp \varphi_2)
	\imp \varphi_1 \imp \forall x . \varphi_2$
	if $x \not\in \FV(\varphi_1)$
	\item $ \MM \vDash \varphi$
	implies
	$ \MM \vDash \forall x . \varphi$
	\item $ \vDash \CSub{\sigma}[\bot] \imp \bot$
	\item $ \vDash \CSub{\sigma}[\varphi_1 \vee \varphi_2]
	\imp \CSub{\sigma}[\varphi_1] 
	\vee \CSub{\sigma}[\varphi_2]$
	\item $ \vDash \CSub{\sigma}[\exists x . \varphi]
	\imp \exists x . \CSub{\sigma}[\varphi]$
	if $x \not\in \FV(\Csigmaapp{\exists x . \varphi})$
	\item $ \MM,\rho \vDash \varphi_1 \imp \varphi_2$
	implies
	$ \MM,\rho \vDash \CSub{\sigma}[\varphi_1] 
	\imp \CSub{\sigma}[\varphi_2]$
	\item $ \vDash \exists x . x$
	\item $ \vDash \neg (C_1[x \wedge \varphi] 
	\wedge C_2[x \wedge \neg \varphi])$
\end{enumerate}
where $\varphi,\varphi_1,\varphi_2,\varphi_3$ are patterns, 
$x,y$ are variables,
$\sigma \in \Sigma$,
$C_\sigma$ is a symbol context,
$\MM$ is a model,
and $\rho$ is a valuation.
\end{lemma}
\begin{proof}
	Some of the propositions are proved in~\cite{rosu-2017-lmcs}.
	To make this paper self-contained, we present the proof of all propositions.
	Let $\MM$ by a model and $\rho$ be a valuation.
	
	(1)
	$\barrho(\varphi_1 \imp (\varphi_2 \imp \varphi_1))
	= \barrho(\neg \varphi_1)
	\cup
	\barrho(\varphi_2 \imp \varphi_1)
	= (M \setminus \barrho(\varphi_1))
	\cup \barrho(\neg \varphi_2)
	\cup \barrho(\varphi_1)
	= M$.
	
	(2)
	$\barrho(\varphi_1 \imp (\varphi_2 \imp \varphi_3)
	\imp (\varphi_1 \imp \varphi_2)
	\imp (\varphi_1 \imp \varphi_3))
	= \barrho(\neg (\varphi_1 \imp (\varphi_2 \imp \varphi_3)))
	\cup
	\barrho((\varphi_1 \imp \varphi_2)
	\imp (\varphi_1 \imp \varphi_3))
	= (\barrho(\varphi_1) 
	\cap (\barrho(\neg (\varphi_2 \imp \varphi_3)))
	\cup
	\barrho(\neg (\varphi_1 \imp \varphi_2))
	\cup
	\barrho(\varphi_1 \imp \varphi_3)
	= (\barrho(\varphi_1) 
	\cap \barrho(\varphi_2) 
	\cap (M \setminus \barrho(\varphi_3)))
	\cup
	(\barrho(\varphi_1) \cap (M \setminus \barrho(\varphi_2)))
	\cup (M \setminus \barrho(\varphi_1)) \cup \barrho(\varphi_3)
	= M.
	$
	
	(3)
	$\barrho(\neg \varphi_1 \imp \neg \varphi_2)
	\imp (\varphi_2 \imp \varphi_1)
	= \barrho(\neg (\neg \varphi_1 \imp \varphi_2))
	\cup
	\barrho(\varphi_2 \imp \varphi_1)
	= (M \setminus \barrho(\neg \varphi_1 \imp \neg \varphi_2))
	\cup
	(M \setminus \barrho(\varphi_2))
	\cup \barrho(\varphi_1)
	= (M \setminus ( \barrho(\neg \neg \varphi_1) \cup \barrho(\neg \varphi_2)))
	\cup
	(M \setminus \barrho(\varphi_2))
	\cup \barrho(\varphi_1)
	= (M \setminus ( (M \setminus M \setminus \barrho(\varphi_1))
	\cup (M \setminus \barrho(\varphi_2))))
	\cup
	(M \setminus \barrho(\varphi_2))
	\cup \barrho(\varphi_1)
	= (M \setminus ( \barrho(\varphi_1)
	\cup (M \setminus \barrho(\varphi_2))))
	\cup
	(M \setminus \barrho(\varphi_2))
	\cup \barrho(\varphi_1)
	= M.
	$
	
	(4)
	$\MM,\rho \vDash \varphi_1 \imp \varphi_2$,
	so 
	$\barrho(\varphi_1 \imp \varphi_2) 
	= (M \setminus \barrho(\varphi_1)) \cup \barrho(\varphi_2) = M$,
	and thus $\barrho(\varphi_1) \subseteq \barrho(\varphi_2)$.
	Because $\MM,\rho \vDash \varphi_1$,
	$\barrho(\varphi_1) = M$,
	and thus $\barrho(\varphi_2) = M$.
	
	(5)
	$\barrho(\forall x . \varphi \imp \varphi[y/x])
	= (M \setminus \barrho(\forall x . \varphi)) \cup \barrho(\varphi[y/x])
	= (M \setminus \bigcap_{\rhop} (\barrhop(\varphi)) )
	\cup \barrhopx{y}(\varphi)
	$
	where $\rhopx{y} = \rho[\rho(y) /x]$
	and $\rhop \simon{x} \rho$.
	Notice that $\rhox{y} \simon{x} \rho$.
	Thus $\bigcap_{\rhop} (\barrhop(\varphi)) \subseteq \barrhopx{y}(\varphi)$,
	and $ (M \setminus \bigcap_{\rhop} (\barrhop(\varphi)) )
	\cup \barrhopx{y}(\varphi) = M$.
	
	(6)
	If suffices to show
	$\barrho(\forall x . (\varphi_1 \imp \varphi_2)
	\subseteq
	\barrho(\varphi_1 \imp \forall x . \varphi_2).
	$
	Notice that
	$\barrho(\forall x . (\varphi_1 \imp \varphi_2))
	= \bigcap_{\rhop}\barrhop((\varphi_1 \imp \varphi))
	= \bigcap_{\rhop}((M \setminus \barrhop(\varphi_1)) \cup 
	\barrhop(\varphi_2))
	$
	where $\rhop \simon{x} \rho$.
	Since $x \not\in \FV(\varphi_1)$,
	$\barrhop(\varphi_1) = \barrho(\varphi_1)$,
	and thus
	$\bigcap_{\rhop}((M \setminus \barrhop(\varphi_1)) \cup \barrhop(\varphi_2))
	= \bigcap_{\rhop}((M \setminus \barrho(\varphi_1)) \cup \barrhop(\varphi_2))
	= (M \setminus \barrho(\varphi_1)) \cup \bigcap_{\rhop}(\barrhop(\varphi_2))
	= \barrho(\varphi_1 \imp \forall x . \varphi_2).
	$
	
	
	
	(7)
	$\barrho(\forall x . \varphi)
	= \bigcap_{\rhop} \barrhop(\varphi)
	$
	where $\rhop \simon{x} \rho$,
	so it suffices to show $\barrhop(\varphi) = M$ for any $\rhop$.
	Since $\vDash \varphi$, $\MM,\rhop \vDash \varphi$, and thus
	$\barrhop(\varphi) = M$.
	
	%In the following, let
	%$\CSub{\sigma}[\varphi_i] =
	%\sigma(\varphi_1 \ddd \varphi_{i-1}, \varphi_i, \varphi_{i+1} \ddd 
	%\varphi_n)$.
	
	(8)
	$\barrho(\CSub{\sigma}[\bot] \imp \bot)
	= M \setminus \barrho(\CSub{\sigma}[\bot])
	$,
	so it suffices to show $\barrho(\CSub{\sigma}[\bot]) = \emptyset$.
	In fact,
	$\barrho(\sigma(\dots \bot \dots))
	= \sigmaM(\dots \barrho(\bot) \dots)
	= \sigmaM(\dots \emptyset \dots)
	= \emptyset.
	$
	
	(9)
	It suffices to show
	$\barrho(\CSub{\sigma}(\varphi_1 \vee \varphi_2))
	\subseteq
	\barrho(\CSub{\sigma}[ \varphi_1 ]
	\vee
	\CSub{\sigma}[ \varphi_2 ])$.
	In fact,
	$\barrho(\CSub{\sigma}(\varphi_1 \vee \varphi_2))
	= \barrho(\sigma(\dots (\barrho(\varphi_1) \cup \barrho(\varphi_2)) \dots))
	= \sigmaM(\dots \barrho(\varphi_1) \dots)
	\cup
	\sigmaM(\dots \barrho(\varphi_2) \dots)
	= \barrho(\CSub{\sigma}[ \varphi_1 ])
	\cup
	\barrho(\CSub{\sigma}[ \varphi_2 ])
	= \barrho(\CSub{\sigma}[ \varphi_1 ]
	\vee
	\CSub{\sigma}[ \varphi_2 ]).
	$
	
	(10)
	It suffices to show
	$\barrho(\CSub{\sigma}[\exists x . \varphi])
	\subseteq
	\barrho(\exists x . \CSub{\sigma}[\varphi])$.
	In fact,
	$
	\barrho(\CSub{\sigma}[\exists x . \varphi])
	= \barrho(\sigma(\dots \exists x . \varphi \dots))
	= \sigmaM(\dots \barrho(\exists x. \varphi) \dots)
	= \sigmaM(\ldots \bigcup_{\rhop}\barrhop(\varphi) \dots)
	= \bigcup_{\rhop} \sigmaM(\dots \barrhop(\varphi) \dots)
	= \barrho(\exists x . \CSub{\sigma}[\varphi])
	$
	where $\rhop \simon{x} \rho$.
	Notice that we can move the big union $\bigcup_{\rhop}$ from the argument
	to the top without affecting other arguments because
	$x \not\in \FV(\Csigmaapp{\exists x . \varphi})$.
	
	(11)
	It suffices to show
	$\barrho(\Csigma[\varphi_1]) \subseteq \barrho(\Csigma[\varphi_2])$.
	Notice that
	$\vDash \varphi_1 \imp \varphi_2$,
	so $\barrho(\varphi_1) \subseteq \barrho(\varphi_2)$,
	and thus,
	$\barrho(\Csigma[\varphi_1])
	= \sigmaM(\dots \barrho(\varphi_1) \dots)
	\subseteq \sigmaM(\dots \barrho(\varphi_2) \dots)
	= \barrho(\Csigma[\varphi_2])$.
	
	(12)
	$\barrho(\exists x . x)
	= \bigcup_{\rhop}(\barrhop(x))
	= \bigcup_{\rhop} \{ \rhop(x) \}$
	where $\rhop \simon{x} \rho$.
	Notice $\bigcup_{\rhop} \{ \rhop(x) \} = \bigcup_{a \in M} \{ a \} = M.$
\end{proof}

(13)
It suffices to show that
either
$\barrho(C_1[x \wedge \varphi])$
or
$\barrho(C_2[x \wedge \neg \varphi])$ is the empty set.
For every symbol context $C$,
use the same technique in (8) and structural induction,
we can prove that if $\barrho(\psi) = \emptyset$ then
$\barrho(C[\psi]) = \emptyset$.
Therefore, we just need to prove that
either
$\barrho(x \wedge \varphi)$
or
$\barrho(x \wedge \neg \varphi)$ is the empty set.
If $\rho(x) \not\in \barrho(\varphi)$, then the former is empty.
Otherwise, the latter is empty.

Now we are ready to prove Theorem~\ref{thm_soundness}.
\soundness*
\begin{proof}
Conduct induction on the length of proof of $\varphi$.
If the length is 1, then $\varphi$ is either an axiom or a member of
$\Gamma$.
If $\varphi$ is an axiom, then $\vDash \varphi$ by 
Lemma~\ref{lemma_soundness_lemma}.
It $\varphi \in \Gamma$, then $\Gamma \vDash \varphi$ by definition.

Assume every pattern which has a proof less than $n$ steps satisfies
the conclusion,
and $\varphi$ has a proof of $n+1$ steps:
$$
\varphi_1 \ddd \varphi_{n} , \varphi_{n+1}
\qquad
\text{with $\varphi_{n+1} \equiv \varphi$}
$$
By induction hypothesis,
$\Gamma \vDash \varphi_1$ \ddd $\Gamma \vDash \varphi_n$.
If $\varphi$ is an axiom or a member of $\Gamma$, 
then $\Gamma \vDash \varphi$ for the same reason as showed before.
If $\varphi$ is the conclusion of rules
\modusponens, \universalgeneralization, or \framing,
then $\Gamma \vDash \varphi$ by Lemma~\ref{lemma_soundness_lemma},
Case (4), (7), and (11), respectively.
\end{proof}

\subsection{Completeness when the Hypothesis Set is Empty}

In this subsection and the next one, we will discuss
complete deduction of matching logic.
The completeness theorem that we will eventually prove
says that 
for any hypothesis set $H$
and any pattern $\varphi$ such that $H \vDash \varphi$,
under some mild assumption,
there is a proof of $\varphi$ from $H$, i.e., 
$H \vdash \varphi$.
We call the pattern set $H$ the hypothesis set.
We will prove the theorem in two steps.
Firstly, we prove a preliminary completeness theorem
called the local completeness theorem, where the hypothesis set $H$ 
is the empty set.
Then in the next subsection, we extend 
local completeness theorem to global completeness theorem,
where the hypothesis set $H$ can be any pattern set.
We give credits to Blackburn's previous research
about hybrid and polyadic modal logic; while this paper
uses novel techniques to handle many-sortedness,
and to combine the hybrid and polyadic cases.

We start by stating the local completeness theorem.

\begin{restatable}[Local completeness]{theorem}{completenessA}
\label{thm_completeness_A}
For any pattern $\varphi$ such that $\emptyset \vDash \varphi$, 
$\emptyset \vdash \varphi$.
\end{restatable}




\begin{definition}[Local Provability Relation]
Let $s$ be a sort,
$H_s \subseteq \Pattern_s$ be a pattern set,
and $\varphi_s$ be a pattern of sort $s$. 
We write $H_s \Vdash_s \varphi_s$,
if there exists a finite subset $\Delta_s \subseteq_\fin H_s$ such that
$\emptyset \vdash_s \bigwedge \Delta_s \imp \varphi_s$, where $\bigwedge 
\Delta_s$ is the conjunction of all patterns in $\Delta_s$.
When $\Delta_s$ is the empty set, $\bigwedge \Delta_s$ is $\top_s$.
Let $H = \{ H_s \}_{s \in S}$ be a family set of patterns.
We write $H \Vdash_s \varphi_s$ if $H_s \Vdash_s \varphi_s$.
We drop sort subscripts when there is no confusion.
\end{definition}

The provability relation $\Vdash_s$ is called a {local} one
because it is local in the sort $s$.
In other words, given a hypothesis set
$H = \{ H_s \}_{s \in S}$ and a pattern $\varphi_s$,
whether $H \Vdash_s \varphi_s$ depends only on $H_s$.
This is different from the provability relation we give in
Definition~\ref{def_proof}, where
whether $H \vdash_s \varphi_s$ depends on the hypothesis sets of all sorts.
As an example, let $\varphi,\varphi' \in \Pattern_{s_1}$ be two patterns
and $\sigma \in \Sigma_{s_1,s_2}$ be a symbol.
Define the hypothesis set
$H = \{ H_{s_1} , H_{s_2} \}$ where 
$H_{s_1} = \{ \varphi \imp \varphi' \}$
and $H_{s_2} = \emptyset$.
By frame reasoning, 
$H \vdash_{s_2} \sigma(\varphi) \imp \sigma(\varphi')$,
but
$H \Vdash_{s_2} \sigma(\varphi) \imp \sigma(\varphi')$ does not hold.

The following proposition shows that the local provability relation is
a subrelation of the provability relation defined in Definition~\ref{def_proof}.
\begin{proposition}
For any pattern set $H$
and pattern $\varphi$ of the same sort,
$H \Vdash \varphi$ implies $H \vdash \varphi$.
\end{proposition}
\begin{proof}
By definition and simple propositional reasoning.
\end{proof}

\begin{definition}[Consistent Sets]
\label{def_consistent_sets}
Let $\Gamma_s$ be a pattern set of sort $s$.
We say $\Gamma_s$ is \emph{consistent}, if $\Gamma_s \not\Vdash \bot_s$.
$\Gamma_s$ is a maximal consistent set (MCS) 
if any strict extension of it is inconsistent.
By abuse of language,
we say $\Gamma = \{ \Gamma_s \}_{s \in S}$ 
is consistent if every $\Gamma_s$ is consistent,
and $\Gamma$ is an MCS if every $\Gamma_s$ is an MCS.
\end{definition}

Like the local provability relation,
consistency is also a local property.
Pattern set $\Gamma_s$ is consistent (or an MCS) only depends on itself.
A useful intuition about consistent sets
is that they provide consistent ``views'' of patterns.
Recall that patterns in matching logic match elements in domain.
Intuitively speaking, a pattern set $\Gamma_s$ is inconsistent
if it contains patterns 
that cannot match common elements in any models and valuations.
In other words,
if $\Gamma_s$ is consistent,
then there exist a model $\MM$ and a valuation $\rho$,
and an element $a$ in the model,
such that 
all patterns in $\Gamma_s$ match $a$,
i.e.,
$a \in \barrho(\varphi)$
for all pattern $\varphi \in \Gamma_s$.
If $\Gamma_s$ is in addition an MCS, 
adding any pattern $\psi \not\in \Gamma_s$ will lead to inconsistency, 
and thus $a \not\in \barrho(\psi_s)$.
Therefore, we can think of the MCS $\Gamma_s$ representing
that particular element $a$,
with all patterns in $\Gamma_s$ matching it
while patterns outside $\Gamma_s$ not.
This useful intuition motivates the definition of canonical models
that consist MCSs as elements (see Definition~\ref{def_canonical_model}),
and the Truth Lemma that says
``Matching $=$ Membership in MCSs'',
connecting syntax and semantics,
(see Lemma~\ref{lemma_truth_lemma}).
They play an important role in proving the completeness result,
including both local and global completeness theorems.
The rest of this and the next subsections is all about making this intuition work.

\begin{proposition}[MCS Properties]
\label{prop_properties_of_MCS}
Given an MCS $\Gamma$
and patterns $\varphi, \varphi_1, \varphi_2$ of the same sort $s$.
The following propositions hold.
\begin{enumerate}
\item $\varphi \in \Gamma$ if and only if $\Gamma \Vdash \varphi$;
      In particular, if $\vdash \varphi$ then $\varphi \in \Gamma$;
\item $\neg \varphi \in \Gamma$ if and only if $\varphi \not\in \Gamma$;
\item $\varphi_1 \wedge \varphi_2 \in \Gamma$
      if and only if $\varphi_1 \in \Gamma$ and $\varphi_2 \in \Gamma$;
      In general, for any finite pattern set $\Delta$,
      $\bigwedge \Delta \in \Gamma$ if and only if
      $\Delta \subseteq \Gamma$;
\item $\varphi_1 \vee \varphi_2 \in \Gamma$
      if and only if $\varphi_1 \in \Gamma$ or $\varphi_2 \in \Gamma$;
      In general, for any finite pattern set $\Delta$,
      $\bigvee \Delta \in \Gamma$ if and only if
      $\Delta \cap \Gamma \neq \emptyset$;
      As a convention,
      when $\Delta = \emptyset$,
      $\bigvee \Delta$ is $\bot$;
\item $\varphi_1, \varphi_1 \imp \varphi_2 \in \Gamma$ implies
      $\varphi_2 \in \Gamma$;
      In particular, if $\vdash \varphi_1 \imp \varphi_2$,
      then $\varphi_1 \in \Gamma$ implies $\varphi_2 \in \Gamma$.
\end{enumerate}
\end{proposition}
\begin{proof}
Standard propositional reasoning.
\end{proof}

\begin{definition}[Witnessed MCSs]
Let $\Gamma$ be an MCS of sort $s$.
$\Gamma$ is a witnessed MCS,
if for any pattern $\exists x . \varphi \in \Gamma$, 
there is a variable $y$ such that
$(\exists x . \varphi) \imp \varphi[y/x] \in \Gamma$.
By abuse use of language, 
we say the family set $\Gamma = \{ \Gamma_s \}_{s \in S}$ is a witnessed MCS
if every $\Gamma_s$ is a witnessed MCS.
\end{definition}

\begin{comment}

\begin{definition}[Nominal Extension of Languages]
	Given a language $\Pattern$ with a set $\Var$ of variables.
	Assume a countably infinite set $\newVar$ of variables
	such that $\newVar \cap \Var = \emptyset$.
	Variables in $\newVar$ are called \emph{nominal variables}.
	Let $\eVar = \newVar \cup \Var$.
	Let $\ePattern$ be the extended language with a set $\eVar$ of variables.
	The \emph{nominal extension} of $\Pattern$, denoted as $\ePattern$,
	is a subset of $\ePattern$ that
	contains all those patterns in $\Pattern^+$ where
	nominal variables are not quantified.
\end{definition}


\begin{definition}[Provability and Consistency in Nominal Extension Languages]
Let $\Pattern$ be a language,
$\ePattern$ be its extension,
and $\ePattern$ be its nominal extension.
A proof in $\ePattern$ is a sequence of patterns
$\varphi_1 \ddd \varphi_n$
such that for any $1 \le i \le n$, $\varphi_i \in \ePattern$
and $\varphi_1 \ddd \varphi_n$ is a proof in $\ePattern$.
A pattern $\varphi$ is derivable in $\ePattern$ if it has a proof in 
$\ePattern$.
A pattern $\varphi$ is derivable from a set $\Gamma$ of patterns in $\ePattern$
if there exists a finite subset $\Gamma_0 \subseteq_\fin \Gamma$
such that the pattern $\bigwedge \Gamma_0 \imp \varphi$
is provable in $\ePattern$.
$\Gamma$ is called consistent in $\ePattern$,
if $\bot$ is not provable from $\Gamma$ in $\ePattern$.
$\Gamma$ is called maximal consistent in $\ePattern$,
if any proper extension is inconsistent.
\end{definition}

As we will show in the next lemmas and propositions, even if
$\ePattern$ is a restriction of the extended language $\ePattern$,
it still enjoys many desiring properties.
\begin{lemma}
\label{lemma_neLang_UG}
Let $\Pattern$ be a language
and $\ePattern$ be its nominal extension.
If $\varphi[i/x]$ is derivable in $\ePattern$
where $i \in \newVar$ and $x \in \Var$,
then there is a variable $y \in \Var$ that does not occur in $\varphi$
such that
$\forall y . \varphi[y/x]$ is derivable in~$\ePattern$.
\end{lemma}
\begin{proof}
If $x$ does not occur free in $\varphi$,
then $\varphi[i/x]$ and $\varphi[y/x]$ are exactly $\varphi$,
and the conclusion is clear.

Now suppose $x$ occurs free in $\varphi$.
By assumption, there is a proof of $\varphi[i/x]$ in $\ePattern$.
Pick $y \in \Var$ that does not occur in the proof, and replace
any occurrence of $i$ for $y$.
By induction on the length of the proof, we get a new proof
that derives $\varphi[y/x]$.
Finally by \universalgeneralization, we derive
$\forall y . \varphi[y/x]$.
\end{proof}

\begin{proposition}
\label{prop_provability_extension}
Let $\Pattern$ be a language,
$\ePattern$ be its extension,
and $\ePattern$ be its nominal extension.
For any pattern $\varphi$ in $\Pattern$, 
$\varphi$ is provable in $\Pattern$ iff
$\varphi$ is provable in $\ePattern$.
For any pattern $\varphi$ in $\ePattern$, 
$\varphi$ is provable in $\ePattern$ iff
$\varphi$ is provable in $\ePattern$.
\end{proposition}
\begin{proof}
Conduct induction on the length of the proof.
\end{proof}

\begin{proposition}
Let $\Pattern$ be a language,
$\ePattern$ be its extension,
and $\ePattern$ be its nominal extension.
For any maximal consistent set $\Gamma$ in $\ePattern$
and any pattern $\varphi$ in $\ePattern$, 
\begin{itemize}
\item $\varphi \in \Gamma$ iff $\varphi$ is provable from $\Gamma$ in 
$\ePattern$
\item $\neg \varphi \in \Gamma$ iff $\varphi \not\in \Gamma$ 
\item $\varphi \vee \psi \in \Gamma$ iff 
      $\varphi \in \Gamma$ or $\phi \in \Gamma$
\item $\varphi \wedge \psi \in \Gamma$ iff 
      $\varphi \in \Gamma$ and $\psi \in \Gamma$
\item $\varphi, \varphi \imp \psi \in \Gamma$ implies $\psi \in \Gamma$
\end{itemize}
\end{proposition}

\begin{proposition}
\label{prop_neLang_consistent}
Let $\Pattern$ be a language,
$\ePattern$ be its extension,
and $\ePattern$ be its nominal extension.
Any consistent set in $\Pattern$ is also
consistent in $\ePattern$, and
any consistent set in $\ePattern$ is also
consistent in $\ePattern$.
\end{proposition}
\begin{proof}
Use Proposition~\ref{prop_provability_extension}.
\end{proof}



The above results show that the nominal extension $\ePattern$
still enjoys expected properties,
even though it
is a restriction of the extended language $\ePattern$ by excluding all patterns
where nominal variables are quantified.
From now on till the end of this section,
let us only consider the nominal extension language $\ePattern$.
We will use $\Gamma, \Delta, \Sigma$ to denote witnessed MCSs
in $\ePattern$ unless we explicitly say otherwise.
We also write $\vdash \varphi$ to denote that $\varphi$ is derivable in 
$\ePattern$, unless we say otherwise.

\end{comment}


In the following, we show any consistent set
$\Gamma$ can be extended to a witnessed MCS
$\eGamma$.
The extension, however, requires an extension
of the set of variables.
To see why such an extension is needed, consider
the following example.
Let $\sig = (\Var, S, \Sigma)$ be a signature,
$s \in S$ be a sort,
and 
$\Gamma = \{ \neg x \mid x \in \Var_s \}$
be a pattern set containing all variable negations.
We leave it for the readers to show that $\Gamma$ is consistent.
Here, we claim the consistent set $\Gamma$
cannot be extended to a witnessed MCS $\eGamma$ in the signature $\sig$.
The proof is by contradiction.
Assume $\eGamma$ exists.
By Proposition~\ref{prop_properties_of_MCS} and \existence,
$\exists x . x \in \eGamma$.
Because $\eGamma$ is a witnessed MCS,
there is a variable $y$ such that
$(\exists x . x) \imp y \in \eGamma$, and
by Proposition~\ref{prop_properties_of_MCS}, $y \in \eGamma$.
On the other hand, $\neg y \in \Gamma \subseteq \eGamma$.
This contradicts the consistency of $\eGamma$.


\begin{lemma}[Extension Lemma]
\label{lemma_consistently_extension}
Let $\sig = (\Var, S, \Sigma)$ be a signature and
$\Gamma$ be a consistent set of sort $s \in S$.
Extend the variable set $\Var$ to $\eVar$
with countably infinitely many new variables,
and denoted the extended signature as
$\esig = (\eVar, S, \Sigma)$.
There exists a pattern set $\eGamma$ in the extended signature $\sig$
such that $\Gamma \subseteq \eGamma$
and $\eGamma$ is a witnessed MCS.
\end{lemma}
\begin{proof}
We use $\Pattern_s$ and $\ePattern_s$
denote the set of all patterns of sort $s$ in the original and extended signatures, respectively.
Enumerate all patterns $\varphi_1, \varphi_2, \dots \in \ePattern_s$.
For every sort $s$, enumerate all variables
$\newx_1 \cln s, \newx_2 \cln s, \dots$ in $\eVar_s \setminus \Var_s$.
We will construct a non-decreasing sequence of pattern sets
$\Gamma_0 \subseteq \Gamma_1 \subseteq \Gamma_2 \dots \subseteq \ePattern_s$,
with $\Gamma_0 = \Gamma$.
Notice that $\Gamma_0$ contains variables only in $\Var$.
Eventually, we will let $\eGamma = \bigcup_{i \ge 0} \Gamma_i$
and prove it has the intended properties.

For every $n \ge 1$, we define $\Gamma_n$
as follows.
If $\Gamma_{n-1} \cup \{ \varphi_n \}$ is inconsistent,
then $\Gamma_n = \Gamma_{n-1}$.
Otherwise,
$$
\Gamma_n = 
\begin{cases*}
  \Gamma_{n-1} \cup \{ \varphi_n \} 
     & if $\varphi_n$ is not of the form $\exists x \cln s'. \psi$
  \\
  \Gamma_{n-1} 
    \cup \{ \varphi_n \} 
    \cup \{ \psi[\newx_i \cln s' /x \cln s'] \}
     & if $\varphi_n \equiv \exists x \cln s' . \psi$ 
       (note that $x \cln s'$ is in $\eVar_{s'}$)
     \\
     & and $\newx_i \cln s'$ is the first variable in 
       $\eVar_{s'} \setminus \Var_{s'}$
     \\
     & that does not occur free
       in $\Gamma_{n-1}$ and $\psi$
\end{cases*}
$$
Notice that in the second case,
we can always pick a variable $\newx_i \cln s'$ that satisfies the conditions
because by construction, $\Gamma_{n-1} \cup \{\varphi_n\}$
uses at most finitely many variables in $\eVar \setminus \Var$.

We show that $\Gamma_n$ is consistent
for every $n \ge 0$ by induction.
The base case is to show
$\Gamma_0$ is consistent in the extended signature.
Assume it is not.
Then there exists a finite subset
$\Delta_0 \subseteq_\fin \Gamma_0$ such that
$\vdash \bigwedge \Delta_0 \imp \bot$.
The proof of $\bigwedge \Delta_0 \imp \bot$
is a finite sequence of patterns in $\ePattern$.
We can replace every occurrence of the variable $\newy \in \newVar$
($\newy$ can have any sort)
with a variable $y \in \Var$ that 
has the same sort as $\newy$ and
does not occur
(no matter bound or free)
in the proof.
By induction on the length of the proof,
the resulting sequence is also a proof of
$\bigwedge \Delta_0 \imp \bot$,
and it consists of only patterns in $\Pattern$.
This contradicts the consistency of $\Gamma_0$
as a subset of $\Pattern_s$,
and this contradiction finishes our proof of the base case.

Now assume $\Gamma_{n-1}$ is consistent for $n \ge 1$.
We will show $\Gamma_n$ is also consistent.
If $\Gamma_{n-1} \cup \{ \varphi_n \}$ is inconsistent
or $\varphi_n$ does not have the form $\exists x \cln s' . \psi$,
$\Gamma_n$ is consistent by construction.
Assume $\Gamma_{n-1} \cup \{ \varphi_n \}$ is consistent,
$\varphi_n \equiv \exists x \cln s' . \psi$,
but
$\Gamma_n = 
 \Gamma_{n-1} 
 \cup \{ \varphi_n \} 
 \cup \{ \psi[\newx_i \cln s' /x \cln s'] \}$
is not consistent.
Then there exists a finite subset 
$\Delta \subseteq_\fin \Gamma_{n-1} \cup \{\varphi_n\}$
such that 
$\vdash \bigwedge \Delta \imp \neg \psi[\newx_i \cln s' /x \cln s']$.
By \universalgeneralization,
$\vdash 
 \forall \newx_i \cln s'. 
 (\bigwedge \Delta \imp \neg \psi[\newx_i \cln s' /x \cln s'])$.
Notice that $\newx_i \cln s' \not\in \FV(\bigwedge \Delta)$
by construction,
so by FOL reasoning
$\vdash 
 \bigwedge \Delta 
 \imp \neg \exists \newx_i \cln s' . (\psi[\newx_i\cln s' /x\cln s' ])$.
Since $\newx_i \cln s' \not\in \FV(\psi)$,
by Definition~\ref{def_fv_etal},
$\exists \newx_i \cln s' . (\psi[\newx_i\cln s' /x\cln s' ]) \equiv \exists x 
\cln s' . \psi \equiv \varphi_n$, 
and thus $\vdash \bigwedge \Delta \imp \neg \varphi_n$.
This contradicts the assumption
that $\Gamma_{n-1} \cup \{\varphi_n\}$ is consistent.

Since $\Gamma_n$ is consistent for any $n \ge 0$, 
$\eGamma = \bigcup_n \Gamma_n$
is also consistent.
This is because the derivation 
that shows inconsistency would use only finitely many
patterns in $\eGamma$.
In addition, we know $\eGamma$ is maximal and witnessed by construction.
\end{proof}

We will prove that for every witnessed MCS 
$\Gamma = \{ \Gamma_s \}_{s \in S}$,
there exists a model $\MM$ and a valuation $\rho$ such that
for every $\varphi \in \Gamma_s$, $\barrho(\varphi) \neq \emptyset$.
The next definition defines the canonical model which
contains all witnessed MCSs as its elements.
We will construct our intended model $\MM$ as a submodel of
the canonical model.

\begin{definition}[Canonical Model]
\label{def_canonical_model}
Given a signature $\sig = (S,\Sigma)$.
The canonical model 
$\WW = (W,\__\WW)$ 
consists of
\begin{itemize}
\item a carrier set 
      $W_s = \{ \Gamma 
               \mid \text{$\Gamma$ is a witnessed MCS of sort $s$} \}$
       for every sort $s \in S$;
       Let $W = \{ W_s \}_{s \in S}$;
\item an interpretation 
      $\sigmaW \colon W_{s_1} \times \dots \times W_{s_n} \to \pset{W_s}$
      for every symbol 
      $\sigma \in \Sigma_{s_1 \dots s_n , s}$,
      defined as
      \begin{center}
        $\Gamma \in \sigmaW(\Gamma_1,\dots,\Gamma_n)$
        \quad if and only if \quad
        for any $\varphi_i \in \Gamma_i$, $1 \le i \le n$,
        $\sigma(\varphi_1,\dots,\varphi_n) \in \Gamma$;
      \end{center}
      In particular, the interpretation for a constant symbol $\sigma \in \SigmaSub{\lambda,s}$
      is $\sigma_\WW = \{ \Gamma \in W_s \mid \sigma \in \Gamma \}$.
\end{itemize}
The carrier set $W$ is not empty,
thanks to Lemma~\ref{lemma_consistently_extension}.

\end{definition}

The canonical model has a nontrivial property stated as the next lemma.
The proof of the lemma is difficult, so we leave it to the end of the subsection.

\begin{restatable}[Existence Lemma]{lemma}{existenceLemma}
\label{lemma_existence_of_witmodels}
Let $\sig = (S,\Sigma)$ be a signature
and $\Gamma$ be a witnessed MCS of sort $s \in S$.
Given a symbol $\sigma \in \SigmaSub{s_1 \dots s_n , s}$
and patterns $\varphi_1 \ddd \varphi_n$ of appropriate sorts.
If $\sigma(\varphi_1 \ddd \varphi_n) \in \Gamma$,
then there exist $n$ witnessed MCSs
$\Gamma_1  \ddd
 \Gamma_n $ of appropriate sorts
such that
$\varphi_i \in \Gamma_i$ for every $1 \le i \le n$, and
$\Gamma \in \sigmaMGammaoc( \Gamma_1 \ddd \Gamma_n )$.
\end{restatable}

\begin{definition}[Generated Models]
\label{def_generated_models}
Let $\sig = (S,\Sigma)$ be a signature and
$\WW = (W,\__\WW)$ be the canonical model.
Given a witnessed MCS $\Gamma = \{ \Gamma_s \}_{s \in S}$.
Define $Y = \{Y_s\}_{s \in S}$ 
be the smallest sets such that
$Y_s \subseteq W_s$ for every sort $s$, and
the following inductive properties are satisfied:
\begin{itemize}
\item $\Gamma_s \in Y_s$ for every sort $s$;
\item If $\Delta \in Y_s$
      and there exist a symbol 
      $\sigma \in \SigmaSub{s_1 \dots s_n, s}$ and 
      witnessed MCSs $\Delta_1 \ddd \Delta_n$ of appropriate sorts
      such that
      $\Delta \in \sigmaMGammaoc(\Delta_1,\dots,\Delta_n)$,
      then $\Delta_1 \in Y_{s_1} \ddd \Delta_n \in Y_{s_n}$. 
\end{itemize}
Let $\YY = (Y, \interp{\YY})$ 
be the model generated from $\Gamma$, where
\begin{center}
$\sigmaY (\Delta_1 \ddd \Delta_n) =
  Y_s \cap \sigmaW(\Delta_1 \ddd \Delta_n)$
\quad for every $\sigma \in \SigmaSub{s_1 \dots s_n, s}$ and
      $\Delta_1 \in Y_{s_1} \ddd \Delta_n \in Y_{s_n}$.
\end{center}
\end{definition}

We give some intuition about the generated model $\YY = (Y, \interp{\YY})$.
The interpretation $\sigmaY$ is just the restriction of 
the interpretation $\sigmaM$ on $Y$.
The carrier set $Y$ is defined inductively.
Firstly, $Y$ contains $\Gamma$.
Given a set $\Delta \in Y$.
If sets
$\Delta_1 \ddd \Delta_n$ 
are ``generated'' from $\Delta$ by a symbol $\sigma$,
meaning that 
$\Delta \in \sigmaW(\Delta_1, \ddd \Delta_n)$,
then they are also in $Y$.
Of course, a set $\Delta$ is in $Y$
maybe because it is generated
from a set $\Delta'$ by a symbol $\sigma'$,
while $\Delta'$ is generated 
from a set $\Delta''$ by a symbol $\sigma''$, and so on.
This generating path keeps going
and eventually ends at $\Gamma$ in finite number of steps.
By definition, every member of $Y$ has at least one such generating path,
which we formally define as follows.

\begin{definition}[Generating Paths]
\label{def_generating_path}
Let $\Gamma = \{ \Gamma_s \}_{s \in S}$ be a witnessed MCS and
$\YY$ be the model generated from $\Gamma$.
A \emph{generating path} $\pi$ is either the empty path $\epsilon$, or
a sequence of pairs 
$\seq{(\sigma_1, p_1) \ddd (\sigma_k , p_k)}$
where $\sigma_1 \ddd \sigma_k$ are symbols (not necessarily distinct)
and $p_1 \ddd p_k$ are natural numbers representing positions.
The \emph{generating path relation}, denoted as $\GP$,
is a binary relation
between witnessed MCSs in $Y$
and generating paths,
defined as the smallest relation that satisfies the following conditions:
\begin{itemize}
\item $\GP(\Gamma_s, \epsilon)$ holds for every sort $s$;
\item If $\GP(\Delta,\pi)$ holds for a set $\Delta \in Y_s$ and a generating path $\pi$,
      and there exist a symbol $\sigma \in \SigmaSub{s_1 \dots s_n, s}$ and 
      witnessed MCSs $\Delta_1 \ddd \Delta_n$ such that
      $\Delta \in \sigmaMGammaoc(\Delta_1,\dots,\Delta_n)$,
      then $\GP(\Delta_i, \seq{\pi, (\sigma,i)} )$ holds
      for every $1 \le i \le n$.
\end{itemize}
We say that $\Delta$ has a generating path $\pi$ in the generated model if
$\GP(\Delta,\pi)$ holds.
It is easy to see that every witnessed MCS in $Y$
has at least one generating path,
and if a witnessed MCS of sort $s$
has the empty path $\epsilon$ as its generating path,
it must be $\Gamma_s$ itself.
\end{definition}

\begin{definition}[Symbol Contexts for Generating Paths]
\label{def_generated_symbol_context}
Given a generating path $\pi$.
Define the symbol context $\Cpi$
inductively as follows.
If $\pi = \epsilon$, 
then $\Cpi$ is the identity context $\hole$.
If $\pi = \seq{\pi_0 , (\sigma, i)}$
where  $\sigma \in \SigmaSub{s_1 \dots s_n , s}$
and $1 \le i \le n$,
then
$\Cpi = C_{\pi_0}[
\sigma(\top_{s_1} \ddd \top_{s_{i-1}} , \hole , 
\top_{s_{i+1}} \ddd \top_{s_n})
]$.
\end{definition}

A good intuition about Definition~\ref{def_generated_symbol_context}
is given as the next lemma.

\begin{lemma}
\label{lemma_generating_path}
Let $\Gamma$ be a witnessed MCS and
$\YY$ be the model generated from $\Gamma$.
Let $\Delta \in Y$.
If $\Delta$ has a generating path $\pi$,
then
$\Cpi[\varphi] \in \Gamma$
for any pattern $\varphi \in \Delta$.
\end{lemma}
\begin{proof}
The proof is by induction on the length of the generating path $\pi$.
If $\pi$ is the empty path $\epsilon$, 
then $\Delta$ must be $\Gamma$ and $\Cpi$ is the identity 
context, and 
$\Cpi[\varphi] = \varphi \in \Gamma$ for any $\varphi \in \Delta$.
Now assume $\Delta$ has a generating path
$\pi = \seq{\pi_0 , (\sigma, i)}$
with $\sigma \in \SigmaSub{s_1 \dots s_n , s}$.
By Definition~\ref{def_generating_path}, there exist
witnessed MCSs
$\Delta_{s_1} \ddd \Delta_{s_n}, \Delta_s \in Y$
and $1 \le i \le n$ such that
$\Delta = \Delta_{s_i}$,
$\Delta_s \in \sigmaW(\Delta_{s_1} \ddd \Delta_{s_n})$,
and $\Delta_s$ has $\pi_0$ as its generating path.
For every $\varphi \in \Delta = \Delta_i$,
since $\top_{s_j} \in \Delta_{s_j}$ for any $j \neq i$,
by Definition~\ref{def_canonical_model},
$\sigma(\top_{s_1} \ddd \top_{s_{i-1}} , \varphi , 
\top_{s_{i+1}} \ddd \top_{s_n}) \in \Delta_s$.
By induction hypothesis, 
$C_{\pi_0}[
\sigma(\top_{s_1} \ddd \top_{s_{i-1}} , \varphi , 
\top_{s_{i+1}} \ddd \top_{s_n})] \in \Gamma$,
while the latter is exactly $\Cpi[\varphi]$.
\end{proof}

\begin{lemma}[Singleton Variables]
\label{lemma_singleton_variable}
Let $\Gamma$ be a witnessed MCS and
$\YY$ be the model generated from $\Gamma$.
For every $\Gamma_1, \Gamma_2 \in Y$ of the same sort
and every variable $x$,
if $x \in \Gamma_1 \cap \Gamma_2$ then $\Gamma_1 = \Gamma_2$.
\end{lemma}
\begin{proof}
Let $\pi_i$ be a generating path of $\Gamma_i$
for $i = 1, 2$.
Assume $\Gamma_1 \neq \Gamma_2$.
Then there exists a pattern $\varphi$ such that
$\varphi \in \Gamma_1$ and $\neg \varphi \in \Gamma_2$.
Because $x \in \Gamma_1 \cap \Gamma_2$, 
we know 
$x \wedge \varphi \in \Gamma_1$ and 
$x \wedge \neg \varphi \in \Gamma_2$.
By Lemma~\ref{lemma_generating_path},
$C_{\pi_1}[x \wedge \varphi], 
 C_{\pi_2}[x \wedge \neg \varphi] \in {\Gamma}$,
and thus 
$C_{\pi_1}[x \wedge \varphi] \wedge
 C_{\pi_2}[x \wedge \neg \varphi]
 \in \Gamma$.
On the other hand, 
$\neg(
 C_{\pi_1}[x \wedge \varphi] \wedge
 C_{\pi_2}[x \wedge \neg \varphi]
 )
$
is an instance of \singletonvariable
and thus it is included in ${\Gamma}$.
This contradicts the consistency of ${\Gamma}$.
\end{proof}

We will establish an important result about generated models
in Lemma~\ref{lemma_truth_lemma} (the Truth Lemma),
which links the semantics and syntax
and is essential to the completeness result.
Roughly speaking, the lemma says that for any generated model $\YY$
and any witnessed MCS $\Delta \in Y$,
a pattern $\varphi$ is in $\Delta$
if and only if
the interpretation of $\varphi$ in $\YY$
contains $\Delta$.
To prove the lemma, it is important to
show that every variable is interpreted to a singleton.
Lemma~\ref{lemma_singleton_variable} ensures
that every variable belongs to
\emph{at most one} witnessed MCS.
To make sure it is interpreted to \emph{exactly one} MCS, we complete our model
by adding a dummy element $\star$ to the carrier set, 
and interpreting all variables which are interpreted to 
none of the MCSs to
the dummy element.
This motivates the next definition.

\begin{definition}[Completed Models and Completed Valuations]
\label{def_completed_model}
Let ${\Gamma} = \{ \Gamma_s \}_{s \in S}$ be a witnessed MCS and 
$\YY$ be the ${\Gamma}$-generated model.
We here define the $\Gamma$-completed model, denoted as 
$\MM = (M, \interpM)$.
The carrier set $M = \{ M_s \}_{s \in S}$ is defined as follows
(for every sort $s \in S$):
\begin{itemize}
\item $M_s = Y_s$, 
      if every variable $x \cln s$ belongs at least one MCS in $Y_s$;
\item $M_s = Y_s \cup \{ \star_s \}$,
      otherwise.
\end{itemize}
We assume $\star_s$ is an entity that is different from any MCSs,
and $\star_{s_1} \neq \star_{s_2}$ if $s_1 \neq s_2$.
For every $\sigma \in \SigmaSub{s_1 \dots s_n, s}$,
define its interpretation
$$
\sigmaM(\Delta_1 \ddd \Delta_n) = 
\begin{cases*}
\emptyset
& if some $\Delta_i = \star_{s_i}$
\\
\sigmaY(\Delta_1 \ddd \Delta_n) \cup \{ \star_s \}
& if for all $1 \le j \le n$, $\Delta_j \neq \star_{s_j}$ and
  some $\Delta_i = {\Gamma_{s_i}}$
\\
\sigmaMGammaow(\Delta_1 \ddd \Delta_n)
& otherwise
\end{cases*}
$$
The completed valuation $\rho \colon \Var \to M$
is defined as
$$
\rho(x \cln s) = 
\begin{cases*}
\Delta & if $x \cln s \in \Delta$ \\
\star_s  & otherwise
\end{cases*}
$$
The valuation $\rho$ is a well-defined function,
because by Lemma~\ref{lemma_singleton_variable},
if there are two witnessed MCSs $\Delta_1$ and $\Delta_2$ such that
$x \in \Delta_1$ and $x \in \Delta_2$,
then $\Delta_1 = \Delta_2$.
\end{definition}


\begin{comment}


\begin{lemma}
\label{lemma_lemma_for_proving_existence_of_witmodels}
The following pattern is provable
$$
\sigma(\varphi_1 \ddd \varphi_{i-1} , \varphi_i , \varphi_{i+1} \ddd \varphi_n) 
\imp
\exists y_i . \sigma( \varphi_1 \ddd \varphi_{i-1} ,
                      (\exists x_i . \psi \imp \psi[y_i/x_i]) \wedge \varphi_i  
                      , \varphi_{i+1} \ddd \varphi_n )
$$
if $y_i$ does not occur free in it or in $\psi$.
\end{lemma}
\begin{proof}
By standard first-order reasoning.
\end{proof}

\end{comment}

Now we come back to prove Lemma~\ref{lemma_existence_of_witmodels}.
We need the following technical lemma.

\begin{lemma}
\label{lemma_existence_of_witmodels_lemma}
Let $\sigma \in \SigmaSub{s_1 \dots s_n , s}$ be a symbol,
$\Phi_1 \ddd \Phi_n, \phi$ be patterns 
of appropriate sorts,
and
$y_1 \ddd y_n,x$ be variables of appropriate sorts
such that $y_1 \ddd y_n$ are distinct,
and
$y_1 \ddd y_n \not\in
 \FV(\phi)\cup
 \bigcup_{1 \le i \le n} 
 \FV(\Phi_i) 
$.
Then
$$
\vdash
\sigma(\Phi_1 \ddd \Phi_n) \imp
\exists y_1 \ddd \exists y_n . 
\sigma(\Phi_1 \wedge (\exists x . \phi \imp \phi [y_1/x])
\ddd   \Phi_n \wedge (\exists x . \phi \imp \phi [y_n/x]))
$$
\end{lemma}
\begin{proof}
Notice that for every $1 \le i \le n$,
$$\vdash \exists x . \phi 
  \imp \exists y_i . (\phi[y_i/x]).$$
By easy matching logic reasoning,
$$
\vdash
\sigma(\Phi_1 \ddd \Phi_n) \imp
\sigma(\Phi_1 \wedge (\exists x . \phi \imp \exists y_1 . (\phi[y_1/x]))
\ddd   \Phi_n \wedge (\exists x . \phi \imp \exists y_n . (\phi[y_n/x])))
$$
Then use Proposition~\ref{prop_propgation_of_symbol_application} 
to move the quantifiers
$\exists y_1 \ddd \exists y_n$ to the top.
\end{proof}

\existenceLemma*

\begin{proof}
Recall that 
$\Gamma \in \sigmaW( \Gamma_1 \ddd \Gamma_n )$ means
for every $\phi_i \in \Gamma_i$, $1 \le i \le n$,
$\sigma(\phi_1 \ddd \phi_n) \in \Gamma$.
The main technique that we will be using here
is similar to Lemma~\ref{lemma_consistently_extension}.
We start with the singleton sets 
$\{ \varphi_i \}$ for every $1 \le i \le n$
and extend them to witnessed MCSs $\Gamma_i$,
while this time we also need to make sure the results
$\Gamma_1 \ddd \Gamma_n$ satisfy the desired property
$\Gamma \in \sigmaMGammaoc( \Gamma_1 \ddd \Gamma_n )$.
Another difference compared to Lemma~\ref{lemma_consistently_extension}
is that this time we do not extend our set of variables,
because our starting point, $\{ \varphi_i \}$, contains just one pattern
and uses only finitely many variables.
Readers will see how these conditions play a role in the upcoming proof.

Enumerate all patterns of sorts $s_1 \ddd s_n$ as follows
$\psi_0, \psi_1, \psi_2, \dots \in 
 \bigcup_{1 \le i \le n} \Pattern_{s_i}$.
Notice that $s_1 \ddd s_n$ do not need to be all distinct.
To ease our notation, we define a ``choice'' operator,
denoted as $[\varphi_s]_{s'}$,
as follows
$$
[\varphi_s]_{s'} =
\begin{cases*}
\varphi_s & if $s = s'$ \\
\text{nothing} & otherwise
\end{cases*}
$$
For example, $\varphi_s \wedge [\psi]_s$ means
$\varphi_s \wedge \psi$ if $\psi$ also has sort $s$.
Otherwise, it means $\varphi_s$.
The choice operator propagates with all logic connectives
in the natural way.
For example, $[\neg \psi]_s = \neg [\psi]_s$.

In the following, we will define a non-decreasing sequence
of pattern sets
$\Gammai{0} \subseteq \Gammai{1} \subseteq \Gammai{2} 
 \subseteq \dots \subseteq \Pattern_{s_i}$ 
for each $1 \le i \le n$, 
such that the following conditions are true 
for all $1 \le i \le n$ and $k \ge 0$:
\begin{enumerate}
\item If $\psi_k$ has sort $s_i$, 
      then either $\psi_k$ or $\neg \psi_k$ belongs to $\Gammai{k+1}$.
\item If $\psi_k$ has the form $\exists x . \phi_k$ and
it belongs to $\Gammai{k+1}$, then there exists
a variable $z$ such that
$(\exists x . \phi_k) \imp \phi_k[z/x]$ also belongs to 
$\Gammai{k+1}$.
\item $\Gammai{k}$ is finite.
\item Let $\pii{k} = \bigwedge\Gammai{k}$ for every $1 \le i \le n$. Then
      $\sigma(\pi_1^{(k)} \ddd \pi_n^{(k)}) \in \Gamma$.
\item $\Gammai{k}$ is consistent.
\end{enumerate}

Among the above five conditions, 
condition~(2)--(5) are like ``safety'' properties
while condition~(1) is like a ``liveness'' properties.
We will eventually let $\Gamma_i = \bigcup_{k \ge 0} \Gammai{k}$ and prove that
$\Gamma_i$ has the desired property.
Before we present the actual construction, 
we give some hints on how to prove these conditions hold.
Conditions (1)--(3) will be satisfied directly by construction, although
we will put a notable effort in 
satisfying condition (2).
Condition (4) will be proved hold by induction
on $k$.
Condition (5) is in fact a consequence of condition~(4)
as shown below.
Assume condition (4) holds but condition~(5) fails.
This means that $\Gammai{k}$ is not consistent for some $1 \le i \le n$,
so $\vdash \pii{k} \imp \bot$.
By \framing
$$\vdash \sigma(\pi_1^{(k)} \ddd \pi_i^{(k)} \ddd \pi_n^{(k)}) \imp
        \sigma(\pi_1^{(k)} \ddd \bot \ddd \pi_n^{(k)})$$
Then by Proposition~\ref{prop_propgation_of_symbol_application}
and FOL reasoning,
$$\vdash \sigma(\pi_1^{(k)} \ddd \pi_i^{(k)} \ddd \pi_n^{(k)}) \imp
        \bot$$
Since $\sigma(\pi_1^{(k)} \ddd \pi_i^{(k)} \ddd \pi_n^{(k)}) \in \Gamma$
by condition~(4), 
we know $\bot \in \Gamma$
by Proposition~\ref{prop_properties_of_MCS}.
And this contradicts the fact that $\Gamma$ is consistent.

Now we are ready to construct the sequence
$\Gammai{0} \subseteq \Gammai{1} \subseteq \Gammai{2} \subseteq \dots$ 
for $1 \le i \le n$.
Let
$\Gammai{0} = \{ \varphi_i \}$ for $1 \le i \le n$.
Obviously,
$\Gammai{0}$ satisfies conditions (3) and (4).
Condition (5) follows as a consequence
of condition (4).
Conditions (1) and (2) are not applicable.


Suppose we have already constructed
sets $\Gammai{k}$ for every $1 \le i \le n$ and $k \ge 0$,
which satisfy the conditions (1)--(5).
We show how to construct $\Gammai{k+1}$.
In order to satisfy condition~(1),
we should add either $\psi_k$ or $\neg \psi_k$ to
$\Gammai{k}$, if $\Gammaik$ has the same sort as $\psi_k$.
Otherwise, we simply let $\Gammai{k+1}$ be the same as
$\Gammaik$.
The question here is: if $\Gammaik$ has the same sort as $\psi_k$,
which pattern should we add to $\Gammaik$, 
$\psi_k$ or $\neg \psi_k$?
Obviously, condition (3) will still hold no matter which one we choose
to add,
so we just need to make sure that we do not break
conditions (2) and (4).

Let us start by satisfying condition~(4).
Consider pattern
$\sigma(\pi_1^{(k)} \ddd \pi_n^{(k)})$,
which, by condition~(4), is in $\Gamma$.
This tells us that the pattern
$$
\sigma(
\pi_1^{(k)} \wedge [\psi_k \vee \neg \psi_k]_{s_1}
\ddd 
\pi_n^{(k)} \wedge [\psi_k \vee \neg \psi_k]_{s_n}
)
$$
is also in $\Gamma$.
Recall that $[\_]_s$ is the choice operator,
so if $\psi_k$ has sort $s_i$, then
$\pii{k} \wedge [\psi_k \vee \neg \psi_k]_{s_i}$
is $\pii{k} \wedge (\psi_k \vee \neg \psi_k) $.
Otherwise,
it is $\pii{k}$.
Use Proposition~\ref{prop_propgation_of_symbol_application}
and FOL reasoning, and notice that the choice operator propagates
with the disjunction $\vee$ and the negation $\neg$,
we get
$$\sigma(
(\pi_1^{(k)} \wedge [\psi_k]_{s_1}) 
\vee 
(\pi_1^{(k)} \wedge \neg [\psi_k]_{s_1})
\ddd 
(\pi_n^{(k)} \wedge [\psi_k]_{s_n}) 
\vee 
(\pi_n^{(k)} \wedge \neg [\psi_k]_{s_n})
) \in \Gamma $$
Then we use Proposition~\ref{prop_propgation_of_symbol_application} again
and move all the disjunctions to the top, 
and we end up with a disjunction of
$2^n$ patterns:
$$\bigvee
  \sigma(
  \pi_1^{(k)} \wedge [\neg]_1^{(k)} [\psi_k]_{s_1} \ddd
  \pi_n^{(k)} \wedge [\neg]_n^{(k)} [\psi_k]_{s_n}
) \in \Gamma
$$
where $[\neg]$ means either nothing or $\neg$.
Notice that some $[\psi_k]_{s_i}$'s might be nothing, 
so some of these $2^n$ patterns may be the same.

Notice that $\Gamma$ is an MCS.
By proposition~\ref{prop_properties_of_MCS}, among these $2^n$ patterns
there must exists one pattern that is in $\Gamma$.
We denote \emph{that} pattern as
$$
\sigma(
\pi_1^{(k)} \wedge [\neg]_1^{(k)} [\psi_k]_{s_1} \ddd
\pi_n^{(k)} \wedge [\neg]_n^{(k)} [\psi_k]_{s_n}
)
$$
For any $1 \le i \le n$,
if $[\neg]_i^{(k)} [\psi_k]_{s_i}$
does not have the form $\exists x . \phi$,
we simply define 
$\Gammai{k+1} = \Gammai{k} \cup \{ [\neg]_i^{(k)} [\psi_k]_{s_i} \}$.
If $[\neg]_i^{(k)} [\psi_k]_{s_i}$
does have the form $\exists x . \phi$,
we need special effort to satisfy condition~(2).
Without loss of generality
and to ease our notation,
let us assume that \emph{for every} $1 \le i \le n$,
the pattern $[\neg]_i^{(k)} [\psi_k]_{s_i}$ has the same form
$\exists x . \phi$.
We are going to find for each index $i$ a variable $z_i$
such that
$$
\sigma(
\pi_1^{(k)} \wedge  \exists x . \phi 
            \wedge (\exists x . \phi \imp \phi[z_1/x]) \ddd
\pi_n^{(k)} \wedge  \exists x . \phi
            \wedge (\exists x . \phi \imp \phi[z_n/x])
) \in \Gamma
$$
This will allow us to define
$\Gammai{k+1} = \Gammai{k} 
    \cup \{ \exists x . \phi \}
    \cup \{ \exists x . \phi \imp \phi[z_i/x] \}
$
which satisfies conditions~(2) and~(4).

We find these variables $z_i$'s
by Lemma~\ref{lemma_existence_of_witmodels_lemma}
and the fact that $\Gamma$ is a witnessed set.
Let
$\Phi_i \equiv \pi_i^{(k)} \wedge  \exists x . \phi$
for $1 \le i \le n$.
By construction,
$\sigma(\Phi_1\ddd\Phi_n) \in \Gamma$.
Hence,
by Lemma~\ref{lemma_existence_of_witmodels_lemma}
and Proposition~\ref{prop_properties_of_MCS},
for any distinct variables 
$y_1 \ddd y_n \not\in
\FV(\phi)\cup
\bigcup_{1 \le i \le n} 
\FV(\Phi_i) 
$,
$$
\exists y_1 \dots \exists y_n .
\sigma(
\Phi_1 \wedge (\exists x . \phi \imp \phi[y_1/x])
\ddd
\Phi_n \wedge (\exists n . \phi \imp \phi[y_n/x])
) \in \Gamma
$$
The set $\Gamma$ is a witnessed set, 
so there exist variables $z_1 \ddd z_n$ such that
$$
\sigma(
\Phi_1
\wedge (\exists x . \phi \imp \phi[z_1/x])
\ddd
\Phi_n
\wedge (\exists x . \phi \imp \phi[z_n/x])
) \in \Gamma
$$
This justifies our construction
$\Gammai{k+1} = \Gammai{k} 
\cup \{ \exists x . \phi \}
\cup \{ \exists x . \phi \imp \phi[z_i/x] \}
$.

So far we have proved our construction
of the sequences
$\Gammai{0} \subseteq \Gammai{1} \subseteq \Gammai{2} \subseteq \dots$ 
for $1 \le i \le n$
satisfy the conditions (1)--(5).
Let $\Gamma_i = \bigcup_{k \ge 0} \Gammai{k}$ for $1 \le i \le n$.
By construction, $\Gamma_i$ is a witnessed MCS.
It remains to prove that
$\Gamma \in \sigmaMGammaoc(\Gamma_1 \ddd \Gamma_n)$.
To prove it, assume
$\phi_i \in \Gamma_i$ for $1 \le i \le n$.
By construction, there exists $K > 0$ such that
$\phi_i \in \Gammai{K}$ for all $1 \le i \le n$.
Therefore, $\vdash \pi_i^{(K)} \imp \phi_i$.
By condition (4), 
$\sigma(\pi_1^{(K)} \ddd \pi_n^{(K)}) \in \Gamma$,
and thus by \framing and Proposition~\ref{prop_properties_of_MCS},
$\sigma(\phi_1 \ddd \phi_n) \in \Gamma$.
\end{proof}



\begin{lemma}[Truth Lemma]
\label{lemma_truth_lemma}
Let $\Gamma$ be a witnessed MCS,
$\MM = (M, \interpM)$ be its completed model,
and $\rho$ be the completed valuation.
For any witnessed MCS $\Delta \in M$
and any pattern $\varphi$
such that $\Delta$ and $\varphi$ have the same sort,
\begin{center}
$\varphi \in \Gamma$ 
\quad if and only if \quad
$\Gamma \in \barrho(\varphi)$
\end{center}
\end{lemma}
\begin{proof}
The proof is by induction on the structure of $\varphi$.
If $\varphi$ is a variable
the conclusion follows by Definition~\ref{def_canonical_model}.
If $\varphi$ has the form $\psi_1 \wedge \psi_2$
or $\neg \psi_1$, the conclusion follows from 
Proposition~\ref{prop_properties_of_MCS}.
If $\varphi$ has the form $\sigma(\varphi_1 \ddd \varphi_n)$,
the conclusion from left to right is given by 
Lemma~\ref{lemma_existence_of_witmodels}.
The conclusion from right to left follows from
Definition~\ref{def_canonical_model}.

Now assume $\varphi$ has the form $\exists x . \psi$.
If $\exists x . \psi \in \Gamma$,
since $\Gamma$ is a witnessed set, there is a variable $y$ such that
$\exists x . \psi \imp \psi[y / x] \in \Gamma$,
and thus $\psi[y / x] \in \Gamma$.
By induction hypothesis,
$\Gamma \in \barrho(\psi[y / x])$,
and thus by the semantics of the logic,
$\Gamma \in \barrho(\exists x . \psi)$.

Consider the other direction. Assume $\Gamma \in \barrho(\exists x .\psi)$.
By definition there exists a witnessed set $\Gamma'$ in $\MM$ such that
$\Gamma \in \bar{\rho'}(\psi)$ where $\rho' = \rho[\Gamma' / x]$.
By Definition~\ref{def_completed_model},
every element in $\MM$ has a variable that is assigned to it by the 
completed valuation $\rho$.
Let us assume the variable $y$ is assigned to $\Gamma'$, i.e.,
$\rho(y) = \Gamma'$.
By Lemma~\ref{lemma_substitution_lemma},
$\Gamma \in \bar{\rho'}(\psi) = \barrho(\psi[y/x])$.
By induction hypothesis,
$\psi[y/x] \in \Gamma$.
Finally notice that $\vdash \psi[y/x] \imp \exists y . \psi[y/x]$.
By Proposition~\ref{prop_properties_of_MCS},
$\exists y . \psi[y/x] \in \Gamma$, i.e., $\psi \in \exists x . \psi$.

\end{proof}

\begin{theorem}
\label{thm_consistent_sets_have_models}
For any consistent set $\Gamma$,
there is a model $\MM$ and an valuation $\rho$ such that
for any pattern $\varphi \in \Gamma$, $\barrho(\varphi) \neq \emptyset$.
\end{theorem}
\begin{proof}
Use Lemma~\ref{lemma_consistently_extension} and extend $\Gamma$ to a
witnessed MCS $\eGamma$.
Let $\MM$ and $\rho$ be the completed model and valuation generated by
$\eGamma$ respectively.
By Lemma~\ref{lemma_truth_lemma}, 
for any pattern $\varphi \in \Gamma \subseteq \eGamma$, 
we get $\eGamma \in \barrho(\varphi)$,
so $\barrho(\varphi) \neq \emptyset$.
\end{proof}

We restate the completeness theorem and prove it.

\completenessA*

\begin{proof}
Assume the opposite.
If $\emptyset \not\vdash \varphi$, 
then $\{ \neg \varphi \}$ is consistent by 
Definition~\ref{def_consistent_sets}.
Then there is a model $\MM$ and an valuation $\rho$ such that
$\barrho(\neg \varphi) \neq \emptyset$, i.e., 
$\barrho(\varphi) \neq M$.
This contradicts the fact that $\emptyset \vDash \varphi$.
\end{proof}

\subsection{Completeness When the Hypothesis Set is Nonempty}

In the previous subsection, we discussed local completeness,
where the hypothesis set is empty.
In this section, we take a step forward and consider global completeness,
where the hypothesis set need not be empty.
More specifically, we will prove the next theorem.
\begin{restatable}[Global Completeness]{theorem}{completenessB}
\label{thm_completenessB}
Let $\varphi$ be a pattern of sort $s$ and $H$ 
be a set of patterns
such that $H \not\vDash \bot_{s'}$ for every sort $s'$ different from $s$.  
Then $H \vDash \varphi$ implies $H \vdash \varphi$.
\end{restatable}

We explain why we need the requirement
$H \not\vDash \bot_{s'}$.
Consider the following (counter-)example.
Let $\sig = (S,\Sigma)$ be a signature
where $S = \{s,s'\}$ and $\Sigma = \emptyset$.
Let $H = \{ H_s , H_{s'} \}$ where
$H_s = \{ \bot_s \}$ and $H_{s'} = \emptyset$.
Obviously, the hypothesis set $H$ has no model,
so $H \vDash \varphi$ holds for any pattern $\varphi$.
On the other hand,
we can prove for every pattern $\varphi_{s'}$ of sort $s'$,
$H \vdash \varphi_{s'}$ holds if and only if
$\emptyset \vdash \varphi_{s'}$,
because the symbol set $\Sigma$ is empty.
Therefore, we have
$H \vDash \bot_{s'}$ and $H \not\vdash \bot_{s'}$,
contradicting Theorem~\ref{thm_completenessB}.


\begin{definition}[Deductive Closure]
\label{def_deductive_closure}
Let $H = \{ H_s \}_{s \in S}$ be a hypothesis set.
The \emph{deductive closure} of $H$,
denoted as $\CC(H)$,
is the set of all patterns $\varphi$ such that
$H \vdash \varphi$. 
For any sort $s \in S$,
define $\CC_s(H) = \CC(H) \cap \Pattern_s$
be the set of all patterns $\varphi_s$ of sort $s$ such that
$\Gamma \vdash \varphi_s$.
\end{definition}
We immediately get the following result.
\begin{proposition}
For any hypothesis set $H$ and any pattern $\varphi$, 
$H \vdash \varphi$ if and only if 
$\CC(H) \Vdash \varphi$.
In particular, if $H \not\vdash \bot_s$ for every $s \in S$,
then $\CC(H)$ is consistent.
\end{proposition}

To prove Theorem~\ref{thm_completenessB}, 
we assume a hypothesis set $H$ such that
$\Gamma \not\vdash \bot_s$ for every sort $s$
and a pattern $\varphi$ 
such that $H \not\vdash \varphi$, and we try to show
$H \not\vDash \varphi$
by looking for a model $\MM$ and a valuation $\rho$ such that
$\MM \vDash H$ and $\barrho(\varphi) \neq M$.
We point out that it is sufficient to
consider the simpler case when all patterns in $H$ are closed.
If not,
we can ``make it closed'' by letting
$\forall H = 
 \{ \forall x_1 \dots \forall x_n . \psi
    \mid \psi \in H 
    \txtand \FV(\psi) = \{ x_1 \ddd x_n \}   \}$,
and notice that
\begin{align*}
& H \vdash \psi \quad\text{iff}\quad
  \forall H \vdash \psi
&& \text{for every pattern $\psi$}
\\
& \MM \vDash H \quad\text{iff}\quad
  \MM \vDash \forall H
&& \text{for every model $\MM$}
\end{align*}
Therefore, 
we can assume
the hypothesis set $H$ contains only closed
patterns without any loss of generality.
This additional assumption is quite convenient,
because when showing $\MM \vDash H$,
we just need to consider one valuation, instead of all.

The main proof technique is in fact similar
to the one we used in proving local completeness.
We look for a model $\MM$ and a valuation $\rho$ such that
$\barrho(\varphi) \neq M$,
but this time we also require $\MM \vDash H$.
How can we guarantee it?
We can expect a form of the truth lemma, which says
for every witnessed MCS $\Delta \in M$ and pattern $\psi$,
$\psi \in \Delta$ if and only if $\Delta \in \barrho(\psi)$.
To show that $\MM \vDash H$, we need to show
$\MM \vDash \psi$ for every $\psi \in H$.
Recall our assumption that all patterns in $H$ are closed,
so every $\psi \in H$ is closed.
Therefore, it suffices to show that
$\barrho(\psi) = M$
for every $\psi \in H$,
which means for every $\Delta \in M$, $\Delta \in \barrho(\psi)$.
Now by the truth lemma,
$\Delta \in \barrho(\psi)$ means
$\psi \in \Delta$, and thus our objective becomes to prove
$\psi \in \Delta$
for every $\psi \in H$ and every $\Delta \in M$.
In other words, every witnessed MCS $\Delta$ in the model $\MM$
contains $H$ as its subset.
This motivates the following definition of the canonical model
when a hypothesis pattern set $H$ is given.

\begin{definition}[Canonical Model \Rmnum{2}]
\label{def_canonical_model_B}
Given a hypothesis set $H$ 
such that $H \not\vdash \bot_s$ for any sort $s$,
and a pattern $\varphi$ such that
$H \not\vdash \varphi$.
The canonical model for $H$, denoted as
$\WW = (W,\__\WW)$,
consists of
\begin{itemize}
\item for every sort $s \in S$,
a carrier set
$W_s = \{ \Gamma \subseteq \Pattern_s
       \mid \text{$\Gamma$ is a witnessed MCS and
       	          $\CC_s(H) \subseteq \Gamma$}\}$;
      let $W = \{W_s\}_{s \in S}$;
\item for any symbol 
$\sigma \in \Sigma_{s_1 \dots s_n , s}$,
its interpretation 
$\sigmaMGammaoc \colon W_{s_1} \times \dots \times W_{s_n} \to \pset{W_s}$
defined as
\begin{center}
	$\Gamma \in \sigmaMGammaoc(\Gamma_1,\dots,\Gamma_n)$
	\quad iff \quad
	for any $\varphi_i \in \Gamma_i$, $1 \le i \le n$,
	$\sigma(\varphi_1,\dots,\varphi_n) \in \Gamma$
\end{center}
\end{itemize}
\end{definition}

Similarly, we have a form of existence lemma.
\begin{restatable}[Existence Lemma \Rmnum{2}]{lemma}{existenceLemmaTwo}
\label{lemma_existence_lamma_two}
Given a hypothesis set $H$ 
such that $H \not\vdash \bot_s$ for any sort $s$,
and its canonical model
$\WW = (W,\__\WW)$.
For any witnessed MCS $\Gamma \in W$,
any symbol $\sigma \in \SigmaSub{s_1 \dots s_n , s}$,
and any patterns $\varphi_1 \ddd \varphi_n$,
if $\sigma(\varphi_1 \ddd \varphi_n) \in \Gamma$,
then there exist witnessed MCSs $\Gamma_1 \ddd \Gamma_n \in W$ such that
$\varphi_i \in \Gamma_i$ for every $1 \le i \le n$, and
$\Gamma \in \sigmaW( \Gamma_1 \ddd \Gamma_n )$.
\end{restatable}
The difference between this existence lemma and
the previous one (Lemma~\ref{lemma_existence_of_witmodels})
is that the witnessed MCSs $\Gamma_1 \ddd \Gamma_n$ 
must be in the canonical model $\WW$,
which means they must contain $H_s$ (of appropriate sort $s$)
as subsets.
We will prove the lemma later.

\begin{definition}[Generated Models \Rmnum{2}]
Given a hypothesis set $H$ 
such that $H \not\vdash \bot_s$ for any sort $s$
and its canonical model $\WW = (W,\__\WW)$.
Let $\Gamma \in W$ be a witnessed MCS containing $H_s$
(of appropriate sort).
Define a subset $Y \subseteq W$ in the following inductive way:
\begin{itemize}
\item $\Gamma \in Y$;
\item If $\Delta \in Y$ and there exist a symbol $\sigma$
      and witnessed MCSs $\Delta_1 \ddd \Delta_n \in W$ such that
      $\Delta \in \sigmaW(\Delta_1 \ddd \Delta_n)$,
      then $\Delta_1 \ddd \Delta_n \in Y$.
\end{itemize}
Define $\YY = (Y, \interpY)$
be the ${\Gamma}$-generated model, where
$$
\sigmaY(\Delta_1 \ddd \Delta_n) = Y \cap \sigmaW(\Delta_1 \ddd \Delta_n)
\qquad \text{for any $\Delta_1 \ddd \Delta_n \in Y$}
$$
\end{definition}

We could then prove a similar result as Lemma~\ref{lemma_singleton_variable}.
\begin{lemma}[Singleton Variables \Rmnum{2}]
\label{lemma_singleton_variable_two}
Let $\YY = (Y, \interpY)$ be the $\Gamma$-generated model.
For every $\Gamma_1, \Gamma_2 \in Y$, if $x \in \Gamma_1 \cap \Gamma_2$ 
then $\Gamma_1 = \Gamma_2$. 
\end{lemma}

Again, Lemma~\ref{lemma_singleton_variable_two} tells us that
any variable $x$ belongs to at most one witnessed MCSs in the generated model
$\YY$.
We can then complete it by the following definition:
\begin{definition}[Completed Model and Completed Valuation \Rmnum{2}]
Given a hypothesis set $H$ 
such that $H \not\vdash \bot_s$ for any sort $s$
and its canonical model $\WW = (W,\__\WW)$.
Let $\Gamma \in W$ be a witnessed MCS containing $H_s$
(of appropriate sort).
Let $\YY = (Y, \interp{\YY})$ be the $\Gamma$-generated model.
The completed model of $\YY$, denoted as $\MM$, is defined as follows.
If every variable $x$ belongs to at least one witnessed MCS in $Y$,
then define $\MM$ be the same as $\YY$.
Otherwise, define it as follows:
\begin{itemize}
\item for every sort $s$, define 
      $M_s = Y_s \cup \{\star_s\}$, where $\star_s$ 
      is an arbitrary entity that is different from any MCSs;
      in addition, $\star_{s} \neq \star_{s'}$
      for every $s \neq s'$;
\item for every $\sigma \in \SigmaSub{s_1 \dots s_n,s}$,
      define
      $$\sigmaM(\Delta_1 \ddd \Delta_n) = 
       \begin{cases*}
       \emptyset
           & if there exists $1 \le i \le n$ such that
             $\Delta_i = \star_{s_i}$
       \\
       \sigmaY(\Delta_1 \ddd \Delta_n) \cup \{ \star_s \}
           & if for all $1 \le j \le n$, $\Delta_j \neq \star_{s_j}$, and \\
           & there exists $1 \le i \le n$ such that
             $\Delta_i = \Gamma_i$
       \\
       \sigmaY(\Delta_1 \ddd \Delta_n)
           & otherwise
       \end{cases*}$$
\end{itemize}
The completed valuation $\rho \colon \Var \to M$ is defined as
$$
\rho(x \cln s) = 
\begin{cases*}
\Gamma & if $x\cln s \in \Gamma$ \\
\star_s  & otherwise
\end{cases*}
$$
\end{definition}

Let us come back and prove Lemma~\ref{lemma_existence_lamma_two}.

\existenceLemmaTwo*

\begin{proof}
Enumerate all patterns of sorts $s_1 \ddd s_n$
as $\psi_0,\psi_1,\dots \in \bigcup_{1 \le i \le n} \Pattern_{s_i}$.
We will follow the same way as in
Lemma~\ref{lemma_existence_of_witmodels}.
More specifically, we will construct for every $1 \le i \le n$
a non-decreasing sequence of pattern sets
$\Gammai{0} \subseteq \Gammai{1} \subseteq \dots$,
starting from $\Gammai{0} = \CC_{s_i}(H) \cup \{ \varphi_i \}$.
As in Lemma~\ref{lemma_existence_of_witmodels},
these sequences should satisfy the following conditions
for every $k \ge 0$ and $1 \le i \le n$:
\begin{enumerate}
\item If $\psi_k$ has sort $s_i$, 
      then either $\psi_k$ or $\neg \psi_k$ belongs to $\Gammai{k+1}$.
\item If $\psi_k$ has the form $\exists x . \phi_k$ and
it belongs to $\Gammai{k+1}$, then there exists
a variable $z$ such that
$(\exists x . \phi_k) \imp \phi_k[z/x]$ also belongs to 
$\Gammai{k+1}$.
\item For every $\Deltai{k} \subseteq_\fin \Gammai{k}$
            and $\pii{k} = \bigwedge \Deltai{k}$,
            $\sigma(\pi_1^{(k)} \ddd \pi_n^{(k)}) \in \Gamma$.
\item $\Gammai{k}$ is consistent.
\end{enumerate}

We have seen conditions (1), (2), and (4)
in the proof of Lemma~\ref{lemma_existence_of_witmodels}.
Condition (3) naturally generalizes 
the condition (4) in the proof of Lemma~\ref{lemma_existence_of_witmodels},
as $\Gamma_i^{(k)}$ might not be finite anymore.
It is easy to show that condition (3) implies condition (4).

We need to worry about two things.
One is to show that all initial sets
$\Gamma_1^{(0)} \ddd \Gamma_n^{(0)}$ satisfy the condition (3).
The other is to construct 
$\Gamma_i^{(k+1)} \ddd \Gamma_n^{(k+1)}$
while maintaining the condition (3).
We discuss these two worries one by one.

Let us first show 
$\Gamma_1^{(0)} \ddd \Gamma_n^{(0)}$ satisfy the condition (3).
Let $\Delta_i^{(0)} \subseteq \Gamma_i^{(0)} = \CC_{s_i}(H) \cup \{\varphi_i\}$ 
for every $1 \le i \le n$.
By easy matching logic reasoning,
$H \vdash \varphi_i \imp \bigwedge \Delta_i^{(0)}$ for any $i$,
and then by frame reasoning,
$H \vdash \sigma(\varphi_1 \ddd \varphi_n) 
 \imp \sigma(\bigwedge \Delta_1^{(0)} \ddd \bigwedge \Delta_n^{(0)})$.
Since $\sigma(\varphi_1 \ddd \varphi_n) \in \Gamma$
and $\Gamma$ is a MCS,
we know
$\sigma(\bigwedge \Delta_1^{(0)} \ddd \bigwedge \Delta_n^{(0)}) \in \Gamma$,
and condition (3) holds.

Now we consider the construction of
$\Gamma_i^{(k+1)} \ddd \Gamma_n^{(k+1)}$.
In Lemma~\ref{lemma_existence_of_witmodels}, we showed 
if $\sigma(\pi_1^{(k)} \ddd \pi_n^{(k)}) \in \Gamma$,
then we can always pick
$[\neg]_1^{(k)} \psi_k \ddd [\neg]_n^{(k)} \psi_k$
where $[\neg]$ means either nothing or $\neg$,
such that
$$
\sigma(
  \pi_1^{(k)} \wedge [\neg]_1^{(k)} \psi_k \ddd
  \pi_n^{(k)} \wedge [\neg]_n^{(k)} \psi_k
)
\in \Gamma
$$
However, here we have many $\pii{k}$'s, one for each finite subset of 
$\Gammai{k}$.
How do we know if we can pick 
$[\neg]_1^{(k)} \psi_k \ddd [\neg]_n^{(k)} \psi_k$
such that they work for every finite subsets?
Notice that if $[\neg]_1^{(k)} \psi_k \ddd [\neg]_n^{(k)} \psi_k$
work for 
$
\pi_1^{(k)} = \bigwedge \Delta_1^{(k)} 
\ddd 
\pi_n^{(k)} = \bigwedge \Delta_n^{(k)} 
$,
then they also work for
every
$
{\pi'}_1^{(k)} = \bigwedge {\Delta'}_1^{(k)} 
\ddd 
{\pi'}_n^{(k)} = \bigwedge {\Delta'}_n^{(k)} 
$
where 
${\Delta'}_i^{(k)}$ is a subset of $\Delta_i^{(k)}$ for $i = 1 \ddd n$.
This is simply because that
$\vdash \pi_i^{(k)} \imp {\pi'}_i^{(k)}$ for $i = 1 \ddd n$,
and thus by frame reasoning,
\begin{align*}
\vdash
\sigma(
  \pi_1^{(k)} \wedge [\neg]_1^{(k)} \psi_k \ddd
  \pi_n^{(k)} \wedge [\neg]_n^{(k)} \psi_k
)
\imp
\sigma(
  {\pi'}_1^{(k)} \wedge [\neg]_1^{(k)} \psi_k \ddd
  {\pi'}_n^{(k)} \wedge [\neg]_n^{(k)} \psi_k
)
\end{align*}
Then by Lemma~\ref{prop_properties_of_MCS},
$$
\sigma(
  {\pi'}_1^{(k)} \wedge [\neg]_1^{(k)} \psi_k \ddd
  {\pi'}_n^{(k)} \wedge [\neg]_n^{(k)} \psi_k
)
\in \Gamma
$$
Therefore, if there was a set $\Deltai{k}$
that is the ``largest'' finite subset of $\Gammai{k}$
for $i = 1 \ddd n$,
we could then pick our
$[\neg]_1^{(k)} \psi_k \ddd [\neg]_n^{(k)} \psi_k$
according to
$\Delta_1^{(k)} \ddd \Delta_n^{(k)}$.
However, since there exists no largest finite subset
if $\Gammai{k}$ is infinite,
this approach does not work.
Instead, we consider all possible ways of picking
$[\neg]_1^{(k)} \psi_k \ddd [\neg]_n^{(k)} \psi_k$,
and as $\Delta_i^{(k)}$ approaches towards $\Gammai{k}$,
we will converge to one particular way of picking
$[\neg]_1^{(k)} \psi_k \ddd [\neg]_n^{(k)} \psi_k$
that work for all
$\Delta_1^{(k)} \ddd \Delta_n^{(k)}$.

Formally, define the set of all picking ways as
$$
P = \underbrace{
	\{ \psi_k , \neg \psi_k \} \times \dots \times
    \{ \psi_k , \neg \psi_k \}
    }_\text{
    $n$ times
    }
$$
Notice that $P$ is a discrete set consisting of $2^n$ elements.
Denote $P(\Delta_1^{(k)} \ddd \Delta_n^{(k)})$
as the set of all picking ways
for subsets $\Delta_1^{(k)} \ddd \Delta_n^{(k)}$
such that
$
\sigma(\bigwedge \Delta_1^{(k)} \wedge [\neg]_1^{(k)} \psi_k
  \ddd \bigwedge \Delta_n^{(k)} \wedge [\neg]_n^{(k)} \psi_k) \in \Gamma
$.
We know $P(\Delta_1^{(k)} \ddd \Delta_n^{(k)})$ is nonempty,
and as any $\Delta_i^{(k)}$ increases,
$P(\Delta_1^{(k)} \ddd \Delta_n^{(k)})$ decreases.
Let each $\Delta_i^{(k)}$ increases towards $\Gamma_i^{(k)}$,
and we will obtain a decreasing sequence of
sets of working picking ways,
which converges to a nonempty set $P_0$.
Assume 
$([\neg]_1^{(k)} \psi_k \ddd [\neg]_n^{(k)} \psi_k)$ belongs to $P_0$.

We now discuss condition (2). 
Similar to the proof of
Lemma~\ref{lemma_existence_of_witmodels},
let us assume (without loss of generality and for simplicity) 
that for every $1 \le i \le n$
the pattern $[\neg]_i^{(k)}[\psi_k]_{s_i}$
has the form $\exists x . \phi$,
and we look for variable $z_1 \ddd z_n$ such that
$$
\sigma(\bigwedge \Delta_1^{(k)} \wedge \exists x . \phi 
                                \wedge \exists x . \phi \imp \phi[z_1/x]
  \ddd \bigwedge \Delta_n^{(k)} \wedge \exists x . \phi
                                \wedge \exists x . \phi \imp \phi[z_n/x])
\in \Gamma
$$
for any subsets 
$\Delta_1^{(k)} \subseteq_\fin \Gamma_1^{(k)}
 \ddd 
 \Delta_n^{(k)} \subseteq_\fin \Gamma_n^{(k)}
$.
The difficulty, again, is that there might be infinitely many
finite subsets $\Delta_1^{(k)} \ddd \Delta_n^{(k)}$.
We already knew from the proof of 
Lemma~\ref{lemma_existence_of_witmodels}
that for any fixed subsets
$\Delta_1^{(k)} 
 \ddd 
 \Delta_n^{(k)},
$
we can find witnessed variables $z_1 \ddd z_n$.
In addition, by easy matching logic reasoning,
if witnessed variables $z_1 \ddd z_n$
work for subsets  
$\Delta_1^{(k)} 
 \ddd 
 \Delta_n^{(k)}
$,
they also work for subsets
${\Delta'}_1^{(k)} \subseteq \Delta_1^{(k)} 
 \ddd 
 {\Delta'}_n^{(k)} \subseteq \Delta_n^{(k)}
$.
Therefore,
we could consider the set of all possible
witnessed variables
$(z_1 \ddd z_n)$ for subsets 
$\Delta_1^{(k)} 
 \ddd 
 \Delta_n^{(k)}
$.
Let these subsets approach
$\Gamma_1^{(k)} 
 \ddd 
 \Gamma_n^{(k)},
$
and we will converge to a set of witnessed variables,
from which we pick anyone $(z_1 \ddd z_n)$.

The rest of the proof is the same as the proof of 
Lemma~\ref{lemma_existence_of_witmodels}.
\end{proof}

We can then prove the truth lemma as Lemma~\ref{lemma_truth_lemma}.
\begin{lemma}[Truth Lemma \Rmnum{2}]
\label{lemma_truth_lemma_two}
Given a hypothesis set $H$ 
such that $H \not\vdash \bot_s$ for any sort $s$
and its canonical model $\WW = (W,\__\WW)$.
Let $\Gamma \in W$ be a witnessed MCS containing $H_s$
(of appropriate sort).
Let $\WW = (W, \interp{\WW})$ be the $\Gamma$-generated model.
For every witnessed MCS $\Delta \in M$ and pattern $\varphi$,
$\varphi \in \Delta$ if and only if $\Delta \in \barrho(\varphi)$.
\end{lemma}
\begin{proof}
The same as the proof of Lemma~\ref{lemma_truth_lemma}.
\end{proof}

\completenessB*
\begin{proof}
Without loss of generality, assume $H$ contains only closed patterns.
Assume $H \not\vdash \varphi$,
and thus $\CC(H)  \cup \{ \neg \varphi \}$ is consistent.
Extend it to a witnessed MCS denoted as $\Gamma$.
Let $\WW = (W, \interpW)$ be the canonical model for $H$,
and $\MM = (M,\interpM)$ be the completed model generated by $\Gamma$.
Notice that $\neg \varphi \in \Gamma$.
By Lemma~\ref{lemma_truth_lemma_two},
$\Gamma \in \barrho(\neg \varphi)$,
so $\barrho(\varphi)$ is not the total set,
and $\MM \not\vDash \varphi$.

It remains to show that $\MM \vDash H$.
For every $\psi \in H$, we show that $\barrho(\psi) = M$, i.e.,
$\Delta \in \barrho(\psi)$ for every $\Delta \in M$.
By definition, if a witnessed MCS $\Delta \in M$,
then $\CC(H) \subseteq \Delta$.
In particular, $H \subseteq \Delta$, and thus $\psi \in \Delta$.
Again, by Lemma~\ref{lemma_truth_lemma_two}, 
$\Delta \in \barrho(\psi)$,
\todo[inline]{Fixme. What if $\Delta$ is $\star$?}

Therefore, the completed model $\WW$ satisfies $H$ but not $\varphi$,
and thus we conclude that $H \not\vDash \varphi$.
Here ends our proof.
\end{proof}


\end{document}