#!/usr/bin/env python3

import sys
import shutil
from os import (path, environ)

repo_dir = path.dirname(__file__)
sys.path.append(path.join(repo_dir, 'ext/'))
from kninja import *
environ['PATH'] = path.join(repo_dir, 'ext/k-light/bin/') + ':' + environ['PATH']

# Project Definition
# ==================

proj = KProject()

# Matching Logic Prover
# =====================

other_md_files = [ 'lang/smt-lang.md'
                 , 'lang/kore-lang.md'
                 , 'drivers/base.md'
                 , 'drivers/smt-driver.md'
                 , 'drivers/kore-driver.md'
                 , 'strategies/core.md'
                 , 'strategies/knaster-tarski.md'
                 , 'strategies/matching.md'
                 , 'strategies/simplification.md'
                 , 'strategies/search-bound.md'
                 , 'strategies/smt.md'
                 , 'strategies/unfolding.md'
                 ]

def prover(alias, flags = None):
    return proj.definition( alias = alias
                          , backend = 'ocaml'
                          , main = 'prover.md'
                          , other = other_md_files
                          , runner_script = './prover'
                          , flags = flags
                          )

prover_kore = prover('prover-kore', '--main-module DRIVER-KORE --syntax-module DRIVER-KORE-SYNTAX')
prover_smt  = prover('prover-smt',  '--main-module DRIVER-SMT  --syntax-module DRIVER-SMT-SYNTAX' )

# Functional tests
# ----------------

prover_kore.tests(inputs = glob('t/*.kore'), implicit_inputs = glob('t/definitions/*.kore'), flags = '-cCOMMANDLINE=.CommandLine')
prover_smt .tests(inputs = glob('t/*.smt2'), flags = '-cCOMMANDLINE=.CommandLine')

def log_on_success(file, message):
    return proj.rule( 'log-to-success'
                    , description = '$out: $message'
                    , command = "echo '$message' >> '$log_file'"
                    ) \
               .variable('log_file', file) \
                        .variable('message',  message) \
                        .ext(message.replace('/', '.'))

def krun_with_timeout(timeout_flags):
    # TODO: This timeout functionality should become a part of the runner script
    # or KNinja
    timeout_cmd = 'gtimeout' if shutil.which("gtimeout") else 'timeout'
    return prover_smt.krun() \
                     .ext('timeout') \
                     .variable('env', timeout_cmd + ' ' + timeout_flags + ' opam config exec --') \

unsat_tests = list(map(str.strip, open('t/test-lists/qf_shid_entl.unsat').readlines()))
passing_5   = list(map(str.strip, open('t/test-lists/qf_shid_entl.unsat.5').readlines()))
passing_8   = list(map(str.strip, open('t/test-lists/qf_shid_entl.unsat.8').readlines()))

def strategy_for_test(test):
    if test == 't/SL-COMP18/bench/qf_shid_entl/nll-vc01.smt2':
        return 'search-sl(bound: 11)'
    if test in passing_5: return 'search-sl(bound: 5)'
    if test in passing_8: return 'search-sl(bound: 8)'
    else:                 return 'search-sl(bound: 8)'
def known_passing(test):
    return (test in passing_5) \
        or (test in passing_8) \
        or (test == 't/SL-COMP18/bench/qf_shid_entl/nll-vc01.smt2')

def make_test(rule, test):
    commandline = "'--default-strategy %s'" % strategy_for_test(test)
    return proj.source(test) \
               .then(rule.variable('flags', '-cCOMMANDLINE=%s' % commandline))

tests_with_timeout = []
def sl_comp_test(test):
    global tests_with_timeout
    # test_no_timeout   = make_test(prover_smt.krun(), test)
    test_with_timeout = make_test(krun_with_timeout('20m'), test) \
                          .then(log_on_success('.build/passed', test))
    if known_passing(test): test_with_timeout.default()
    tests_with_timeout += [test_with_timeout]

for t in glob('t/SL-COMP18/bench/qf_shid_entl/*.smt2'):
    sl_comp_test(t)
proj.alias('collect-qf-shid-entl', tests_with_timeout)


#d Unit Tests
# ----------

# TODO: LLVM errors are miles better than OCaml (a pretty low bar).
# However, we're still waiting on mkstemp for the SMT test, and
# on parseKore for the rest of the implementation.

test_driver = proj.definition( alias = 'test-driver'
                             , backend = 'llvm'
                             , main = 'drivers/unit-tests.md'
                             , other = other_md_files + ['prover.md']
                             , runner_script = './prover'
                             , flags = '-ccopt -g' # -ccopt -O0'
                             )

unit_tests = []
unit_tests += [proj.source('t/unit/match-assoc')     .then(test_driver.krun())]
unit_tests += [proj.source('t/unit/match-assoc-comm').then(test_driver.krun())]
# unit_tests += [proj.source('t/unit/smt')  .then(test_driver.krun())]
proj.alias('unit-tests', unit_tests)

proj.main()
